{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "certain-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "## Jax Demo\n",
    "## Goal - fool around with Jax AutoDiff (function composition/transformation) library\n",
    "##\n",
    "## Author: Chris Meaney\n",
    "## Date: Feb 2021\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "massive-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import JAX dependencies\n",
    "import jax \n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap, hessian\n",
    "from jax import random\n",
    "\n",
    "## Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import seaborn as sns\n",
    "\n",
    "## Pandas data wrangling, summarization, etc.\n",
    "import pandas as pd\n",
    "\n",
    "## Old numpy - for comparing speed/flexibility JAX approach vs. existing NumPy/Scipy capabilities\n",
    "import numpy as onp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "analyzed-palace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "## Set seed\n",
    "key = random.PRNGKey(912834)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "circular-maximum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([     0, 912834], dtype=uint32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-corruption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-endorsement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "early-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "##\n",
    "##\n",
    "## Stats distribution, density, mass, etc. functions\n",
    "##\n",
    "##\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-demonstration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "threaded-patrick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.6995\n",
       "True     0.3005\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "## Bernoulli distirbution\n",
    "############################\n",
    "x = jax.random.bernoulli(key, p=0.30, shape=(10000,))\n",
    "pd.Series(x).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loving-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple loss function (scalar parm = p; vector input data = x)\n",
    "def bern_loss(p, x):\n",
    "    return -jnp.mean(jax.scipy.stats.bernoulli.logpmf(k=x, p=p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "minus-lingerie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fd1a841b950>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Log Likelihood as a Function of Parameter (p)\n",
    "support = jnp.linspace(0.001,0.999,1000)\n",
    "log_lik = jnp.array([bern_loss(p=p,x=x) for p in support])\n",
    "\n",
    "df = pd.DataFrame({'x':support, 'y':log_lik})\n",
    "plt = sns.lineplot(data=df, x='x', y='y')\n",
    "plt.axvline(0.30, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "arabic-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient of loss function\n",
    "grad_p = grad(bern_loss, argnums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "addressed-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get gradient for each value of support\n",
    "grad_support = jnp.array([grad_p(p,x) for p in support])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "civil-belize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.611287</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.299701</td>\n",
       "      <td>0.611289</td>\n",
       "      <td>-0.003808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.301699</td>\n",
       "      <td>0.611291</td>\n",
       "      <td>0.005690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.298702</td>\n",
       "      <td>0.611295</td>\n",
       "      <td>-0.008584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.302698</td>\n",
       "      <td>0.611299</td>\n",
       "      <td>0.010412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y      grad\n",
       "300  0.300700  0.611287  0.000950\n",
       "299  0.299701  0.611289 -0.003808\n",
       "301  0.301699  0.611291  0.005690\n",
       "298  0.298702  0.611295 -0.008584\n",
       "302  0.302698  0.611299  0.010412"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## See what gradient is at minimizer (and what min value is)\n",
    "df[['grad']] = grad_support\n",
    "\n",
    "## Find minimizer\n",
    "df = df.sort_values(by=['y'])\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "liberal-elements",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration=0\\tLoss=0.6931473\\tp=', '0.5')\n",
      "('Iteration=1\\tLoss=0.686906\\tp=', '0.49202')\n",
      "('Iteration=2\\tLoss=0.6811496\\tp=', '0.48435727')\n",
      "('Iteration=3\\tLoss=0.67583644\\tp=', '0.47699577')\n",
      "('Iteration=4\\tLoss=0.67092794\\tp=', '0.46992096')\n",
      "('Iteration=5\\tLoss=0.6663909\\tp=', '0.4631195')\n",
      "('Iteration=6\\tLoss=0.6621948\\tp=', '0.45657915')\n",
      "('Iteration=7\\tLoss=0.65831304\\tp=', '0.45028853')\n",
      "('Iteration=8\\tLoss=0.6547207\\tp=', '0.44423717')\n",
      "('Iteration=9\\tLoss=0.65139514\\tp=', '0.43841526')\n",
      "('Iteration=10\\tLoss=0.64831686\\tp=', '0.43281367')\n",
      "('Iteration=11\\tLoss=0.6454666\\tp=', '0.4274238')\n",
      "('Iteration=12\\tLoss=0.6428275\\tp=', '0.42223758')\n",
      "('Iteration=13\\tLoss=0.6403847\\tp=', '0.41724735')\n",
      "('Iteration=14\\tLoss=0.638123\\tp=', '0.41244593')\n",
      "('Iteration=15\\tLoss=0.6360295\\tp=', '0.40782645')\n",
      "('Iteration=16\\tLoss=0.6340922\\tp=', '0.40338236')\n",
      "('Iteration=17\\tLoss=0.63229924\\tp=', '0.39910746')\n",
      "('Iteration=18\\tLoss=0.63064104\\tp=', '0.39499575')\n",
      "('Iteration=19\\tLoss=0.6291076\\tp=', '0.39104152')\n",
      "('Iteration=20\\tLoss=0.6276897\\tp=', '0.3872393')\n",
      "('Iteration=21\\tLoss=0.6263794\\tp=', '0.3835838')\n",
      "('Iteration=22\\tLoss=0.6251687\\tp=', '0.38006997')\n",
      "('Iteration=23\\tLoss=0.62405044\\tp=', '0.3766929')\n",
      "('Iteration=24\\tLoss=0.62301815\\tp=', '0.3734478')\n",
      "('Iteration=25\\tLoss=0.6220652\\tp=', '0.37033018')\n",
      "('Iteration=26\\tLoss=0.6211864\\tp=', '0.36733556')\n",
      "('Iteration=27\\tLoss=0.62037563\\tp=', '0.36445966')\n",
      "('Iteration=28\\tLoss=0.6196283\\tp=', '0.36169836')\n",
      "('Iteration=29\\tLoss=0.6189397\\tp=', '0.35904762')\n",
      "('Iteration=30\\tLoss=0.6183056\\tp=', '0.35650355')\n",
      "('Iteration=31\\tLoss=0.61772186\\tp=', '0.35406232')\n",
      "('Iteration=32\\tLoss=0.61718464\\tp=', '0.3517203')\n",
      "('Iteration=33\\tLoss=0.6166903\\tp=', '0.34947392')\n",
      "('Iteration=34\\tLoss=0.6162358\\tp=', '0.34731972')\n",
      "('Iteration=35\\tLoss=0.615818\\tp=', '0.34525436')\n",
      "('Iteration=36\\tLoss=0.61543417\\tp=', '0.34327456')\n",
      "('Iteration=37\\tLoss=0.61508185\\tp=', '0.34137717')\n",
      "('Iteration=38\\tLoss=0.61475813\\tp=', '0.3395591')\n",
      "('Iteration=39\\tLoss=0.6144611\\tp=', '0.3378174')\n",
      "('Iteration=40\\tLoss=0.6141889\\tp=', '0.3361492')\n",
      "('Iteration=41\\tLoss=0.61393905\\tp=', '0.33455166')\n",
      "('Iteration=42\\tLoss=0.61371017\\tp=', '0.33302212')\n",
      "('Iteration=43\\tLoss=0.6135002\\tp=', '0.33155793')\n",
      "('Iteration=44\\tLoss=0.6133081\\tp=', '0.33015656')\n",
      "('Iteration=45\\tLoss=0.6131322\\tp=', '0.32881558')\n",
      "('Iteration=46\\tLoss=0.61297107\\tp=', '0.32753256')\n",
      "('Iteration=47\\tLoss=0.61282367\\tp=', '0.32630524')\n",
      "('Iteration=48\\tLoss=0.612689\\tp=', '0.32513136')\n",
      "('Iteration=49\\tLoss=0.61256564\\tp=', '0.3240088')\n",
      "('Iteration=50\\tLoss=0.61245304\\tp=', '0.32293546')\n",
      "('Iteration=51\\tLoss=0.61235\\tp=', '0.32190937')\n",
      "('Iteration=52\\tLoss=0.61225617\\tp=', '0.32092857')\n",
      "('Iteration=53\\tLoss=0.61217004\\tp=', '0.3199912')\n",
      "('Iteration=54\\tLoss=0.6120917\\tp=', '0.31909546')\n",
      "('Iteration=55\\tLoss=0.61202013\\tp=', '0.3182396')\n",
      "('Iteration=56\\tLoss=0.6119547\\tp=', '0.31742197')\n",
      "('Iteration=57\\tLoss=0.6118951\\tp=', '0.31664094')\n",
      "('Iteration=58\\tLoss=0.61184067\\tp=', '0.315895')\n",
      "('Iteration=59\\tLoss=0.61179113\\tp=', '0.3151826')\n",
      "('Iteration=60\\tLoss=0.6117458\\tp=', '0.31450236')\n",
      "('Iteration=61\\tLoss=0.6117046\\tp=', '0.31385288')\n",
      "('Iteration=62\\tLoss=0.6116669\\tp=', '0.3132328')\n",
      "('Iteration=63\\tLoss=0.611633\\tp=', '0.3126409')\n",
      "('Iteration=64\\tLoss=0.6116016\\tp=', '0.31207594')\n",
      "('Iteration=65\\tLoss=0.6115732\\tp=', '0.31153673')\n",
      "('Iteration=66\\tLoss=0.6115472\\tp=', '0.31102216')\n",
      "('Iteration=67\\tLoss=0.6115239\\tp=', '0.31053114')\n",
      "('Iteration=68\\tLoss=0.61150235\\tp=', '0.31006262')\n",
      "('Iteration=69\\tLoss=0.61148274\\tp=', '0.3096156')\n",
      "('Iteration=70\\tLoss=0.611465\\tp=', '0.30918917')\n",
      "('Iteration=71\\tLoss=0.6114488\\tp=', '0.30878237')\n",
      "('Iteration=72\\tLoss=0.6114343\\tp=', '0.3083943')\n",
      "('Iteration=73\\tLoss=0.6114207\\tp=', '0.3080242')\n",
      "('Iteration=74\\tLoss=0.61140865\\tp=', '0.3076712')\n",
      "('Iteration=75\\tLoss=0.6113975\\tp=', '0.30733454')\n",
      "('Iteration=76\\tLoss=0.6113875\\tp=', '0.30701348')\n",
      "('Iteration=77\\tLoss=0.61137825\\tp=', '0.30670732')\n",
      "('Iteration=78\\tLoss=0.61137\\tp=', '0.3064154')\n",
      "('Iteration=79\\tLoss=0.6113623\\tp=', '0.30613706')\n",
      "('Iteration=80\\tLoss=0.61135554\\tp=', '0.30587167')\n",
      "('Iteration=81\\tLoss=0.61134934\\tp=', '0.30561864')\n",
      "('Iteration=82\\tLoss=0.6113437\\tp=', '0.30537745')\n",
      "('Iteration=83\\tLoss=0.61133844\\tp=', '0.30514753')\n",
      "('Iteration=84\\tLoss=0.6113339\\tp=', '0.30492833')\n",
      "('Iteration=85\\tLoss=0.61132944\\tp=', '0.3047194')\n",
      "('Iteration=86\\tLoss=0.61132574\\tp=', '0.30452022')\n",
      "('Iteration=87\\tLoss=0.6113222\\tp=', '0.3043304')\n",
      "('Iteration=88\\tLoss=0.61131895\\tp=', '0.30414948')\n",
      "('Iteration=89\\tLoss=0.61131597\\tp=', '0.30397704')\n",
      "('Iteration=90\\tLoss=0.6113133\\tp=', '0.3038127')\n",
      "('Iteration=91\\tLoss=0.611311\\tp=', '0.3036561')\n",
      "('Iteration=92\\tLoss=0.6113088\\tp=', '0.30350685')\n",
      "('Iteration=93\\tLoss=0.6113067\\tp=', '0.3033646')\n",
      "('Iteration=94\\tLoss=0.6113049\\tp=', '0.30322906')\n",
      "('Iteration=95\\tLoss=0.61130327\\tp=', '0.3030999')\n",
      "('Iteration=96\\tLoss=0.611302\\tp=', '0.30297682')\n",
      "('Iteration=97\\tLoss=0.61130065\\tp=', '0.30285954')\n",
      "('Iteration=98\\tLoss=0.6112992\\tp=', '0.3027478')\n",
      "('Iteration=99\\tLoss=0.61129826\\tp=', '0.3026413')\n",
      "('Iteration=100\\tLoss=0.6112972\\tp=', '0.30253986')\n",
      "('Iteration=101\\tLoss=0.6112962\\tp=', '0.30244318')\n",
      "('Iteration=102\\tLoss=0.6112954\\tp=', '0.30235106')\n",
      "('Iteration=103\\tLoss=0.6112946\\tp=', '0.3022633')\n",
      "('Iteration=104\\tLoss=0.6112941\\tp=', '0.3021797')\n",
      "('Iteration=105\\tLoss=0.6112935\\tp=', '0.30210003')\n",
      "('Iteration=106\\tLoss=0.611293\\tp=', '0.30202416')\n",
      "('Iteration=107\\tLoss=0.61129224\\tp=', '0.30195186')\n",
      "('Iteration=108\\tLoss=0.61129194\\tp=', '0.30188298')\n",
      "('Iteration=109\\tLoss=0.61129147\\tp=', '0.30181736')\n",
      "('Iteration=110\\tLoss=0.6112911\\tp=', '0.30175483')\n",
      "('Iteration=111\\tLoss=0.6112907\\tp=', '0.3016953')\n",
      "('Iteration=112\\tLoss=0.61129045\\tp=', '0.30163854')\n",
      "('Iteration=113\\tLoss=0.61129004\\tp=', '0.30158448')\n",
      "('Iteration=114\\tLoss=0.6112899\\tp=', '0.30153298')\n",
      "('Iteration=115\\tLoss=0.6112896\\tp=', '0.30148393')\n",
      "('Iteration=116\\tLoss=0.6112895\\tp=', '0.3014372')\n",
      "('Iteration=117\\tLoss=0.61128926\\tp=', '0.3013927')\n",
      "('Iteration=118\\tLoss=0.6112891\\tp=', '0.3013503')\n",
      "('Iteration=119\\tLoss=0.61128885\\tp=', '0.3013099')\n",
      "('Iteration=120\\tLoss=0.61128885\\tp=', '0.30127144')\n",
      "('Iteration=121\\tLoss=0.61128855\\tp=', '0.30123478')\n",
      "('Iteration=122\\tLoss=0.6112886\\tp=', '0.30119988')\n",
      "('Iteration=123\\tLoss=0.6112885\\tp=', '0.30116662')\n",
      "('Iteration=124\\tLoss=0.6112883\\tp=', '0.30113494')\n",
      "('Iteration=125\\tLoss=0.6112884\\tp=', '0.30110478')\n",
      "('Iteration=126\\tLoss=0.61128813\\tp=', '0.30107605')\n",
      "('Iteration=127\\tLoss=0.6112881\\tp=', '0.30104867')\n",
      "('Iteration=128\\tLoss=0.611288\\tp=', '0.3010226')\n",
      "('Iteration=129\\tLoss=0.611288\\tp=', '0.30099776')\n",
      "('Iteration=130\\tLoss=0.6112878\\tp=', '0.3009741')\n",
      "('Iteration=131\\tLoss=0.6112878\\tp=', '0.30095157')\n",
      "('Iteration=132\\tLoss=0.6112879\\tp=', '0.3009301')\n",
      "('Iteration=133\\tLoss=0.6112877\\tp=', '0.30090967')\n",
      "('Iteration=134\\tLoss=0.6112878\\tp=', '0.3008902')\n",
      "('Iteration=135\\tLoss=0.6112878\\tp=', '0.30087167')\n",
      "('Iteration=136\\tLoss=0.61128753\\tp=', '0.300854')\n",
      "('Iteration=137\\tLoss=0.6112878\\tp=', '0.30083716')\n",
      "('Iteration=138\\tLoss=0.6112877\\tp=', '0.30082113')\n",
      "('Iteration=139\\tLoss=0.61128753\\tp=', '0.30080587')\n",
      "('Iteration=140\\tLoss=0.6112875\\tp=', '0.30079132')\n",
      "('Iteration=141\\tLoss=0.6112876\\tp=', '0.30077747')\n",
      "('Iteration=142\\tLoss=0.6112875\\tp=', '0.30076426')\n",
      "('Iteration=143\\tLoss=0.6112876\\tp=', '0.3007517')\n",
      "('Iteration=144\\tLoss=0.6112876\\tp=', '0.3007397')\n",
      "('Iteration=145\\tLoss=0.6112875\\tp=', '0.3007283')\n",
      "('Iteration=146\\tLoss=0.6112875\\tp=', '0.30071744')\n",
      "('Iteration=147\\tLoss=0.6112874\\tp=', '0.3007071')\n",
      "('Iteration=148\\tLoss=0.6112875\\tp=', '0.30069727')\n",
      "('Iteration=149\\tLoss=0.61128753\\tp=', '0.30068788')\n",
      "('Iteration=150\\tLoss=0.6112874\\tp=', '0.30067894')\n",
      "('Iteration=151\\tLoss=0.6112875\\tp=', '0.30067042')\n",
      "('Iteration=152\\tLoss=0.6112874\\tp=', '0.3006623')\n",
      "('Iteration=153\\tLoss=0.6112875\\tp=', '0.3006546')\n",
      "('Iteration=154\\tLoss=0.6112874\\tp=', '0.30064723')\n",
      "('Iteration=155\\tLoss=0.61128736\\tp=', '0.30064023')\n",
      "('Iteration=156\\tLoss=0.61128724\\tp=', '0.30063355')\n",
      "('Iteration=157\\tLoss=0.6112874\\tp=', '0.3006272')\n",
      "('Iteration=158\\tLoss=0.6112874\\tp=', '0.30062115')\n",
      "('Iteration=159\\tLoss=0.6112875\\tp=', '0.3006154')\n",
      "('Iteration=160\\tLoss=0.6112874\\tp=', '0.30060992')\n",
      "('Iteration=161\\tLoss=0.6112875\\tp=', '0.3006047')\n",
      "('Iteration=162\\tLoss=0.61128736\\tp=', '0.30059972')\n",
      "('Iteration=163\\tLoss=0.6112873\\tp=', '0.300595')\n",
      "('Iteration=164\\tLoss=0.6112874\\tp=', '0.30059046')\n",
      "('Iteration=165\\tLoss=0.6112874\\tp=', '0.30058616')\n",
      "('Iteration=166\\tLoss=0.6112875\\tp=', '0.30058205')\n",
      "('Iteration=167\\tLoss=0.6112874\\tp=', '0.30057815')\n",
      "('Iteration=168\\tLoss=0.6112875\\tp=', '0.30057442')\n",
      "('Iteration=169\\tLoss=0.61128736\\tp=', '0.30057088')\n",
      "('Iteration=170\\tLoss=0.61128736\\tp=', '0.3005675')\n",
      "('Iteration=171\\tLoss=0.6112873\\tp=', '0.3005643')\n",
      "('Iteration=172\\tLoss=0.6112875\\tp=', '0.30056122')\n",
      "('Iteration=173\\tLoss=0.6112874\\tp=', '0.3005583')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration=174\\tLoss=0.6112876\\tp=', '0.30055553')\n",
      "('Iteration=175\\tLoss=0.6112875\\tp=', '0.30055287')\n",
      "('Iteration=176\\tLoss=0.6112875\\tp=', '0.30055037')\n",
      "('Iteration=177\\tLoss=0.6112874\\tp=', '0.300548')\n",
      "('Iteration=178\\tLoss=0.61128736\\tp=', '0.3005457')\n",
      "('Iteration=179\\tLoss=0.6112875\\tp=', '0.30054352')\n",
      "('Iteration=180\\tLoss=0.61128724\\tp=', '0.30054143')\n",
      "('Iteration=181\\tLoss=0.6112875\\tp=', '0.30053946')\n",
      "('Iteration=182\\tLoss=0.61128736\\tp=', '0.3005376')\n",
      "('Iteration=183\\tLoss=0.61128736\\tp=', '0.3005358')\n",
      "('Iteration=184\\tLoss=0.6112875\\tp=', '0.3005341')\n",
      "('Iteration=185\\tLoss=0.6112874\\tp=', '0.3005325')\n",
      "('Iteration=186\\tLoss=0.61128724\\tp=', '0.30053094')\n",
      "('Iteration=187\\tLoss=0.6112873\\tp=', '0.30052948')\n",
      "('Iteration=188\\tLoss=0.6112873\\tp=', '0.30052808')\n",
      "('Iteration=189\\tLoss=0.6112873\\tp=', '0.30052674')\n",
      "('Iteration=190\\tLoss=0.61128724\\tp=', '0.30052546')\n",
      "('Iteration=191\\tLoss=0.6112873\\tp=', '0.30052423')\n",
      "('Iteration=192\\tLoss=0.61128724\\tp=', '0.30052307')\n",
      "('Iteration=193\\tLoss=0.61128724\\tp=', '0.30052197')\n",
      "('Iteration=194\\tLoss=0.6112875\\tp=', '0.30052093')\n",
      "('Iteration=195\\tLoss=0.6112874\\tp=', '0.30051994')\n",
      "('Iteration=196\\tLoss=0.61128724\\tp=', '0.300519')\n",
      "('Iteration=197\\tLoss=0.6112874\\tp=', '0.3005181')\n",
      "('Iteration=198\\tLoss=0.6112874\\tp=', '0.30051723')\n",
      "('Iteration=199\\tLoss=0.6112873\\tp=', '0.30051643')\n",
      "('Iteration=200\\tLoss=0.6112874\\tp=', '0.30051565')\n",
      "('Iteration=201\\tLoss=0.6112873\\tp=', '0.3005149')\n",
      "('Iteration=202\\tLoss=0.6112875\\tp=', '0.3005142')\n",
      "('Iteration=203\\tLoss=0.61128736\\tp=', '0.3005135')\n",
      "('Iteration=204\\tLoss=0.6112875\\tp=', '0.30051285')\n",
      "('Iteration=205\\tLoss=0.61128724\\tp=', '0.30051222')\n",
      "('Iteration=206\\tLoss=0.6112874\\tp=', '0.30051166')\n",
      "('Iteration=207\\tLoss=0.6112873\\tp=', '0.3005111')\n",
      "('Iteration=208\\tLoss=0.6112874\\tp=', '0.30051056')\n",
      "('Iteration=209\\tLoss=0.6112875\\tp=', '0.30051005')\n",
      "('Iteration=210\\tLoss=0.61128736\\tp=', '0.30050957')\n",
      "('Iteration=211\\tLoss=0.6112874\\tp=', '0.30050912')\n",
      "('Iteration=212\\tLoss=0.6112874\\tp=', '0.30050868')\n",
      "('Iteration=213\\tLoss=0.6112873\\tp=', '0.30050826')\n",
      "('Iteration=214\\tLoss=0.6112874\\tp=', '0.30050787')\n",
      "('Iteration=215\\tLoss=0.6112874\\tp=', '0.3005075')\n",
      "('Iteration=216\\tLoss=0.61128736\\tp=', '0.30050713')\n",
      "('Iteration=217\\tLoss=0.61128736\\tp=', '0.3005068')\n",
      "('Iteration=218\\tLoss=0.6112874\\tp=', '0.30050647')\n",
      "('Iteration=219\\tLoss=0.6112875\\tp=', '0.30050617')\n",
      "('Iteration=220\\tLoss=0.6112873\\tp=', '0.30050588')\n",
      "('Iteration=221\\tLoss=0.6112874\\tp=', '0.3005056')\n",
      "('Iteration=222\\tLoss=0.6112874\\tp=', '0.30050534')\n",
      "('Iteration=223\\tLoss=0.6112875\\tp=', '0.30050507')\n",
      "('Iteration=224\\tLoss=0.6112875\\tp=', '0.30050483')\n",
      "('Iteration=225\\tLoss=0.61128724\\tp=', '0.3005046')\n",
      "('Iteration=226\\tLoss=0.6112874\\tp=', '0.3005044')\n",
      "('Iteration=227\\tLoss=0.6112873\\tp=', '0.30050418')\n",
      "('Iteration=228\\tLoss=0.6112874\\tp=', '0.30050397')\n",
      "('Iteration=229\\tLoss=0.6112874\\tp=', '0.3005038')\n",
      "('Iteration=230\\tLoss=0.6112875\\tp=', '0.3005036')\n",
      "('Iteration=231\\tLoss=0.6112874\\tp=', '0.30050343')\n",
      "('Iteration=232\\tLoss=0.6112873\\tp=', '0.30050328')\n",
      "('Iteration=233\\tLoss=0.61128736\\tp=', '0.30050313')\n",
      "('Iteration=234\\tLoss=0.6112873\\tp=', '0.300503')\n",
      "('Iteration=235\\tLoss=0.6112873\\tp=', '0.30050284')\n",
      "('Iteration=236\\tLoss=0.61128736\\tp=', '0.3005027')\n",
      "('Iteration=237\\tLoss=0.6112874\\tp=', '0.30050257')\n",
      "('Iteration=238\\tLoss=0.61128736\\tp=', '0.30050245')\n",
      "('Iteration=239\\tLoss=0.6112874\\tp=', '0.30050233')\n",
      "('Iteration=240\\tLoss=0.6112875\\tp=', '0.3005022')\n",
      "('Iteration=241\\tLoss=0.6112874\\tp=', '0.30050212')\n",
      "('Iteration=242\\tLoss=0.6112875\\tp=', '0.30050203')\n",
      "('Iteration=243\\tLoss=0.61128724\\tp=', '0.30050194')\n",
      "('Iteration=244\\tLoss=0.61128724\\tp=', '0.30050185')\n",
      "('Iteration=245\\tLoss=0.61128724\\tp=', '0.30050176')\n",
      "('Iteration=246\\tLoss=0.6112873\\tp=', '0.30050167')\n",
      "('Iteration=247\\tLoss=0.61128736\\tp=', '0.30050159')\n",
      "('Iteration=248\\tLoss=0.6112874\\tp=', '0.3005015')\n",
      "('Iteration=249\\tLoss=0.6112873\\tp=', '0.30050144')\n"
     ]
    }
   ],
   "source": [
    "## Simple gradient descent update\n",
    "p = 0.5\n",
    "step_size = 0.01\n",
    "\n",
    "l = []\n",
    "\n",
    "for i in jnp.arange(250):\n",
    "    current_loss = bern_loss(p, x)\n",
    "    l.append(current_loss)\n",
    "    print_string = \"Iteration=\" + str(i) + \"\\tLoss=\" + str(current_loss) + \"\\tp=\", str(p)\n",
    "    print(print_string)\n",
    "    p = p - step_size*grad_p(p, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suspected-mentor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='iter', ylabel='loss'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAa2klEQVR4nO3deXBd5Znn8e+je7XvkiUj2ZI3sEEOMYvZkpAAqSYswUxnQgIMTVd3qmhSTTqdmnQPqUwq+WcqPUO6p6kUS9wkaaY7HcIQUpAuGtNJWDpDgpHBODbCYIwXYWMt3mTZ1vrMH/fIFpcjWbHv8bm65/epct1733Ok+7wcl3+855z3PebuiIiIZCuKuwAREclPCggREQmlgBARkVAKCBERCaWAEBGRUOm4C8ilOXPm+MKFC+MuQ0Rk1li3bl2fuzeFbSuogFi4cCGdnZ1xlyEiMmuY2faptukUk4iIhFJAiIhIKAWEiIiEUkCIiEgoBYSIiIRSQIiISCgFhIiIhEp8QLg73/3lWzz/Zm/cpYiI5JXEB4SZsfo/tvLsGz1xlyIiklcSHxAAjZUl7B0cjrsMEZG8ooAAGqtK6R8cirsMEZG8ooAAGipL6D+kEYSIyGQKCGBOVQn9OsUkIvI+CgigsbKUvYPDjI973KWIiOQNBQSZU0xj487BoyNxlyIikjcUEEBjVQkAfboOISJyjAKCzCkmgP5DupNJRGSCAoLjIwjNhRAROU4BwaRTTAoIEZFjFBBAfUUwgtA1CBGRYxQQQHGqiLqKYs2mFhGZRAER0GxqEZH3U0AE5lRqPSYRkckUEIHGKo0gREQmU0AEGrTkt4jI+yggAo1Vpew9PMyY1mMSEQEUEMc0VpbgDvsOaxQhIgIKiGM0m1pE5P0UEIGJ9Zj6tB6TiAiggDhGIwgRkfdTQAQaKzMBoVtdRUQyFBCBuooSzLTkt4jIBAVEIFVkNFTo2dQiIhMUEJNoNrWIyHEKiEk0m1pE5DgFxCSNVaX0acE+ERFAAfE+jVryW0TkmEgDwsyuMbPNZrbFzO6eYp8rzGy9mW0ys+cntX8laNtoZj82s7IoawWYU1XKgSMjDI+OR/1VIiJ5L7KAMLMUcB9wLdAB3GJmHVn71AH3A6vcfTlwU9A+D/gLYKW7fwhIATdHVeuE5urMbOpe3eoqIhLpCOJiYIu7b3X3YeAR4MasfW4FHnf3HQDu3jNpWxooN7M0UAHsirBWAJprMgHRc/Bo1F8lIpL3ogyIecDOSZ+7g7bJlgL1Zvacma0zs9sB3P1d4DvADmA3cMDdnwn7EjO7w8w6zayzt7f3lApurs6cxdpzUCMIEZEoA8JC2rIftpAGLgSuBz4FfMPMlppZPZnRxiKgFag0s9vCvsTdV7v7Sndf2dTUdEoFT4wgegc0ghARSUf4u7uBtkmf5/PB00TdQJ+7DwKDZvYCsCLY9o679wKY2ePAR4B/jrBeGitLKTKNIEREINoRxMvAWWa2yMxKyFxkfjJrnyeAy80sbWYVwCVAF5lTS5eaWYWZGfDJoD1SqSKjqbqUHo0gRESiG0G4+6iZ3QWsIXMX0g/cfZOZ3Rlsf9Ddu8zsaWADMA485O4bAczsMeAVYBR4FVgdVa2TNVeX0TOgEYSISJSnmHD3p4CnstoezPp8D3BPyM9+E/hmlPWFaa4uZdcBjSBERDSTOktzTZkuUouIoID4gObqUvoODTMyptnUIpJsCogsc2sycyH0bGoRSToFRJaJ5TZ6dKuriCScAiLLxGS5PVpuQ0QSTgGRZeIUk251FZGkU0BkaawswUwBISKigMiSThXRWFmqFV1FJPEUECHm1pRqBCEiiaeACNFcXaqL1CKSeAqIEFqPSUREARFqbk0p/YeGGNVsahFJMAVEiKaaMsYd+geH4y5FRCQ2CogQmk0tIqKACHV8spwuVItIcikgQkyMIPToURFJMgVEiKbqzLOp3ztwJO5SRERio4AIUZwqYm5NGe/u1ykmEUkuBcQUWmrL2K0RhIgkmAJiCq115ezar4AQkeRSQEyhta6cXQeO4u5xlyIiEgsFxBRaa8sYHh3XZDkRSSwFxBRa68oBdJpJRBJLATEFBYSIJJ0CYgrHA0K3uopIMikgplBfUUxZcZFGECKSWAqIKZgZrbXl7D6gEYSIJJMCYhqtdeW8qxGEiCSUAmIarXVlOsUkIomlgJhGS205vYeGGB7Vk+VEJHkUENOYV1eOO+w5qOsQIpI8CohpTNzqqusQIpJECohptNRlniynVV1FJIkUENNordVkORFJLgXENMpLUjRUlugUk4gkkgLiBFpqy9itgBCRBFJAnIAmy4lIUikgTmB+fTnd+47owUEikjgKiBNob6jg8PCYHhwkIokTaUCY2TVmttnMtpjZ3VPsc4WZrTezTWb2/KT2OjN7zMzeMLMuM7ssylqnsqCxAoDt/Yfj+HoRkdhEFhBmlgLuA64FOoBbzKwja5864H5glbsvB26atPle4Gl3PxtYAXRFVet02hsqAdixdzCOrxcRiU2UI4iLgS3uvtXdh4FHgBuz9rkVeNzddwC4ew+AmdUAHwe+H7QPu/v+CGud0vz6csxgR78uVItIskQZEPOAnZM+dwdtky0F6s3sOTNbZ2a3B+2LgV7gh2b2qpk9ZGaVYV9iZneYWaeZdfb29ua6D5QVpzijpoztGkGISMJEGRAW0pZ9K1AauBC4HvgU8A0zWxq0XwA84O7nA4NA6DUMd1/t7ivdfWVTU1POip+svaGCHboGISIJE2VAdANtkz7PB3aF7PO0uw+6ex/wApnrDd1At7u/FOz3GJnAiEV7QwU79iogRCRZogyIl4GzzGyRmZUANwNPZu3zBHC5maXNrAK4BOhy9/eAnWa2LNjvk8DrEdY6rQWNFfQMDHFkeCyuEkRETrt0VL/Y3UfN7C5gDZACfuDum8zszmD7g+7eZWZPAxuAceAhd98Y/IovAT8KwmUr8CdR1Xoi7Y0TdzIdZtkZ1XGVISJyWkUWEADu/hTwVFbbg1mf7wHuCfnZ9cDKKOubqfaGzFwIBYSIJIlmUs/AgoaJyXK6k0lEkkMBMQN1FcVUl6V1oVpEEkUBMQNmpjuZRCRxFBAztKBRcyFEJFkUEDPU3lDJzn2HGRvXst8ikgwKiBlqb6hgZMx576CeTy0iyaCAmKHjy37rTiYRSYYZBYSZfdnMaizj+2b2ipldHXVx+WThnMxkuXf6FBAikgwzHUH8qbsfBK4GmsjMav6byKrKQy01ZZQXp9jScyjuUkRETouZBsTEyqzXAT9099cIX621YBUVGUuaK3m7VyMIEUmGmQbEOjN7hkxArDGzajJrJyXKkqYq3tYIQkQSYqYB8QUyz2O4yN0PA8XEuHheXM5squLd/Uc4PDwadykiIpGbaUBcBmx29/1mdhvw34ED0ZWVn5Y0VwGwVaeZRCQBZhoQDwCHzWwF8NfAduD/RFZVnjozCIi3e3WaSUQK30wDYtTdHbgRuNfd7wUSt+71gsYKigzdySQiiTDT50EMmNnXgD8i8wS4FJnrEIlSmk6xoLFSIwgRSYSZjiA+DwyRmQ/xHjCPkIf8JMGSpkqNIEQkEWYUEEEo/AioNbNPA0fdPXHXICBzoXpb32FGxxJ3l6+IJMxMl9r4HLAWuAn4HPCSmX02ysLy1ZKmKobHxtm570jcpYiIRGqm1yC+TmYORA+AmTUBvwAei6qwfHXsTqaeQywK1mcSESlEM70GUTQRDoH+3+NnC8qSpkxAbNGFahEpcDMdQTxtZmuAHwefPw88FU1J+a22vJim6lItuSEiBW9GAeHuf2Vm/xn4KJlF+la7+88irSyPndlUxZsKCBEpcDMdQeDuPwV+GmEts8ayM6r5ycs7GRt3UkWJWtRWRBJk2oAwswEg7CHMBri710RSVZ7raK3hyMgY2/sHWRxckxARKTTTBoS7J245jZnoaMnkYtfuAQWEiBSsRN6JdKrObK4iVWS8vjtxC9qKSIIoIE5CWXGKJU2VdO0eiLsUEZHIKCBOUkdLDV27D8ZdhohIZBQQJ+mclhp2HzjK/sPDcZciIhIJBcRJOie4UP26RhEiUqAUECfpnEl3MomIFCIFxElqqi5lTlUpr+/SCEJECpMC4hR0tOpCtYgULgXEKTinpZotPYcY0cODRKQAKSBOQUdLDcNj43oEqYgUJAXEKTh3Xi0AG7r3x1uIiEgEFBCnYNGcSmrLi1m/c3/cpYiI5JwC4hSYGSva6nh1x/64SxERyblIA8LMrjGzzWa2xczunmKfK8xsvZltMrPns7alzOxVM/vXKOs8Fee11fHmngEGh0bjLkVEJKciCwgzSwH3AdcCHcAtZtaRtU8dcD+wyt2XAzdl/ZovA11R1ZgL57fVMe6woVsru4pIYYlyBHExsMXdt7r7MPAIcGPWPrcCj7v7DgB375nYYGbzgeuBhyKs8ZStaKsD0HUIESk4UQbEPGDnpM/dQdtkS4F6M3vOzNaZ2e2Ttv098NdAXk8yaKgsYUFjBet37ou7FBGRnJrxM6lPQtjDmrMfX5oGLgQ+CZQDvzGz35IJjh53X2dmV0z7JWZ3AHcAtLe3n2LJJ+f8tjp+s7U/lu8WEYlKlCOIbqBt0uf5wK6QfZ5290F37wNeAFYAHwVWmdk2MqemrjKzfw77Endf7e4r3X1lU1NTrvswI+e11bHn4BC7DxyJ5ftFRKIQZUC8DJxlZovMrAS4GXgya58ngMvNLG1mFcAlQJe7f83d57v7wuDnfuXut0VY6yk5r70egPW63VVECkhkAeHuo8BdwBoydyI96u6bzOxOM7sz2KcLeBrYAKwFHnL3jVHVFJVzWqopSRXxqi5Ui0gBifIaBO7+FPBUVtuDWZ/vAe6Z5nc8BzwXQXk5U5pO8aF5NXRu2xt3KSIiOaOZ1Dly6eJGNnQf0IQ5ESkYCogcuWxJI6PjTud23e4qIoVBAZEjFy6oJ11k/Fa3u4pIgVBA5EhFSZoVbXUKCBEpGAqIHLp0cQMbug9wSNchRKQAKCBy6LLFcxgbd93NJCIFQQGRQxcsqKM4Zfx2qwJCRGY/BUQOVZSkWTFf6zKJSGFQQOTYpYsb2fjuAQaOjsRdiojIKVFA5NjHzspch/j1W31xlyIickoUEDl24YJ6asrS/OqNnhPvLCKSxxQQOVacKuLjS5t4dnMv4+PZj78QEZk9FBARuOrsZvoODbFxl55TLSKzlwIiAp9Y2oQZOs0kIrOaAiICjVWlnNdWp4AQkVlNARGRq5Y1s6H7AD0DR+MuRUTkpCggInLVOc0APLe5N+ZKREROjgIiIh0tNbTWlrFm43txlyIiclIUEBExM67/cAsvvNXLgcOaVS0is48CIkI3rGhlZMxZs0mjCBGZfRQQETp3Xi3tDRX8fMOuuEsREfm9KSAiZGbcsKKFF9/up+/QUNzliIj8XhQQEbthRStj486/6WK1iMwyCoiILZtbzZnNVfz8NZ1mEpHZRQERMTNj1YpW1r6zlx39h+MuR0RkxhQQp8FNK+dTZPDIyzviLkVEZMYUEKdBS205V509l0c7uxkZG4+7HBGRGVFAnCa3XtJG36Eh/v31PXGXIiIyIwqI0+QTS5uZV1fOv7yk00wiMjsoIE6TVJHx+Yva+PWWPrb3D8ZdjojICSkgTqPPX9RGusj4xxe3xV2KiMgJKSBOo7k1Zaw6r5VH1u5k7+Bw3OWIiExLAXGaffETSzgyMqZRhIjkPQXEaXbW3Gr+oGMuD7+4jcGh0bjLERGZkgIiBl+8YgkHjozw47W6o0lE8pcCIgYXtNdz6eIGVr+wlcPDGkWISH5SQMTkq1cvo2dgiIf+4524SxERCaWAiMnKhQ1cs/wMHnz+bXoGjsZdjojIByggYvTfrj2b4dFx/v4Xb8VdiojIByggYrRoTiW3XbqAR9buYPN7A3GXIyLyPpEGhJldY2abzWyLmd09xT5XmNl6M9tkZs8HbW1m9qyZdQXtX46yzjj9xSfPora8mLsf38DYuMddjojIMZEFhJmlgPuAa4EO4BYz68japw64H1jl7suBm4JNo8B/dfdzgEuBP8/+2ULRUFnCN29Yzqs79mvynIjklShHEBcDW9x9q7sPA48AN2btcyvwuLvvAHD3nuB1t7u/ErwfALqAeRHWGqsbz2vlymVNfGfNZj11TkTyRpQBMQ/YOelzNx/8R34pUG9mz5nZOjO7PfuXmNlC4HzgpbAvMbM7zKzTzDp7e3tzU/lpZmb8jz88l1SR8VePvcaoHiokInkgyoCwkLbsk+xp4ELgeuBTwDfMbOmxX2BWBfwU+Et3Pxj2Je6+2t1XuvvKpqam3FQeg9a6cr61ajkvvbOX//2LN+MuR0Qk0oDoBtomfZ4P7ArZ52l3H3T3PuAFYAWAmRWTCYcfufvjEdaZNz574XxuvqiN+559m1+9oSfPiUi8ogyIl4GzzGyRmZUANwNPZu3zBHC5maXNrAK4BOgyMwO+D3S5+99FWGPe+daq5XS01PCVn7zGtj49WEhE4hNZQLj7KHAXsIbMReZH3X2Tmd1pZncG+3QBTwMbgLXAQ+6+Efgo8EfAVcEtsOvN7Lqoas0nZcUpHrjtAooMbv/BWs2yFpHYmHvh3Hu/cuVK7+zsjLuMnHh1xz5u/YeXWDSnkp/82aVUlxXHXZKIFCAzW+fuK8O2aSZ1njq/vZ77b7uAN/cM8Cc/fJmDR0fiLklEEkYBkceuXNbMvTefz2vd+7ll9W/pOzQUd0kikiAKiDx3/YdbWH37St7uPcTnvvcb3tGFaxE5TRQQs8CVy5r5py9cwr7BYVZ999f8sku3wIpI9BQQs8RFCxv4+Zc+xoI5FXzh4U6+/W9dHB0Zi7ssESlgCohZZH59BY/d+RFuubid7z2/lU9/99e8umNf3GWJSIFSQMwyZcUpvv2Zc3n4Ty9mcGiUzzzwIl/9v6+x56DmS4hIbikgZqlPLG1izVc+zh2XL+bJ9bu44p7n+PZTXfQoKEQkRzRRrgDs6D/Md57ZzL9u2EU6VcRnzp/Hf7lkAefOr427NBHJc9NNlFNAFJBtfYN874Wt/OzVbo6OjLO8tYYbVrRyzfIzWDinMu7yRCQPKSAS5sCREZ5c/y6Pdnbzu3cPAHD2GdX8QcdcLl3cyAXt9ZSXpGKuUkTygQIiwbr3HWbNpj2s2fgendv3Mu6QLjI+PL+W89vr6WipoaO1hiVNVZSkdUlKJGkUEALAwaMjrNu+j7Xv7OWlrf1s2nWQodHM0+uKU8b8+graGypY0Jh5bWuooLm6lDlVpTRVl1JWrFGHSKGZLiDSp7sYiU9NWTFXLmvmymXNAIyOjbOtf5DXdw/wxu6DbO8/zPa9g7yyYx8DR0c/8PNVpWnmVJUwp6qUmvJiqkrTVJamqS5LU1Ua/ClLU16coiRdRGm66NhraTrTVpLKtJWki0gXGUVFRsqMVJFRdOw18xhWEYmXAiLB0qkizmyu5szmalataD3W7u7sPzzCzn2H6R0You/QEH2HhukdGKJ/cJi+gSF6B4Z4p2+QgaOjHBoa4ehIbp+jbQYpyw4QjgXJ8fw4/t4m/awFnyZvyw6dY9tOsP+krwp9jq6cPP2PQG40VJTw6J2X5fz3KiDkA8yM+soS6itLZvwzo2PjDA6NcfDoCEOjYxwdGWd4bJzh0XGGRjOvmfdjx9rGxp1xd8bGnTF3xsedsXEY9xO3Q+YB58fPkAZtfrzNJ7dN7JW1jfdt++DvnbytcE7G5gn9B82Z6rJo/ilXQEhOpFNF1FYUUVuhBxuJFArdtiIiIqEUECIiEkoBISIioRQQIiISSgEhIiKhFBAiIhJKASEiIqEUECIiEqqgFuszs15g+0n++BygL4flzAbqczKoz8lwsn1e4O5NYRsKKiBOhZl1TrWiYaFSn5NBfU6GKPqsU0wiIhJKASEiIqEUEMetjruAGKjPyaA+J0PO+6xrECIiEkojCBERCaWAEBGRUIkPCDO7xsw2m9kWM7s77nqiYmbbzOx3ZrbezDqDtgYz+3czeyt4rY+7zlNlZj8wsx4z2zipbcp+mtnXgmO/2cw+FU/Vp2aKPn/LzN4Njvd6M7tu0rZZ3WczazOzZ82sy8w2mdmXg/ZCP85T9Tu6Y+3uif0DpIC3gcVACfAa0BF3XRH1dRswJ6vtfwF3B+/vBv5n3HXmoJ8fBy4ANp6on0BHcMxLgUXB34VU3H3IUZ+/BXw1ZN9Z32egBbggeF8NvBn0q9CP81T9juxYJ30EcTGwxd23uvsw8AhwY8w1nU43Ag8H7x8G/lN8peSGu78A7M1qnqqfNwKPuPuQu78DbCHzd2JWmaLPU5n1fXb33e7+SvB+AOgC5lH4x3mqfk/llPud9ICYB+yc9Lmb6f+Dz2YOPGNm68zsjqBtrrvvhsxfPqA5tuqiNVU/C/3432VmG4JTUBOnWwqqz2a2EDgfeIkEHeesfkNExzrpAWEhbYV63+9H3f0C4Frgz83s43EXlAcK+fg/ACwBzgN2A38btBdMn82sCvgp8JfufnC6XUPaZmWfIbTfkR3rpAdEN9A26fN8YFdMtUTK3XcFrz3Az8gMNfeYWQtA8NoTX4WRmqqfBXv83X2Pu4+5+zjwDxw/tVAQfTazYjL/SP7I3R8Pmgv+OIf1O8pjnfSAeBk4y8wWmVkJcDPwZMw15ZyZVZpZ9cR74GpgI5m+/nGw2x8DT8RTYeSm6ueTwM1mVmpmi4CzgLUx1JdzE/9QBv6QzPGGAuizmRnwfaDL3f9u0qaCPs5T9TvSYx33lfm4/wDXkbkb4G3g63HXE1EfF5O5m+E1YNNEP4FG4JfAW8FrQ9y15qCvPyYzzB4h839QX5iun8DXg2O/Gbg27vpz2Od/An4HbAj+oWgplD4DHyNzqmQDsD74c10CjvNU/Y7sWGupDRERCZX0U0wiIjIFBYSIiIRSQIiISCgFhIiIhFJAiIhIKAWESA6Y2YvB60IzuzXuekRyQQEhkgPu/pHg7ULg9woIM0vlvCCRHFBAiOSAmR0K3v4NcHmwLv9XzCxlZveY2cvBYmp/Fux/RbC2/7+QmeQkknfScRcgUmDuJrM2/6cBgpVzD7j7RWZWCvw/M3sm2Pdi4EOeWYpZJO8oIESidTXwYTP7bPC5lsyaOMPAWoWD5DMFhEi0DPiSu695X6PZFcBgHAWJzJSuQYjk1gCZx0FOWAN8MVimGTNbGqyoK5L3NIIQya0NwKiZvQb8I3AvmTubXgmWa+6lAB7tKsmg1VxFRCSUTjGJiEgoBYSIiIRSQIiISCgFhIiIhFJAiIhIKAWEiIiEUkCIiEio/w9cbV8r9+dwyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot loss as function of iteration history\n",
    "df = pd.DataFrame({'iter':jnp.arange(len(l)), 'loss':jnp.array(l)})\n",
    "sns.lineplot(data=df, x='iter', y='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-cherry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-excitement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-family",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-strand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-million",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "moderate-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################\n",
    "## Poisson distirbution\n",
    "############################\n",
    "x = jax.random.poisson(key, lam=3.0, shape=(10000,))\n",
    "pd.Series(x).value_counts(normalize=True).sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cosmetic-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple loss function (scalar parm = p; vector input data = x)\n",
    "def pois_loss(mu, x):\n",
    "    return -jnp.mean(jax.scipy.stats.poisson.logpmf(k=x, mu=mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "clinical-marble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fd1a8411090>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Log Likelihood as a Function of Parameter (mu)\n",
    "support = jnp.linspace(0.01,15,1000)\n",
    "log_lik = jnp.array([pois_loss(mu=mu,x=x) for mu in support])\n",
    "\n",
    "df = pd.DataFrame({'x':support, 'y':log_lik})\n",
    "plt = sns.lineplot(data=df, x='x', y='y')\n",
    "plt.axvline(3.0, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fundamental-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient of loss function\n",
    "grad_mu = grad(pois_loss, argnums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "advised-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get gradient for each value of support\n",
    "grad_support = jnp.array([grad_mu(mu,x) for mu in support])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "potential-confusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2.995996</td>\n",
       "      <td>1.938973</td>\n",
       "      <td>-0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3.011001</td>\n",
       "      <td>1.939008</td>\n",
       "      <td>0.004850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2.980991</td>\n",
       "      <td>1.939013</td>\n",
       "      <td>-0.005169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>3.026006</td>\n",
       "      <td>1.939119</td>\n",
       "      <td>0.009784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2.965986</td>\n",
       "      <td>1.939129</td>\n",
       "      <td>-0.010254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y      grad\n",
       "199  2.995996  1.938973 -0.000135\n",
       "200  3.011001  1.939008  0.004850\n",
       "198  2.980991  1.939013 -0.005169\n",
       "201  3.026006  1.939119  0.009784\n",
       "197  2.965986  1.939129 -0.010254"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## See what gradient is at minimizer (and what min value is)\n",
    "df[['grad']] = grad_support\n",
    "\n",
    "## Find minimizer\n",
    "df = df.sort_values(by=['y'])\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "compliant-sigma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration=0\\t Loss=4.807803\\t mu=', '0.5')\n",
      "('Iteration=1\\t Loss=4.264859\\t mu=', '0.62482')\n",
      "('Iteration=2\\t Loss=3.936102\\t mu=', '0.7197105')\n",
      "('Iteration=3\\t Loss=3.7027993\\t mu=', '0.79879403')\n",
      "('Iteration=4\\t Loss=3.5240862\\t mu=', '0.8675729')\n",
      "('Iteration=5\\t Loss=3.3807163\\t mu=', '0.9289172')\n",
      "('Iteration=6\\t Loss=3.262044\\t mu=', '0.9845595')\n",
      "('Iteration=7\\t Loss=3.1615562\\t mu=', '1.0356443')\n",
      "('Iteration=8\\t Loss=3.0749817\\t mu=', '1.0829761')\n",
      "('Iteration=9\\t Loss=2.999367\\t mu=', '1.1271466')\n",
      "('Iteration=10\\t Loss=2.9325886\\t mu=', '1.1686064')\n",
      "('Iteration=11\\t Loss=2.8730712\\t mu=', '1.2077084')\n",
      "('Iteration=12\\t Loss=2.819613\\t mu=', '1.2447349')\n",
      "('Iteration=13\\t Loss=2.7712781\\t mu=', '1.2799164')\n",
      "('Iteration=14\\t Loss=2.7273257\\t mu=', '1.3134437')\n",
      "('Iteration=15\\t Loss=2.687157\\t mu=', '1.345477')\n",
      "('Iteration=16\\t Loss=2.6502848\\t mu=', '1.3761524')\n",
      "('Iteration=17\\t Loss=2.616305\\t mu=', '1.4055867')\n",
      "('Iteration=18\\t Loss=2.5848808\\t mu=', '1.4338812')\n",
      "('Iteration=19\\t Loss=2.555728\\t mu=', '1.461124')\n",
      "('Iteration=20\\t Loss=2.528605\\t mu=', '1.4873927')\n",
      "('Iteration=21\\t Loss=2.503304\\t mu=', '1.512756')\n",
      "('Iteration=22\\t Loss=2.4796467\\t mu=', '1.5372748')\n",
      "('Iteration=23\\t Loss=2.457477\\t mu=', '1.5610039')\n",
      "('Iteration=24\\t Loss=2.43666\\t mu=', '1.5839922')\n",
      "('Iteration=25\\t Loss=2.4170768\\t mu=', '1.6062841')\n",
      "('Iteration=26\\t Loss=2.3986228\\t mu=', '1.6279197')\n",
      "('Iteration=27\\t Loss=2.3812034\\t mu=', '1.6489354')\n",
      "('Iteration=28\\t Loss=2.3647373\\t mu=', '1.6693647')\n",
      "('Iteration=29\\t Loss=2.3491504\\t mu=', '1.6892381')\n",
      "('Iteration=30\\t Loss=2.334375\\t mu=', '1.7085835')\n",
      "('Iteration=31\\t Loss=2.320353\\t mu=', '1.7274268')\n",
      "('Iteration=32\\t Loss=2.3070307\\t mu=', '1.7457918')\n",
      "('Iteration=33\\t Loss=2.2943578\\t mu=', '1.7637007')\n",
      "('Iteration=34\\t Loss=2.2822917\\t mu=', '1.781174')\n",
      "('Iteration=35\\t Loss=2.270791\\t mu=', '1.7982305')\n",
      "('Iteration=36\\t Loss=2.2598195\\t mu=', '1.8148881')\n",
      "('Iteration=37\\t Loss=2.2493436\\t mu=', '1.8311634')\n",
      "('Iteration=38\\t Loss=2.2393332\\t mu=', '1.8470718')\n",
      "('Iteration=39\\t Loss=2.2297595\\t mu=', '1.8626279')\n",
      "('Iteration=40\\t Loss=2.220596\\t mu=', '1.8778453')\n",
      "('Iteration=41\\t Loss=2.2118196\\t mu=', '1.8927368')\n",
      "('Iteration=42\\t Loss=2.203408\\t mu=', '1.9073144')\n",
      "('Iteration=43\\t Loss=2.19534\\t mu=', '1.9215895')\n",
      "('Iteration=44\\t Loss=2.1875978\\t mu=', '1.9355729')\n",
      "('Iteration=45\\t Loss=2.1801627\\t mu=', '1.9492745')\n",
      "('Iteration=46\\t Loss=2.1730196\\t mu=', '1.9627042')\n",
      "('Iteration=47\\t Loss=2.166152\\t mu=', '1.975871')\n",
      "('Iteration=48\\t Loss=2.1595464\\t mu=', '1.9887834')\n",
      "('Iteration=49\\t Loss=2.1531897\\t mu=', '2.0014496')\n",
      "('Iteration=50\\t Loss=2.1470692\\t mu=', '2.0138774')\n",
      "('Iteration=51\\t Loss=2.1411736\\t mu=', '2.0260742')\n",
      "('Iteration=52\\t Loss=2.1354914\\t mu=', '2.038047')\n",
      "('Iteration=53\\t Loss=2.1300132\\t mu=', '2.0498028')\n",
      "('Iteration=54\\t Loss=2.1247292\\t mu=', '2.0613477')\n",
      "('Iteration=55\\t Loss=2.1196303\\t mu=', '2.072688')\n",
      "('Iteration=56\\t Loss=2.1147077\\t mu=', '2.0838296')\n",
      "('Iteration=57\\t Loss=2.1099546\\t mu=', '2.0947778')\n",
      "('Iteration=58\\t Loss=2.1053624\\t mu=', '2.1055381')\n",
      "('Iteration=59\\t Loss=2.1009252\\t mu=', '2.1161158')\n",
      "('Iteration=60\\t Loss=2.0966344\\t mu=', '2.1265156')\n",
      "('Iteration=61\\t Loss=2.0924861\\t mu=', '2.1367424')\n",
      "('Iteration=62\\t Loss=2.0884724\\t mu=', '2.1468003')\n",
      "('Iteration=63\\t Loss=2.0845888\\t mu=', '2.1566942')\n",
      "('Iteration=64\\t Loss=2.0808294\\t mu=', '2.1664279')\n",
      "('Iteration=65\\t Loss=2.077189\\t mu=', '2.1760056')\n",
      "('Iteration=66\\t Loss=2.0736637\\t mu=', '2.185431')\n",
      "('Iteration=67\\t Loss=2.0702481\\t mu=', '2.1947079')\n",
      "('Iteration=68\\t Loss=2.0669382\\t mu=', '2.20384')\n",
      "('Iteration=69\\t Loss=2.0637298\\t mu=', '2.2128308')\n",
      "('Iteration=70\\t Loss=2.0606189\\t mu=', '2.2216833')\n",
      "('Iteration=71\\t Loss=2.057602\\t mu=', '2.230401')\n",
      "('Iteration=72\\t Loss=2.0546753\\t mu=', '2.238987')\n",
      "('Iteration=73\\t Loss=2.051836\\t mu=', '2.2474442')\n",
      "('Iteration=74\\t Loss=2.0490801\\t mu=', '2.2557755')\n",
      "('Iteration=75\\t Loss=2.0464046\\t mu=', '2.2639835')\n",
      "('Iteration=76\\t Loss=2.0438073\\t mu=', '2.2720711')\n",
      "('Iteration=77\\t Loss=2.041285\\t mu=', '2.280041')\n",
      "('Iteration=78\\t Loss=2.038835\\t mu=', '2.2878957')\n",
      "('Iteration=79\\t Loss=2.0364544\\t mu=', '2.2956376')\n",
      "('Iteration=80\\t Loss=2.0341415\\t mu=', '2.3032691')\n",
      "('Iteration=81\\t Loss=2.0318935\\t mu=', '2.3107924')\n",
      "('Iteration=82\\t Loss=2.0297081\\t mu=', '2.31821')\n",
      "('Iteration=83\\t Loss=2.0275834\\t mu=', '2.3255236')\n",
      "('Iteration=84\\t Loss=2.0255175\\t mu=', '2.3327358')\n",
      "('Iteration=85\\t Loss=2.0235074\\t mu=', '2.3398483')\n",
      "('Iteration=86\\t Loss=2.0215526\\t mu=', '2.3468633')\n",
      "('Iteration=87\\t Loss=2.0196507\\t mu=', '2.3537824')\n",
      "('Iteration=88\\t Loss=2.0178\\t mu=', '2.3606079')\n",
      "('Iteration=89\\t Loss=2.0159984\\t mu=', '2.3673413')\n",
      "('Iteration=90\\t Loss=2.014245\\t mu=', '2.3739843')\n",
      "('Iteration=91\\t Loss=2.0125377\\t mu=', '2.380539')\n",
      "('Iteration=92\\t Loss=2.0108757\\t mu=', '2.3870065')\n",
      "('Iteration=93\\t Loss=2.009257\\t mu=', '2.393389')\n",
      "('Iteration=94\\t Loss=2.0076807\\t mu=', '2.3996878')\n",
      "('Iteration=95\\t Loss=2.0061448\\t mu=', '2.4059043')\n",
      "('Iteration=96\\t Loss=2.0046484\\t mu=', '2.4120402')\n",
      "('Iteration=97\\t Loss=2.0031905\\t mu=', '2.418097')\n",
      "('Iteration=98\\t Loss=2.0017698\\t mu=', '2.4240758')\n",
      "('Iteration=99\\t Loss=2.000385\\t mu=', '2.4299784')\n",
      "('Iteration=100\\t Loss=1.999035\\t mu=', '2.4358058')\n",
      "('Iteration=101\\t Loss=1.9977192\\t mu=', '2.4415596')\n",
      "('Iteration=102\\t Loss=1.9964367\\t mu=', '2.4472408')\n",
      "('Iteration=103\\t Loss=1.9951854\\t mu=', '2.4528508')\n",
      "('Iteration=104\\t Loss=1.9939654\\t mu=', '2.4583907')\n",
      "('Iteration=105\\t Loss=1.9927754\\t mu=', '2.463862')\n",
      "('Iteration=106\\t Loss=1.9916148\\t mu=', '2.4692655')\n",
      "('Iteration=107\\t Loss=1.9904824\\t mu=', '2.4746025')\n",
      "('Iteration=108\\t Loss=1.9893777\\t mu=', '2.479874')\n",
      "('Iteration=109\\t Loss=1.9882996\\t mu=', '2.485081')\n",
      "('Iteration=110\\t Loss=1.9872477\\t mu=', '2.4902248')\n",
      "('Iteration=111\\t Loss=1.986221\\t mu=', '2.4953065')\n",
      "('Iteration=112\\t Loss=1.985219\\t mu=', '2.5003269')\n",
      "('Iteration=113\\t Loss=1.9842407\\t mu=', '2.505287')\n",
      "('Iteration=114\\t Loss=1.9832858\\t mu=', '2.5101876')\n",
      "('Iteration=115\\t Loss=1.9823533\\t mu=', '2.51503')\n",
      "('Iteration=116\\t Loss=1.9814428\\t mu=', '2.5198147')\n",
      "('Iteration=117\\t Loss=1.9805539\\t mu=', '2.524543')\n",
      "('Iteration=118\\t Loss=1.9796855\\t mu=', '2.5292158')\n",
      "('Iteration=119\\t Loss=1.9788377\\t mu=', '2.5338337')\n",
      "('Iteration=120\\t Loss=1.9780093\\t mu=', '2.5383976')\n",
      "('Iteration=121\\t Loss=1.9772002\\t mu=', '2.5429082')\n",
      "('Iteration=122\\t Loss=1.9764096\\t mu=', '2.5473666')\n",
      "('Iteration=123\\t Loss=1.9756376\\t mu=', '2.5517735')\n",
      "('Iteration=124\\t Loss=1.9748826\\t mu=', '2.5561297')\n",
      "('Iteration=125\\t Loss=1.9741453\\t mu=', '2.5604358')\n",
      "('Iteration=126\\t Loss=1.9734244\\t mu=', '2.5646925')\n",
      "('Iteration=127\\t Loss=1.9727205\\t mu=', '2.5689006')\n",
      "('Iteration=128\\t Loss=1.9720318\\t mu=', '2.573061')\n",
      "('Iteration=129\\t Loss=1.9713588\\t mu=', '2.5771742')\n",
      "('Iteration=130\\t Loss=1.9707013\\t mu=', '2.581241')\n",
      "('Iteration=131\\t Loss=1.970058\\t mu=', '2.5852618')\n",
      "('Iteration=132\\t Loss=1.9694293\\t mu=', '2.5892377')\n",
      "('Iteration=133\\t Loss=1.9688148\\t mu=', '2.593169')\n",
      "('Iteration=134\\t Loss=1.9682134\\t mu=', '2.5970564')\n",
      "('Iteration=135\\t Loss=1.9676256\\t mu=', '2.6009007')\n",
      "('Iteration=136\\t Loss=1.9670508\\t mu=', '2.6047022')\n",
      "('Iteration=137\\t Loss=1.9664885\\t mu=', '2.6084619')\n",
      "('Iteration=138\\t Loss=1.9659384\\t mu=', '2.61218')\n",
      "('Iteration=139\\t Loss=1.9654008\\t mu=', '2.6158571')\n",
      "('Iteration=140\\t Loss=1.9648749\\t mu=', '2.619494')\n",
      "('Iteration=141\\t Loss=1.9643598\\t mu=', '2.623091')\n",
      "('Iteration=142\\t Loss=1.9638561\\t mu=', '2.626649')\n",
      "('Iteration=143\\t Loss=1.9633635\\t mu=', '2.6301682')\n",
      "('Iteration=144\\t Loss=1.9628814\\t mu=', '2.6336493')\n",
      "('Iteration=145\\t Loss=1.9624096\\t mu=', '2.6370928')\n",
      "('Iteration=146\\t Loss=1.961948\\t mu=', '2.640499')\n",
      "('Iteration=147\\t Loss=1.9614961\\t mu=', '2.6438687')\n",
      "('Iteration=148\\t Loss=1.9610541\\t mu=', '2.6472023')\n",
      "('Iteration=149\\t Loss=1.9606211\\t mu=', '2.6505')\n",
      "('Iteration=150\\t Loss=1.9601978\\t mu=', '2.6537626')\n",
      "('Iteration=151\\t Loss=1.9597838\\t mu=', '2.6569905')\n",
      "('Iteration=152\\t Loss=1.9593775\\t mu=', '2.6601841')\n",
      "('Iteration=153\\t Loss=1.9589804\\t mu=', '2.663344')\n",
      "('Iteration=154\\t Loss=1.9585916\\t mu=', '2.6664703')\n",
      "('Iteration=155\\t Loss=1.958211\\t mu=', '2.6695635')\n",
      "('Iteration=156\\t Loss=1.957838\\t mu=', '2.6726243')\n",
      "('Iteration=157\\t Loss=1.957473\\t mu=', '2.675653')\n",
      "('Iteration=158\\t Loss=1.9571154\\t mu=', '2.67865')\n",
      "('Iteration=159\\t Loss=1.9567657\\t mu=', '2.6816156')\n",
      "('Iteration=160\\t Loss=1.956423\\t mu=', '2.6845503')\n",
      "('Iteration=161\\t Loss=1.9560874\\t mu=', '2.6874545')\n",
      "('Iteration=162\\t Loss=1.9557586\\t mu=', '2.6903284')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration=163\\t Loss=1.955437\\t mu=', '2.6931725')\n",
      "('Iteration=164\\t Loss=1.9551215\\t mu=', '2.6959872')\n",
      "('Iteration=165\\t Loss=1.9548129\\t mu=', '2.698773')\n",
      "('Iteration=166\\t Loss=1.9545102\\t mu=', '2.70153')\n",
      "('Iteration=167\\t Loss=1.9542139\\t mu=', '2.7042587')\n",
      "('Iteration=168\\t Loss=1.9539238\\t mu=', '2.7069595')\n",
      "('Iteration=169\\t Loss=1.9536393\\t mu=', '2.7096326')\n",
      "('Iteration=170\\t Loss=1.9533606\\t mu=', '2.7122784')\n",
      "('Iteration=171\\t Loss=1.9530877\\t mu=', '2.7148972')\n",
      "('Iteration=172\\t Loss=1.9528203\\t mu=', '2.7174892')\n",
      "('Iteration=173\\t Loss=1.9525586\\t mu=', '2.720055')\n",
      "('Iteration=174\\t Loss=1.9523014\\t mu=', '2.722595')\n",
      "('Iteration=175\\t Loss=1.9520496\\t mu=', '2.725109')\n",
      "('Iteration=176\\t Loss=1.9518037\\t mu=', '2.727598')\n",
      "('Iteration=177\\t Loss=1.9515622\\t mu=', '2.7300618')\n",
      "('Iteration=178\\t Loss=1.9513254\\t mu=', '2.7325008')\n",
      "('Iteration=179\\t Loss=1.9510932\\t mu=', '2.7349153')\n",
      "('Iteration=180\\t Loss=1.9508656\\t mu=', '2.7373054')\n",
      "('Iteration=181\\t Loss=1.9506432\\t mu=', '2.7396717')\n",
      "('Iteration=182\\t Loss=1.9504244\\t mu=', '2.7420144')\n",
      "('Iteration=183\\t Loss=1.9502102\\t mu=', '2.7443337')\n",
      "('Iteration=184\\t Loss=1.9500008\\t mu=', '2.74663')\n",
      "('Iteration=185\\t Loss=1.9497948\\t mu=', '2.7489033')\n",
      "('Iteration=186\\t Loss=1.9495926\\t mu=', '2.7511542')\n",
      "('Iteration=187\\t Loss=1.9493953\\t mu=', '2.7533827')\n",
      "('Iteration=188\\t Loss=1.9492016\\t mu=', '2.7555892')\n",
      "('Iteration=189\\t Loss=1.9490117\\t mu=', '2.7577739')\n",
      "('Iteration=190\\t Loss=1.9488252\\t mu=', '2.759937')\n",
      "('Iteration=191\\t Loss=1.9486426\\t mu=', '2.762079')\n",
      "('Iteration=192\\t Loss=1.9484639\\t mu=', '2.7642')\n",
      "('Iteration=193\\t Loss=1.9482887\\t mu=', '2.7663')\n",
      "('Iteration=194\\t Loss=1.9481162\\t mu=', '2.7683794')\n",
      "('Iteration=195\\t Loss=1.9479476\\t mu=', '2.7704387')\n",
      "('Iteration=196\\t Loss=1.9477817\\t mu=', '2.7724776')\n",
      "('Iteration=197\\t Loss=1.9476197\\t mu=', '2.7744968')\n",
      "('Iteration=198\\t Loss=1.9474603\\t mu=', '2.7764962')\n",
      "('Iteration=199\\t Loss=1.9473041\\t mu=', '2.7784762')\n",
      "('Iteration=200\\t Loss=1.9471514\\t mu=', '2.780437')\n",
      "('Iteration=201\\t Loss=1.9470013\\t mu=', '2.782379')\n",
      "('Iteration=202\\t Loss=1.9468539\\t mu=', '2.784302')\n",
      "('Iteration=203\\t Loss=1.94671\\t mu=', '2.7862065')\n",
      "('Iteration=204\\t Loss=1.9465678\\t mu=', '2.7880926')\n",
      "('Iteration=205\\t Loss=1.9464291\\t mu=', '2.7899604')\n",
      "('Iteration=206\\t Loss=1.9462928\\t mu=', '2.7918103')\n",
      "('Iteration=207\\t Loss=1.9461594\\t mu=', '2.7936423')\n",
      "('Iteration=208\\t Loss=1.9460285\\t mu=', '2.7954566')\n",
      "('Iteration=209\\t Loss=1.9458994\\t mu=', '2.7972536')\n",
      "('Iteration=210\\t Loss=1.9457738\\t mu=', '2.7990334')\n",
      "('Iteration=211\\t Loss=1.94565\\t mu=', '2.8007963')\n",
      "('Iteration=212\\t Loss=1.9455287\\t mu=', '2.8025422')\n",
      "('Iteration=213\\t Loss=1.9454095\\t mu=', '2.8042715')\n",
      "('Iteration=214\\t Loss=1.9452928\\t mu=', '2.8059843')\n",
      "('Iteration=215\\t Loss=1.9451782\\t mu=', '2.8076808')\n",
      "('Iteration=216\\t Loss=1.945066\\t mu=', '2.8093612')\n",
      "('Iteration=217\\t Loss=1.9449551\\t mu=', '2.8110256')\n",
      "('Iteration=218\\t Loss=1.9448475\\t mu=', '2.8126743')\n",
      "('Iteration=219\\t Loss=1.9447412\\t mu=', '2.8143072')\n",
      "('Iteration=220\\t Loss=1.9446371\\t mu=', '2.815925')\n",
      "('Iteration=221\\t Loss=1.9445348\\t mu=', '2.817527')\n",
      "('Iteration=222\\t Loss=1.9444344\\t mu=', '2.8191142')\n",
      "('Iteration=223\\t Loss=1.9443357\\t mu=', '2.8206863')\n",
      "('Iteration=224\\t Loss=1.9442395\\t mu=', '2.8222437')\n",
      "('Iteration=225\\t Loss=1.9441444\\t mu=', '2.8237865')\n",
      "('Iteration=226\\t Loss=1.9440517\\t mu=', '2.8253148')\n",
      "('Iteration=227\\t Loss=1.9439605\\t mu=', '2.8268287')\n",
      "('Iteration=228\\t Loss=1.9438709\\t mu=', '2.8283284')\n",
      "('Iteration=229\\t Loss=1.9437834\\t mu=', '2.829814')\n",
      "('Iteration=230\\t Loss=1.9436969\\t mu=', '2.8312857')\n",
      "('Iteration=231\\t Loss=1.9436123\\t mu=', '2.8327436')\n",
      "('Iteration=232\\t Loss=1.9435292\\t mu=', '2.834188')\n",
      "('Iteration=233\\t Loss=1.9434478\\t mu=', '2.8356187')\n",
      "('Iteration=234\\t Loss=1.9433676\\t mu=', '2.8370361')\n",
      "('Iteration=235\\t Loss=1.9432894\\t mu=', '2.8384404')\n",
      "('Iteration=236\\t Loss=1.9432119\\t mu=', '2.8398316')\n",
      "('Iteration=237\\t Loss=1.9431363\\t mu=', '2.84121')\n",
      "('Iteration=238\\t Loss=1.9430621\\t mu=', '2.8425753')\n",
      "('Iteration=239\\t Loss=1.9429892\\t mu=', '2.843928')\n",
      "('Iteration=240\\t Loss=1.942918\\t mu=', '2.8452685')\n",
      "('Iteration=241\\t Loss=1.9428476\\t mu=', '2.8465965')\n",
      "('Iteration=242\\t Loss=1.9427785\\t mu=', '2.847912')\n",
      "('Iteration=243\\t Loss=1.9427114\\t mu=', '2.8492155')\n",
      "('Iteration=244\\t Loss=1.9426445\\t mu=', '2.850507')\n",
      "('Iteration=245\\t Loss=1.9425793\\t mu=', '2.8517866')\n",
      "('Iteration=246\\t Loss=1.9425153\\t mu=', '2.8530543')\n",
      "('Iteration=247\\t Loss=1.9424525\\t mu=', '2.8543103')\n",
      "('Iteration=248\\t Loss=1.942391\\t mu=', '2.8555548')\n",
      "('Iteration=249\\t Loss=1.9423307\\t mu=', '2.856788')\n",
      "('Iteration=250\\t Loss=1.9422709\\t mu=', '2.8580096')\n",
      "('Iteration=251\\t Loss=1.9422129\\t mu=', '2.85922')\n",
      "('Iteration=252\\t Loss=1.9421555\\t mu=', '2.8604195')\n",
      "('Iteration=253\\t Loss=1.942099\\t mu=', '2.861608')\n",
      "('Iteration=254\\t Loss=1.9420439\\t mu=', '2.8627856')\n",
      "('Iteration=255\\t Loss=1.9419894\\t mu=', '2.8639524')\n",
      "('Iteration=256\\t Loss=1.9419365\\t mu=', '2.8651085')\n",
      "('Iteration=257\\t Loss=1.9418844\\t mu=', '2.866254')\n",
      "('Iteration=258\\t Loss=1.941833\\t mu=', '2.8673892')\n",
      "('Iteration=259\\t Loss=1.9417826\\t mu=', '2.868514')\n",
      "('Iteration=260\\t Loss=1.941733\\t mu=', '2.8696287')\n",
      "('Iteration=261\\t Loss=1.9416844\\t mu=', '2.870733')\n",
      "('Iteration=262\\t Loss=1.9416367\\t mu=', '2.8718274')\n",
      "('Iteration=263\\t Loss=1.9415902\\t mu=', '2.8729117')\n",
      "('Iteration=264\\t Loss=1.9415439\\t mu=', '2.8739862')\n",
      "('Iteration=265\\t Loss=1.9414989\\t mu=', '2.875051')\n",
      "('Iteration=266\\t Loss=1.9414546\\t mu=', '2.8761063')\n",
      "('Iteration=267\\t Loss=1.9414109\\t mu=', '2.877152')\n",
      "('Iteration=268\\t Loss=1.9413682\\t mu=', '2.8781881')\n",
      "('Iteration=269\\t Loss=1.941326\\t mu=', '2.879215')\n",
      "('Iteration=270\\t Loss=1.9412848\\t mu=', '2.8802326')\n",
      "('Iteration=271\\t Loss=1.9412444\\t mu=', '2.8812408')\n",
      "('Iteration=272\\t Loss=1.9412049\\t mu=', '2.88224')\n",
      "('Iteration=273\\t Loss=1.9411656\\t mu=', '2.8832302')\n",
      "('Iteration=274\\t Loss=1.9411275\\t mu=', '2.8842115')\n",
      "('Iteration=275\\t Loss=1.9410896\\t mu=', '2.885184')\n",
      "('Iteration=276\\t Loss=1.9410527\\t mu=', '2.8861477')\n",
      "('Iteration=277\\t Loss=1.9410168\\t mu=', '2.8871028')\n",
      "('Iteration=278\\t Loss=1.9409809\\t mu=', '2.8880494')\n",
      "('Iteration=279\\t Loss=1.9409457\\t mu=', '2.8889873')\n",
      "('Iteration=280\\t Loss=1.9409113\\t mu=', '2.889917')\n",
      "('Iteration=281\\t Loss=1.9408777\\t mu=', '2.8908381')\n",
      "('Iteration=282\\t Loss=1.9408445\\t mu=', '2.891751')\n",
      "('Iteration=283\\t Loss=1.9408118\\t mu=', '2.8926558')\n",
      "('Iteration=284\\t Loss=1.9407797\\t mu=', '2.8935525')\n",
      "('Iteration=285\\t Loss=1.9407485\\t mu=', '2.8944411')\n",
      "('Iteration=286\\t Loss=1.9407173\\t mu=', '2.8953218')\n",
      "('Iteration=287\\t Loss=1.9406873\\t mu=', '2.8961947')\n",
      "('Iteration=288\\t Loss=1.940657\\t mu=', '2.8970597')\n",
      "('Iteration=289\\t Loss=1.9406277\\t mu=', '2.897917')\n",
      "('Iteration=290\\t Loss=1.9405992\\t mu=', '2.8987665')\n",
      "('Iteration=291\\t Loss=1.940571\\t mu=', '2.8996086')\n",
      "('Iteration=292\\t Loss=1.9405435\\t mu=', '2.900443')\n",
      "('Iteration=293\\t Loss=1.940516\\t mu=', '2.9012702')\n",
      "('Iteration=294\\t Loss=1.9404893\\t mu=', '2.9020898')\n",
      "('Iteration=295\\t Loss=1.9404631\\t mu=', '2.9029024')\n",
      "('Iteration=296\\t Loss=1.9404376\\t mu=', '2.9037075')\n",
      "('Iteration=297\\t Loss=1.9404117\\t mu=', '2.9045055')\n",
      "('Iteration=298\\t Loss=1.9403871\\t mu=', '2.9052966')\n",
      "('Iteration=299\\t Loss=1.9403627\\t mu=', '2.9060805')\n",
      "('Iteration=300\\t Loss=1.9403383\\t mu=', '2.9068575')\n",
      "('Iteration=301\\t Loss=1.9403149\\t mu=', '2.9076276')\n",
      "('Iteration=302\\t Loss=1.9402912\\t mu=', '2.9083908')\n",
      "('Iteration=303\\t Loss=1.9402688\\t mu=', '2.9091473')\n",
      "('Iteration=304\\t Loss=1.9402463\\t mu=', '2.909897')\n",
      "('Iteration=305\\t Loss=1.9402242\\t mu=', '2.9106402')\n",
      "('Iteration=306\\t Loss=1.940203\\t mu=', '2.911377')\n",
      "('Iteration=307\\t Loss=1.9401816\\t mu=', '2.912107')\n",
      "('Iteration=308\\t Loss=1.9401608\\t mu=', '2.9128306')\n",
      "('Iteration=309\\t Loss=1.9401406\\t mu=', '2.9135478')\n",
      "('Iteration=310\\t Loss=1.9401201\\t mu=', '2.9142587')\n",
      "('Iteration=311\\t Loss=1.9401002\\t mu=', '2.9149632')\n",
      "('Iteration=312\\t Loss=1.940081\\t mu=', '2.9156616')\n",
      "('Iteration=313\\t Loss=1.9400619\\t mu=', '2.916354')\n",
      "('Iteration=314\\t Loss=1.940043\\t mu=', '2.91704')\n",
      "('Iteration=315\\t Loss=1.940025\\t mu=', '2.9177203')\n",
      "('Iteration=316\\t Loss=1.9400065\\t mu=', '2.9183946')\n",
      "('Iteration=317\\t Loss=1.9399891\\t mu=', '2.9190629')\n",
      "('Iteration=318\\t Loss=1.9399714\\t mu=', '2.9197252')\n",
      "('Iteration=319\\t Loss=1.9399543\\t mu=', '2.9203818')\n",
      "('Iteration=320\\t Loss=1.9399375\\t mu=', '2.9210324')\n",
      "('Iteration=321\\t Loss=1.9399207\\t mu=', '2.9216774')\n",
      "('Iteration=322\\t Loss=1.9399047\\t mu=', '2.9223168')\n",
      "('Iteration=323\\t Loss=1.9398885\\t mu=', '2.9229505')\n",
      "('Iteration=324\\t Loss=1.9398726\\t mu=', '2.9235787')\n",
      "('Iteration=325\\t Loss=1.9398574\\t mu=', '2.9242015')\n",
      "('Iteration=326\\t Loss=1.939842\\t mu=', '2.9248188')\n",
      "('Iteration=327\\t Loss=1.939827\\t mu=', '2.9254305')\n",
      "('Iteration=328\\t Loss=1.9398127\\t mu=', '2.926037')\n",
      "('Iteration=329\\t Loss=1.9397982\\t mu=', '2.9266384')\n",
      "('Iteration=330\\t Loss=1.9397839\\t mu=', '2.9272342')\n",
      "('Iteration=331\\t Loss=1.9397703\\t mu=', '2.927825')\n",
      "('Iteration=332\\t Loss=1.9397566\\t mu=', '2.9284105')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration=333\\t Loss=1.9397432\\t mu=', '2.9289908')\n",
      "('Iteration=334\\t Loss=1.9397297\\t mu=', '2.9295661')\n",
      "('Iteration=335\\t Loss=1.9397168\\t mu=', '2.9301364')\n",
      "('Iteration=336\\t Loss=1.9397041\\t mu=', '2.9307017')\n",
      "('Iteration=337\\t Loss=1.9396915\\t mu=', '2.9312623')\n",
      "('Iteration=338\\t Loss=1.9396793\\t mu=', '2.9318178')\n",
      "('Iteration=339\\t Loss=1.9396676\\t mu=', '2.9323685')\n",
      "('Iteration=340\\t Loss=1.9396557\\t mu=', '2.9329145')\n",
      "('Iteration=341\\t Loss=1.9396437\\t mu=', '2.9334557')\n",
      "('Iteration=342\\t Loss=1.939632\\t mu=', '2.9339921')\n",
      "('Iteration=343\\t Loss=1.9396211\\t mu=', '2.9345238')\n",
      "('Iteration=344\\t Loss=1.9396101\\t mu=', '2.935051')\n",
      "('Iteration=345\\t Loss=1.9395988\\t mu=', '2.9355736')\n",
      "('Iteration=346\\t Loss=1.9395884\\t mu=', '2.9360917')\n",
      "('Iteration=347\\t Loss=1.9395782\\t mu=', '2.9366052')\n",
      "('Iteration=348\\t Loss=1.9395676\\t mu=', '2.9371142')\n",
      "('Iteration=349\\t Loss=1.9395572\\t mu=', '2.937619')\n",
      "('Iteration=350\\t Loss=1.9395474\\t mu=', '2.9381192')\n",
      "('Iteration=351\\t Loss=1.9395376\\t mu=', '2.938615')\n",
      "('Iteration=352\\t Loss=1.9395281\\t mu=', '2.9391067')\n",
      "('Iteration=353\\t Loss=1.9395188\\t mu=', '2.939594')\n",
      "('Iteration=354\\t Loss=1.9395094\\t mu=', '2.940077')\n",
      "('Iteration=355\\t Loss=1.9395\\t mu=', '2.940556')\n",
      "('Iteration=356\\t Loss=1.939491\\t mu=', '2.9410307')\n",
      "('Iteration=357\\t Loss=1.9394822\\t mu=', '2.9415014')\n",
      "('Iteration=358\\t Loss=1.939474\\t mu=', '2.941968')\n",
      "('Iteration=359\\t Loss=1.9394654\\t mu=', '2.9424305')\n",
      "('Iteration=360\\t Loss=1.939457\\t mu=', '2.942889')\n",
      "('Iteration=361\\t Loss=1.9394485\\t mu=', '2.9433436')\n",
      "('Iteration=362\\t Loss=1.9394406\\t mu=', '2.9437943')\n",
      "('Iteration=363\\t Loss=1.9394324\\t mu=', '2.944241')\n",
      "('Iteration=364\\t Loss=1.9394246\\t mu=', '2.944684')\n",
      "('Iteration=365\\t Loss=1.9394172\\t mu=', '2.9451232')\n",
      "('Iteration=366\\t Loss=1.9394096\\t mu=', '2.9455585')\n",
      "('Iteration=367\\t Loss=1.939402\\t mu=', '2.94599')\n",
      "('Iteration=368\\t Loss=1.939395\\t mu=', '2.9464178')\n",
      "('Iteration=369\\t Loss=1.9393877\\t mu=', '2.946842')\n",
      "('Iteration=370\\t Loss=1.9393806\\t mu=', '2.9472623')\n",
      "('Iteration=371\\t Loss=1.9393739\\t mu=', '2.947679')\n",
      "('Iteration=372\\t Loss=1.9393668\\t mu=', '2.9480922')\n",
      "('Iteration=373\\t Loss=1.9393604\\t mu=', '2.9485018')\n",
      "('Iteration=374\\t Loss=1.9393537\\t mu=', '2.9489079')\n",
      "('Iteration=375\\t Loss=1.939347\\t mu=', '2.9493105')\n",
      "('Iteration=376\\t Loss=1.9393408\\t mu=', '2.9497097')\n",
      "('Iteration=377\\t Loss=1.9393348\\t mu=', '2.9501054')\n",
      "('Iteration=378\\t Loss=1.9393287\\t mu=', '2.9504976')\n",
      "('Iteration=379\\t Loss=1.9393225\\t mu=', '2.9508865')\n",
      "('Iteration=380\\t Loss=1.9393162\\t mu=', '2.951272')\n",
      "('Iteration=381\\t Loss=1.9393108\\t mu=', '2.9516542')\n",
      "('Iteration=382\\t Loss=1.9393048\\t mu=', '2.9520333')\n",
      "('Iteration=383\\t Loss=1.9392995\\t mu=', '2.952409')\n",
      "('Iteration=384\\t Loss=1.939294\\t mu=', '2.9527814')\n",
      "('Iteration=385\\t Loss=1.9392883\\t mu=', '2.9531507')\n",
      "('Iteration=386\\t Loss=1.9392833\\t mu=', '2.953517')\n",
      "('Iteration=387\\t Loss=1.9392779\\t mu=', '2.9538798')\n",
      "('Iteration=388\\t Loss=1.9392726\\t mu=', '2.9542396')\n",
      "('Iteration=389\\t Loss=1.9392676\\t mu=', '2.9545963')\n",
      "('Iteration=390\\t Loss=1.9392627\\t mu=', '2.95495')\n",
      "('Iteration=391\\t Loss=1.9392574\\t mu=', '2.9553008')\n",
      "('Iteration=392\\t Loss=1.939253\\t mu=', '2.9556484')\n",
      "('Iteration=393\\t Loss=1.9392484\\t mu=', '2.9559932')\n",
      "('Iteration=394\\t Loss=1.9392436\\t mu=', '2.9563348')\n",
      "('Iteration=395\\t Loss=1.939239\\t mu=', '2.9566736')\n",
      "('Iteration=396\\t Loss=1.9392347\\t mu=', '2.9570096')\n",
      "('Iteration=397\\t Loss=1.9392298\\t mu=', '2.9573426')\n",
      "('Iteration=398\\t Loss=1.9392254\\t mu=', '2.9576728')\n",
      "('Iteration=399\\t Loss=1.9392213\\t mu=', '2.9580002')\n",
      "('Iteration=400\\t Loss=1.9392172\\t mu=', '2.9583247')\n",
      "('Iteration=401\\t Loss=1.939213\\t mu=', '2.9586465')\n",
      "('Iteration=402\\t Loss=1.9392092\\t mu=', '2.9589655')\n",
      "('Iteration=403\\t Loss=1.939205\\t mu=', '2.959282')\n",
      "('Iteration=404\\t Loss=1.9392008\\t mu=', '2.9595954')\n",
      "('Iteration=405\\t Loss=1.9391973\\t mu=', '2.9599063')\n",
      "('Iteration=406\\t Loss=1.9391934\\t mu=', '2.9602146')\n",
      "('Iteration=407\\t Loss=1.9391897\\t mu=', '2.9605203')\n",
      "('Iteration=408\\t Loss=1.9391863\\t mu=', '2.9608233')\n",
      "('Iteration=409\\t Loss=1.9391824\\t mu=', '2.9611237')\n",
      "('Iteration=410\\t Loss=1.9391791\\t mu=', '2.9614215')\n",
      "('Iteration=411\\t Loss=1.9391754\\t mu=', '2.961717')\n",
      "('Iteration=412\\t Loss=1.9391723\\t mu=', '2.9620097')\n",
      "('Iteration=413\\t Loss=1.9391687\\t mu=', '2.9622998')\n",
      "('Iteration=414\\t Loss=1.9391655\\t mu=', '2.9625876')\n",
      "('Iteration=415\\t Loss=1.9391621\\t mu=', '2.962873')\n",
      "('Iteration=416\\t Loss=1.939159\\t mu=', '2.963156')\n",
      "('Iteration=417\\t Loss=1.939156\\t mu=', '2.9634364')\n",
      "('Iteration=418\\t Loss=1.9391527\\t mu=', '2.9637144')\n",
      "('Iteration=419\\t Loss=1.9391496\\t mu=', '2.96399')\n",
      "('Iteration=420\\t Loss=1.9391466\\t mu=', '2.9642634')\n",
      "('Iteration=421\\t Loss=1.9391441\\t mu=', '2.9645345')\n",
      "('Iteration=422\\t Loss=1.939141\\t mu=', '2.9648032')\n",
      "('Iteration=423\\t Loss=1.9391385\\t mu=', '2.9650695')\n",
      "('Iteration=424\\t Loss=1.9391356\\t mu=', '2.9653337')\n",
      "('Iteration=425\\t Loss=1.9391325\\t mu=', '2.9655957')\n",
      "('Iteration=426\\t Loss=1.9391301\\t mu=', '2.9658554')\n",
      "('Iteration=427\\t Loss=1.9391276\\t mu=', '2.9661129')\n",
      "('Iteration=428\\t Loss=1.9391246\\t mu=', '2.9663682')\n",
      "('Iteration=429\\t Loss=1.9391217\\t mu=', '2.9666214')\n",
      "('Iteration=430\\t Loss=1.9391199\\t mu=', '2.9668725')\n",
      "('Iteration=431\\t Loss=1.9391174\\t mu=', '2.9671214')\n",
      "('Iteration=432\\t Loss=1.939115\\t mu=', '2.9673681')\n",
      "('Iteration=433\\t Loss=1.9391123\\t mu=', '2.9676127')\n",
      "('Iteration=434\\t Loss=1.9391102\\t mu=', '2.9678552')\n",
      "('Iteration=435\\t Loss=1.9391077\\t mu=', '2.9680958')\n",
      "('Iteration=436\\t Loss=1.9391055\\t mu=', '2.9683342')\n",
      "('Iteration=437\\t Loss=1.9391035\\t mu=', '2.9685705')\n",
      "('Iteration=438\\t Loss=1.9391012\\t mu=', '2.9688048')\n",
      "('Iteration=439\\t Loss=1.9390988\\t mu=', '2.9690373')\n",
      "('Iteration=440\\t Loss=1.9390967\\t mu=', '2.9692676')\n",
      "('Iteration=441\\t Loss=1.9390948\\t mu=', '2.969496')\n",
      "('Iteration=442\\t Loss=1.9390928\\t mu=', '2.9697225')\n",
      "('Iteration=443\\t Loss=1.9390908\\t mu=', '2.969947')\n",
      "('Iteration=444\\t Loss=1.9390887\\t mu=', '2.9701698')\n",
      "('Iteration=445\\t Loss=1.9390872\\t mu=', '2.9703906')\n",
      "('Iteration=446\\t Loss=1.9390848\\t mu=', '2.9706094')\n",
      "('Iteration=447\\t Loss=1.9390832\\t mu=', '2.9708264')\n",
      "('Iteration=448\\t Loss=1.9390811\\t mu=', '2.9710417')\n",
      "('Iteration=449\\t Loss=1.9390793\\t mu=', '2.971255')\n",
      "('Iteration=450\\t Loss=1.939078\\t mu=', '2.9714665')\n",
      "('Iteration=451\\t Loss=1.939076\\t mu=', '2.9716763')\n",
      "('Iteration=452\\t Loss=1.9390743\\t mu=', '2.9718843')\n",
      "('Iteration=453\\t Loss=1.939072\\t mu=', '2.9720905')\n",
      "('Iteration=454\\t Loss=1.9390709\\t mu=', '2.972295')\n",
      "('Iteration=455\\t Loss=1.9390694\\t mu=', '2.9724977')\n",
      "('Iteration=456\\t Loss=1.9390676\\t mu=', '2.9726987')\n",
      "('Iteration=457\\t Loss=1.9390658\\t mu=', '2.972898')\n",
      "('Iteration=458\\t Loss=1.9390645\\t mu=', '2.9730957')\n",
      "('Iteration=459\\t Loss=1.9390628\\t mu=', '2.9732916')\n",
      "('Iteration=460\\t Loss=1.9390612\\t mu=', '2.973486')\n",
      "('Iteration=461\\t Loss=1.93906\\t mu=', '2.9736786')\n",
      "('Iteration=462\\t Loss=1.9390584\\t mu=', '2.9738696')\n",
      "('Iteration=463\\t Loss=1.939057\\t mu=', '2.9740589')\n",
      "('Iteration=464\\t Loss=1.9390554\\t mu=', '2.9742467')\n",
      "('Iteration=465\\t Loss=1.9390541\\t mu=', '2.974433')\n",
      "('Iteration=466\\t Loss=1.9390527\\t mu=', '2.9746175')\n",
      "('Iteration=467\\t Loss=1.9390515\\t mu=', '2.9748006')\n",
      "('Iteration=468\\t Loss=1.9390502\\t mu=', '2.974982')\n",
      "('Iteration=469\\t Loss=1.9390489\\t mu=', '2.975162')\n",
      "('Iteration=470\\t Loss=1.9390475\\t mu=', '2.9753404')\n",
      "('Iteration=471\\t Loss=1.9390465\\t mu=', '2.9755173')\n",
      "('Iteration=472\\t Loss=1.939045\\t mu=', '2.9756927')\n",
      "('Iteration=473\\t Loss=1.9390438\\t mu=', '2.9758668')\n",
      "('Iteration=474\\t Loss=1.9390429\\t mu=', '2.9760394')\n",
      "('Iteration=475\\t Loss=1.9390414\\t mu=', '2.9762104')\n",
      "('Iteration=476\\t Loss=1.9390404\\t mu=', '2.9763799')\n",
      "('Iteration=477\\t Loss=1.9390391\\t mu=', '2.976548')\n",
      "('Iteration=478\\t Loss=1.9390383\\t mu=', '2.9767146')\n",
      "('Iteration=479\\t Loss=1.9390371\\t mu=', '2.9768798')\n",
      "('Iteration=480\\t Loss=1.9390359\\t mu=', '2.9770439')\n",
      "('Iteration=481\\t Loss=1.9390352\\t mu=', '2.9772065')\n",
      "('Iteration=482\\t Loss=1.9390342\\t mu=', '2.9773676')\n",
      "('Iteration=483\\t Loss=1.939033\\t mu=', '2.9775274')\n",
      "('Iteration=484\\t Loss=1.9390321\\t mu=', '2.977686')\n",
      "('Iteration=485\\t Loss=1.9390309\\t mu=', '2.977843')\n",
      "('Iteration=486\\t Loss=1.93903\\t mu=', '2.9779987')\n",
      "('Iteration=487\\t Loss=1.9390289\\t mu=', '2.9781532')\n",
      "('Iteration=488\\t Loss=1.9390281\\t mu=', '2.9783063')\n",
      "('Iteration=489\\t Loss=1.939027\\t mu=', '2.9784582')\n",
      "('Iteration=490\\t Loss=1.9390261\\t mu=', '2.9786088')\n",
      "('Iteration=491\\t Loss=1.9390252\\t mu=', '2.978758')\n",
      "('Iteration=492\\t Loss=1.9390244\\t mu=', '2.9789062')\n",
      "('Iteration=493\\t Loss=1.939024\\t mu=', '2.979053')\n",
      "('Iteration=494\\t Loss=1.9390224\\t mu=', '2.9791987')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration=495\\t Loss=1.9390221\\t mu=', '2.979343')\n",
      "('Iteration=496\\t Loss=1.9390211\\t mu=', '2.979486')\n",
      "('Iteration=497\\t Loss=1.9390203\\t mu=', '2.9796278')\n",
      "('Iteration=498\\t Loss=1.9390196\\t mu=', '2.9797685')\n",
      "('Iteration=499\\t Loss=1.9390187\\t mu=', '2.979908')\n",
      "('Iteration=500\\t Loss=1.9390178\\t mu=', '2.9800463')\n",
      "('Iteration=501\\t Loss=1.9390169\\t mu=', '2.9801834')\n",
      "('Iteration=502\\t Loss=1.9390165\\t mu=', '2.9803195')\n",
      "('Iteration=503\\t Loss=1.9390159\\t mu=', '2.9804544')\n",
      "('Iteration=504\\t Loss=1.9390153\\t mu=', '2.9805882')\n",
      "('Iteration=505\\t Loss=1.9390144\\t mu=', '2.9807208')\n",
      "('Iteration=506\\t Loss=1.9390137\\t mu=', '2.9808524')\n",
      "('Iteration=507\\t Loss=1.9390129\\t mu=', '2.9809828')\n",
      "('Iteration=508\\t Loss=1.9390125\\t mu=', '2.981112')\n",
      "('Iteration=509\\t Loss=1.9390117\\t mu=', '2.9812403')\n",
      "('Iteration=510\\t Loss=1.9390113\\t mu=', '2.9813673')\n",
      "('Iteration=511\\t Loss=1.9390101\\t mu=', '2.9814935')\n",
      "('Iteration=512\\t Loss=1.9390099\\t mu=', '2.9816184')\n",
      "('Iteration=513\\t Loss=1.9390092\\t mu=', '2.9817424')\n",
      "('Iteration=514\\t Loss=1.9390082\\t mu=', '2.9818652')\n",
      "('Iteration=515\\t Loss=1.9390078\\t mu=', '2.981987')\n",
      "('Iteration=516\\t Loss=1.9390074\\t mu=', '2.9821079')\n",
      "('Iteration=517\\t Loss=1.9390064\\t mu=', '2.9822278')\n",
      "('Iteration=518\\t Loss=1.9390067\\t mu=', '2.9823465')\n",
      "('Iteration=519\\t Loss=1.9390059\\t mu=', '2.9824643')\n",
      "('Iteration=520\\t Loss=1.9390053\\t mu=', '2.9825811')\n",
      "('Iteration=521\\t Loss=1.9390047\\t mu=', '2.982697')\n",
      "('Iteration=522\\t Loss=1.9390043\\t mu=', '2.982812')\n",
      "('Iteration=523\\t Loss=1.9390035\\t mu=', '2.982926')\n",
      "('Iteration=524\\t Loss=1.9390035\\t mu=', '2.983039')\n",
      "('Iteration=525\\t Loss=1.9390024\\t mu=', '2.983151')\n",
      "('Iteration=526\\t Loss=1.9390022\\t mu=', '2.983262')\n",
      "('Iteration=527\\t Loss=1.9390016\\t mu=', '2.9833722')\n",
      "('Iteration=528\\t Loss=1.9390013\\t mu=', '2.9834814')\n",
      "('Iteration=529\\t Loss=1.9390004\\t mu=', '2.9835896')\n",
      "('Iteration=530\\t Loss=1.9390002\\t mu=', '2.983697')\n",
      "('Iteration=531\\t Loss=1.9389997\\t mu=', '2.9838033')\n",
      "('Iteration=532\\t Loss=1.9389992\\t mu=', '2.983909')\n",
      "('Iteration=533\\t Loss=1.9389988\\t mu=', '2.9840136')\n",
      "('Iteration=534\\t Loss=1.9389986\\t mu=', '2.9841173')\n",
      "('Iteration=535\\t Loss=1.9389981\\t mu=', '2.9842203')\n",
      "('Iteration=536\\t Loss=1.9389975\\t mu=', '2.9843223')\n",
      "('Iteration=537\\t Loss=1.9389973\\t mu=', '2.9844234')\n",
      "('Iteration=538\\t Loss=1.938997\\t mu=', '2.9845238')\n",
      "('Iteration=539\\t Loss=1.9389963\\t mu=', '2.9846232')\n",
      "('Iteration=540\\t Loss=1.9389961\\t mu=', '2.984722')\n",
      "('Iteration=541\\t Loss=1.9389955\\t mu=', '2.9848197')\n",
      "('Iteration=542\\t Loss=1.9389954\\t mu=', '2.9849167')\n",
      "('Iteration=543\\t Loss=1.9389948\\t mu=', '2.9850128')\n",
      "('Iteration=544\\t Loss=1.9389945\\t mu=', '2.9851081')\n",
      "('Iteration=545\\t Loss=1.9389942\\t mu=', '2.9852028')\n",
      "('Iteration=546\\t Loss=1.9389937\\t mu=', '2.9852965')\n",
      "('Iteration=547\\t Loss=1.9389936\\t mu=', '2.9853895')\n",
      "('Iteration=548\\t Loss=1.938993\\t mu=', '2.9854817')\n",
      "('Iteration=549\\t Loss=1.938993\\t mu=', '2.985573')\n",
      "('Iteration=550\\t Loss=1.9389926\\t mu=', '2.9856637')\n",
      "('Iteration=551\\t Loss=1.938992\\t mu=', '2.9857535')\n",
      "('Iteration=552\\t Loss=1.9389915\\t mu=', '2.9858427')\n",
      "('Iteration=553\\t Loss=1.9389914\\t mu=', '2.9859312')\n",
      "('Iteration=554\\t Loss=1.9389915\\t mu=', '2.986019')\n",
      "('Iteration=555\\t Loss=1.9389911\\t mu=', '2.986106')\n",
      "('Iteration=556\\t Loss=1.9389906\\t mu=', '2.986192')\n",
      "('Iteration=557\\t Loss=1.9389906\\t mu=', '2.9862773')\n",
      "('Iteration=558\\t Loss=1.9389902\\t mu=', '2.986362')\n",
      "('Iteration=559\\t Loss=1.9389899\\t mu=', '2.986446')\n",
      "('Iteration=560\\t Loss=1.9389894\\t mu=', '2.986529')\n",
      "('Iteration=561\\t Loss=1.9389894\\t mu=', '2.9866118')\n",
      "('Iteration=562\\t Loss=1.9389893\\t mu=', '2.9866939')\n",
      "('Iteration=563\\t Loss=1.9389889\\t mu=', '2.9867752')\n",
      "('Iteration=564\\t Loss=1.9389887\\t mu=', '2.9868557')\n",
      "('Iteration=565\\t Loss=1.9389883\\t mu=', '2.9869356')\n",
      "('Iteration=566\\t Loss=1.9389877\\t mu=', '2.9870148')\n",
      "('Iteration=567\\t Loss=1.9389877\\t mu=', '2.9870932')\n",
      "('Iteration=568\\t Loss=1.9389875\\t mu=', '2.9871712')\n",
      "('Iteration=569\\t Loss=1.9389869\\t mu=', '2.9872484')\n",
      "('Iteration=570\\t Loss=1.9389869\\t mu=', '2.987325')\n",
      "('Iteration=571\\t Loss=1.9389869\\t mu=', '2.987401')\n",
      "('Iteration=572\\t Loss=1.9389863\\t mu=', '2.9874763')\n",
      "('Iteration=573\\t Loss=1.9389862\\t mu=', '2.987551')\n",
      "('Iteration=574\\t Loss=1.938986\\t mu=', '2.9876251')\n",
      "('Iteration=575\\t Loss=1.938986\\t mu=', '2.9876986')\n",
      "('Iteration=576\\t Loss=1.9389857\\t mu=', '2.9877713')\n",
      "('Iteration=577\\t Loss=1.9389853\\t mu=', '2.9878435')\n",
      "('Iteration=578\\t Loss=1.9389851\\t mu=', '2.987915')\n",
      "('Iteration=579\\t Loss=1.9389853\\t mu=', '2.987986')\n",
      "('Iteration=580\\t Loss=1.9389851\\t mu=', '2.9880564')\n",
      "('Iteration=581\\t Loss=1.938985\\t mu=', '2.9881263')\n",
      "('Iteration=582\\t Loss=1.9389842\\t mu=', '2.9881954')\n",
      "('Iteration=583\\t Loss=1.938984\\t mu=', '2.988264')\n",
      "('Iteration=584\\t Loss=1.938984\\t mu=', '2.988332')\n",
      "('Iteration=585\\t Loss=1.9389838\\t mu=', '2.9883995')\n",
      "('Iteration=586\\t Loss=1.9389836\\t mu=', '2.9884665')\n",
      "('Iteration=587\\t Loss=1.9389836\\t mu=', '2.9885328')\n",
      "('Iteration=588\\t Loss=1.9389834\\t mu=', '2.9885986')\n",
      "('Iteration=589\\t Loss=1.9389832\\t mu=', '2.988664')\n",
      "('Iteration=590\\t Loss=1.9389832\\t mu=', '2.9887285')\n",
      "('Iteration=591\\t Loss=1.938983\\t mu=', '2.9887927')\n",
      "('Iteration=592\\t Loss=1.9389828\\t mu=', '2.9888563')\n",
      "('Iteration=593\\t Loss=1.9389828\\t mu=', '2.9889195')\n",
      "('Iteration=594\\t Loss=1.9389826\\t mu=', '2.988982')\n",
      "('Iteration=595\\t Loss=1.9389824\\t mu=', '2.989044')\n",
      "('Iteration=596\\t Loss=1.9389822\\t mu=', '2.9891055')\n",
      "('Iteration=597\\t Loss=1.938982\\t mu=', '2.9891665')\n",
      "('Iteration=598\\t Loss=1.938982\\t mu=', '2.989227')\n",
      "('Iteration=599\\t Loss=1.9389817\\t mu=', '2.9892871')\n",
      "('Iteration=600\\t Loss=1.9389813\\t mu=', '2.9893465')\n",
      "('Iteration=601\\t Loss=1.9389814\\t mu=', '2.9894054')\n",
      "('Iteration=602\\t Loss=1.9389813\\t mu=', '2.9894638')\n",
      "('Iteration=603\\t Loss=1.9389813\\t mu=', '2.9895217')\n",
      "('Iteration=604\\t Loss=1.938981\\t mu=', '2.9895792')\n",
      "('Iteration=605\\t Loss=1.938981\\t mu=', '2.9896362')\n",
      "('Iteration=606\\t Loss=1.9389808\\t mu=', '2.9896927')\n",
      "('Iteration=607\\t Loss=1.9389807\\t mu=', '2.9897487')\n",
      "('Iteration=608\\t Loss=1.9389807\\t mu=', '2.9898043')\n",
      "('Iteration=609\\t Loss=1.9389807\\t mu=', '2.9898593')\n",
      "('Iteration=610\\t Loss=1.9389802\\t mu=', '2.989914')\n",
      "('Iteration=611\\t Loss=1.9389802\\t mu=', '2.989968')\n",
      "('Iteration=612\\t Loss=1.9389801\\t mu=', '2.990022')\n",
      "('Iteration=613\\t Loss=1.9389802\\t mu=', '2.9900753')\n",
      "('Iteration=614\\t Loss=1.9389799\\t mu=', '2.9901283')\n",
      "('Iteration=615\\t Loss=1.9389797\\t mu=', '2.9901807')\n",
      "('Iteration=616\\t Loss=1.9389797\\t mu=', '2.9902327')\n",
      "('Iteration=617\\t Loss=1.9389797\\t mu=', '2.9902842')\n",
      "('Iteration=618\\t Loss=1.9389791\\t mu=', '2.9903352')\n",
      "('Iteration=619\\t Loss=1.9389795\\t mu=', '2.990386')\n",
      "('Iteration=620\\t Loss=1.9389793\\t mu=', '2.9904363')\n",
      "('Iteration=621\\t Loss=1.9389789\\t mu=', '2.9904861')\n",
      "('Iteration=622\\t Loss=1.9389789\\t mu=', '2.9905355')\n",
      "('Iteration=623\\t Loss=1.9389789\\t mu=', '2.9905846')\n",
      "('Iteration=624\\t Loss=1.9389787\\t mu=', '2.9906332')\n",
      "('Iteration=625\\t Loss=1.9389791\\t mu=', '2.9906814')\n",
      "('Iteration=626\\t Loss=1.9389789\\t mu=', '2.990729')\n",
      "('Iteration=627\\t Loss=1.9389783\\t mu=', '2.9907765')\n",
      "('Iteration=628\\t Loss=1.9389786\\t mu=', '2.9908235')\n",
      "('Iteration=629\\t Loss=1.9389781\\t mu=', '2.99087')\n",
      "('Iteration=630\\t Loss=1.9389781\\t mu=', '2.9909163')\n",
      "('Iteration=631\\t Loss=1.9389781\\t mu=', '2.990962')\n",
      "('Iteration=632\\t Loss=1.9389781\\t mu=', '2.9910076')\n",
      "('Iteration=633\\t Loss=1.9389781\\t mu=', '2.9910526')\n",
      "('Iteration=634\\t Loss=1.938978\\t mu=', '2.9910972')\n",
      "('Iteration=635\\t Loss=1.9389777\\t mu=', '2.9911416')\n",
      "('Iteration=636\\t Loss=1.9389777\\t mu=', '2.9911854')\n",
      "('Iteration=637\\t Loss=1.9389781\\t mu=', '2.991229')\n",
      "('Iteration=638\\t Loss=1.9389775\\t mu=', '2.9912722')\n",
      "('Iteration=639\\t Loss=1.9389777\\t mu=', '2.9913151')\n",
      "('Iteration=640\\t Loss=1.9389774\\t mu=', '2.9913576')\n",
      "('Iteration=641\\t Loss=1.9389774\\t mu=', '2.9913998')\n",
      "('Iteration=642\\t Loss=1.9389774\\t mu=', '2.9914415')\n",
      "('Iteration=643\\t Loss=1.9389774\\t mu=', '2.991483')\n",
      "('Iteration=644\\t Loss=1.9389771\\t mu=', '2.991524')\n",
      "('Iteration=645\\t Loss=1.9389771\\t mu=', '2.9915648')\n",
      "('Iteration=646\\t Loss=1.9389771\\t mu=', '2.991605')\n",
      "('Iteration=647\\t Loss=1.938977\\t mu=', '2.991645')\n",
      "('Iteration=648\\t Loss=1.9389768\\t mu=', '2.991685')\n",
      "('Iteration=649\\t Loss=1.938977\\t mu=', '2.9917243')\n",
      "('Iteration=650\\t Loss=1.9389768\\t mu=', '2.9917634')\n",
      "('Iteration=651\\t Loss=1.938977\\t mu=', '2.991802')\n",
      "('Iteration=652\\t Loss=1.9389764\\t mu=', '2.9918404')\n",
      "('Iteration=653\\t Loss=1.9389764\\t mu=', '2.9918785')\n",
      "('Iteration=654\\t Loss=1.938977\\t mu=', '2.9919162')\n",
      "('Iteration=655\\t Loss=1.9389765\\t mu=', '2.9919536')\n",
      "('Iteration=656\\t Loss=1.9389765\\t mu=', '2.9919908')\n",
      "('Iteration=657\\t Loss=1.9389764\\t mu=', '2.9920278')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iteration=658\\t Loss=1.9389765\\t mu=', '2.9920642')\n",
      "('Iteration=659\\t Loss=1.9389764\\t mu=', '2.9921005')\n",
      "('Iteration=660\\t Loss=1.9389764\\t mu=', '2.9921365')\n",
      "('Iteration=661\\t Loss=1.9389764\\t mu=', '2.992172')\n",
      "('Iteration=662\\t Loss=1.9389762\\t mu=', '2.9922073')\n",
      "('Iteration=663\\t Loss=1.9389759\\t mu=', '2.9922423')\n",
      "('Iteration=664\\t Loss=1.9389762\\t mu=', '2.9922771')\n",
      "('Iteration=665\\t Loss=1.9389759\\t mu=', '2.9923115')\n",
      "('Iteration=666\\t Loss=1.9389762\\t mu=', '2.9923456')\n",
      "('Iteration=667\\t Loss=1.9389759\\t mu=', '2.9923794')\n",
      "('Iteration=668\\t Loss=1.9389762\\t mu=', '2.992413')\n",
      "('Iteration=669\\t Loss=1.9389759\\t mu=', '2.9924464')\n",
      "('Iteration=670\\t Loss=1.9389759\\t mu=', '2.9924796')\n",
      "('Iteration=671\\t Loss=1.9389759\\t mu=', '2.9925122')\n",
      "('Iteration=672\\t Loss=1.9389758\\t mu=', '2.9925447')\n",
      "('Iteration=673\\t Loss=1.9389756\\t mu=', '2.9925768')\n",
      "('Iteration=674\\t Loss=1.9389758\\t mu=', '2.9926088')\n",
      "('Iteration=675\\t Loss=1.9389758\\t mu=', '2.9926405')\n",
      "('Iteration=676\\t Loss=1.9389756\\t mu=', '2.992672')\n",
      "('Iteration=677\\t Loss=1.9389753\\t mu=', '2.9927032')\n",
      "('Iteration=678\\t Loss=1.9389758\\t mu=', '2.9927342')\n",
      "('Iteration=679\\t Loss=1.9389758\\t mu=', '2.9927647')\n",
      "('Iteration=680\\t Loss=1.9389753\\t mu=', '2.992795')\n",
      "('Iteration=681\\t Loss=1.9389756\\t mu=', '2.992825')\n",
      "('Iteration=682\\t Loss=1.9389752\\t mu=', '2.9928548')\n",
      "('Iteration=683\\t Loss=1.9389752\\t mu=', '2.9928844')\n",
      "('Iteration=684\\t Loss=1.9389752\\t mu=', '2.9929137')\n",
      "('Iteration=685\\t Loss=1.9389753\\t mu=', '2.9929428')\n",
      "('Iteration=686\\t Loss=1.9389753\\t mu=', '2.9929717')\n",
      "('Iteration=687\\t Loss=1.9389753\\t mu=', '2.9930003')\n",
      "('Iteration=688\\t Loss=1.9389752\\t mu=', '2.9930286')\n",
      "('Iteration=689\\t Loss=1.9389752\\t mu=', '2.9930568')\n",
      "('Iteration=690\\t Loss=1.938975\\t mu=', '2.9930847')\n",
      "('Iteration=691\\t Loss=1.9389752\\t mu=', '2.9931123')\n",
      "('Iteration=692\\t Loss=1.9389752\\t mu=', '2.9931397')\n",
      "('Iteration=693\\t Loss=1.9389746\\t mu=', '2.993167')\n",
      "('Iteration=694\\t Loss=1.9389752\\t mu=', '2.9931939')\n",
      "('Iteration=695\\t Loss=1.9389749\\t mu=', '2.9932206')\n",
      "('Iteration=696\\t Loss=1.9389746\\t mu=', '2.993247')\n",
      "('Iteration=697\\t Loss=1.9389746\\t mu=', '2.9932733')\n",
      "('Iteration=698\\t Loss=1.938975\\t mu=', '2.9932995')\n",
      "('Iteration=699\\t Loss=1.9389746\\t mu=', '2.9933255')\n",
      "('Iteration=700\\t Loss=1.9389746\\t mu=', '2.9933512')\n",
      "('Iteration=701\\t Loss=1.9389749\\t mu=', '2.9933767')\n",
      "('Iteration=702\\t Loss=1.9389749\\t mu=', '2.993402')\n",
      "('Iteration=703\\t Loss=1.9389746\\t mu=', '2.993427')\n",
      "('Iteration=704\\t Loss=1.9389746\\t mu=', '2.9934518')\n",
      "('Iteration=705\\t Loss=1.938975\\t mu=', '2.9934764')\n",
      "('Iteration=706\\t Loss=1.9389746\\t mu=', '2.9935007')\n",
      "('Iteration=707\\t Loss=1.9389746\\t mu=', '2.993525')\n",
      "('Iteration=708\\t Loss=1.9389749\\t mu=', '2.993549')\n",
      "('Iteration=709\\t Loss=1.9389749\\t mu=', '2.993573')\n",
      "('Iteration=710\\t Loss=1.9389744\\t mu=', '2.9935966')\n",
      "('Iteration=711\\t Loss=1.9389746\\t mu=', '2.99362')\n",
      "('Iteration=712\\t Loss=1.9389746\\t mu=', '2.993643')\n",
      "('Iteration=713\\t Loss=1.9389746\\t mu=', '2.9936662')\n",
      "('Iteration=714\\t Loss=1.9389746\\t mu=', '2.993689')\n",
      "('Iteration=715\\t Loss=1.9389744\\t mu=', '2.9937117')\n",
      "('Iteration=716\\t Loss=1.9389744\\t mu=', '2.9937341')\n",
      "('Iteration=717\\t Loss=1.9389744\\t mu=', '2.9937563')\n",
      "('Iteration=718\\t Loss=1.9389744\\t mu=', '2.9937785')\n",
      "('Iteration=719\\t Loss=1.9389746\\t mu=', '2.9938004')\n",
      "('Iteration=720\\t Loss=1.9389743\\t mu=', '2.993822')\n",
      "('Iteration=721\\t Loss=1.9389743\\t mu=', '2.9938436')\n",
      "('Iteration=722\\t Loss=1.9389744\\t mu=', '2.993865')\n",
      "('Iteration=723\\t Loss=1.9389744\\t mu=', '2.9938862')\n",
      "('Iteration=724\\t Loss=1.938974\\t mu=', '2.9939072')\n",
      "('Iteration=725\\t Loss=1.9389743\\t mu=', '2.993928')\n",
      "('Iteration=726\\t Loss=1.9389744\\t mu=', '2.9939487')\n",
      "('Iteration=727\\t Loss=1.9389743\\t mu=', '2.9939692')\n",
      "('Iteration=728\\t Loss=1.9389743\\t mu=', '2.9939895')\n",
      "('Iteration=729\\t Loss=1.9389744\\t mu=', '2.9940095')\n",
      "('Iteration=730\\t Loss=1.9389738\\t mu=', '2.9940295')\n",
      "('Iteration=731\\t Loss=1.9389743\\t mu=', '2.9940493')\n",
      "('Iteration=732\\t Loss=1.938974\\t mu=', '2.9940689')\n",
      "('Iteration=733\\t Loss=1.9389743\\t mu=', '2.9940884')\n",
      "('Iteration=734\\t Loss=1.9389738\\t mu=', '2.9941077')\n",
      "('Iteration=735\\t Loss=1.9389743\\t mu=', '2.9941268')\n",
      "('Iteration=736\\t Loss=1.9389744\\t mu=', '2.9941459')\n",
      "('Iteration=737\\t Loss=1.9389744\\t mu=', '2.9941647')\n",
      "('Iteration=738\\t Loss=1.938974\\t mu=', '2.9941833')\n",
      "('Iteration=739\\t Loss=1.938974\\t mu=', '2.994202')\n",
      "('Iteration=740\\t Loss=1.938974\\t mu=', '2.9942203')\n",
      "('Iteration=741\\t Loss=1.938974\\t mu=', '2.9942384')\n",
      "('Iteration=742\\t Loss=1.938974\\t mu=', '2.9942565')\n",
      "('Iteration=743\\t Loss=1.9389744\\t mu=', '2.9942744')\n",
      "('Iteration=744\\t Loss=1.938974\\t mu=', '2.994292')\n",
      "('Iteration=745\\t Loss=1.9389743\\t mu=', '2.9943097')\n",
      "('Iteration=746\\t Loss=1.9389738\\t mu=', '2.994327')\n",
      "('Iteration=747\\t Loss=1.938974\\t mu=', '2.9943445')\n",
      "('Iteration=748\\t Loss=1.9389738\\t mu=', '2.9943616')\n",
      "('Iteration=749\\t Loss=1.938974\\t mu=', '2.9943786')\n",
      "('Iteration=750\\t Loss=1.9389738\\t mu=', '2.9943955')\n",
      "('Iteration=751\\t Loss=1.9389738\\t mu=', '2.9944122')\n",
      "('Iteration=752\\t Loss=1.9389734\\t mu=', '2.9944289')\n",
      "('Iteration=753\\t Loss=1.938974\\t mu=', '2.9944453')\n",
      "('Iteration=754\\t Loss=1.9389738\\t mu=', '2.9944615')\n",
      "('Iteration=755\\t Loss=1.9389743\\t mu=', '2.9944777')\n",
      "('Iteration=756\\t Loss=1.938974\\t mu=', '2.9944937')\n",
      "('Iteration=757\\t Loss=1.9389737\\t mu=', '2.9945097')\n",
      "('Iteration=758\\t Loss=1.938974\\t mu=', '2.9945254')\n",
      "('Iteration=759\\t Loss=1.9389738\\t mu=', '2.9945412')\n",
      "('Iteration=760\\t Loss=1.9389738\\t mu=', '2.9945567')\n",
      "('Iteration=761\\t Loss=1.9389737\\t mu=', '2.9945722')\n",
      "('Iteration=762\\t Loss=1.9389734\\t mu=', '2.9945874')\n",
      "('Iteration=763\\t Loss=1.9389734\\t mu=', '2.9946024')\n",
      "('Iteration=764\\t Loss=1.9389737\\t mu=', '2.9946175')\n",
      "('Iteration=765\\t Loss=1.9389737\\t mu=', '2.9946322')\n",
      "('Iteration=766\\t Loss=1.938974\\t mu=', '2.994647')\n",
      "('Iteration=767\\t Loss=1.938974\\t mu=', '2.9946616')\n",
      "('Iteration=768\\t Loss=1.9389737\\t mu=', '2.994676')\n",
      "('Iteration=769\\t Loss=1.9389737\\t mu=', '2.9946904')\n",
      "('Iteration=770\\t Loss=1.9389737\\t mu=', '2.9947047')\n",
      "('Iteration=771\\t Loss=1.9389737\\t mu=', '2.9947188')\n",
      "('Iteration=772\\t Loss=1.9389737\\t mu=', '2.9947329')\n",
      "('Iteration=773\\t Loss=1.9389732\\t mu=', '2.9947467')\n",
      "('Iteration=774\\t Loss=1.9389737\\t mu=', '2.9947605')\n",
      "('Iteration=775\\t Loss=1.9389738\\t mu=', '2.994774')\n",
      "('Iteration=776\\t Loss=1.9389738\\t mu=', '2.9947877')\n",
      "('Iteration=777\\t Loss=1.9389738\\t mu=', '2.994801')\n",
      "('Iteration=778\\t Loss=1.9389737\\t mu=', '2.9948144')\n",
      "('Iteration=779\\t Loss=1.9389737\\t mu=', '2.9948277')\n",
      "('Iteration=780\\t Loss=1.9389734\\t mu=', '2.9948409')\n",
      "('Iteration=781\\t Loss=1.9389737\\t mu=', '2.994854')\n",
      "('Iteration=782\\t Loss=1.9389737\\t mu=', '2.9948668')\n",
      "('Iteration=783\\t Loss=1.9389738\\t mu=', '2.9948797')\n",
      "('Iteration=784\\t Loss=1.9389732\\t mu=', '2.9948924')\n",
      "('Iteration=785\\t Loss=1.9389734\\t mu=', '2.994905')\n",
      "('Iteration=786\\t Loss=1.9389734\\t mu=', '2.9949174')\n",
      "('Iteration=787\\t Loss=1.9389738\\t mu=', '2.9949298')\n",
      "('Iteration=788\\t Loss=1.9389734\\t mu=', '2.994942')\n",
      "('Iteration=789\\t Loss=1.9389738\\t mu=', '2.994954')\n",
      "('Iteration=790\\t Loss=1.9389734\\t mu=', '2.9949663')\n",
      "('Iteration=791\\t Loss=1.9389737\\t mu=', '2.9949782')\n",
      "('Iteration=792\\t Loss=1.9389734\\t mu=', '2.99499')\n",
      "('Iteration=793\\t Loss=1.9389737\\t mu=', '2.9950018')\n",
      "('Iteration=794\\t Loss=1.9389734\\t mu=', '2.9950135')\n",
      "('Iteration=795\\t Loss=1.9389734\\t mu=', '2.9950252')\n",
      "('Iteration=796\\t Loss=1.9389732\\t mu=', '2.9950366')\n",
      "('Iteration=797\\t Loss=1.9389734\\t mu=', '2.995048')\n",
      "('Iteration=798\\t Loss=1.9389737\\t mu=', '2.9950593')\n",
      "('Iteration=799\\t Loss=1.9389738\\t mu=', '2.9950705')\n",
      "('Iteration=800\\t Loss=1.9389734\\t mu=', '2.9950817')\n",
      "('Iteration=801\\t Loss=1.9389737\\t mu=', '2.9950926')\n",
      "('Iteration=802\\t Loss=1.9389737\\t mu=', '2.9951036')\n",
      "('Iteration=803\\t Loss=1.9389734\\t mu=', '2.9951143')\n",
      "('Iteration=804\\t Loss=1.9389734\\t mu=', '2.995125')\n",
      "('Iteration=805\\t Loss=1.9389734\\t mu=', '2.9951358')\n",
      "('Iteration=806\\t Loss=1.9389734\\t mu=', '2.9951463')\n",
      "('Iteration=807\\t Loss=1.9389734\\t mu=', '2.9951568')\n",
      "('Iteration=808\\t Loss=1.9389734\\t mu=', '2.995167')\n",
      "('Iteration=809\\t Loss=1.9389734\\t mu=', '2.9951773')\n",
      "('Iteration=810\\t Loss=1.9389734\\t mu=', '2.9951875')\n",
      "('Iteration=811\\t Loss=1.9389737\\t mu=', '2.9951975')\n",
      "('Iteration=812\\t Loss=1.9389737\\t mu=', '2.9952075')\n",
      "('Iteration=813\\t Loss=1.9389738\\t mu=', '2.9952176')\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## Simple gradient descent update\n",
    "## Use \"while\" loop instead of \"for\" loop\n",
    "#############################\n",
    "\n",
    "## Initial rate parameter (guess)\n",
    "mu = 0.5\n",
    "## Step size\n",
    "step_size = 0.025\n",
    "\n",
    "## List to hold loss values for each update of the rate parameter\n",
    "l = []\n",
    "\n",
    "## Convergence flag (intialized to false)\n",
    "conv_flag = False\n",
    "## Convergence tolerance abs(loss_i - loss_{i-1})\n",
    "conv_tol = 1e-5\n",
    "\n",
    "## Iteration counter\n",
    "i = 0\n",
    "\n",
    "while conv_flag==False:\n",
    "    ## Grab current loss\n",
    "    current_loss = pois_loss(mu, x)\n",
    "    l.append(current_loss)\n",
    "    ## Print current parm/loss values to console for given iteration\n",
    "    print_string = \"Iteration=\" + str(i) + \"\\t Loss=\" + str(current_loss) + \"\\t mu=\", str(mu)\n",
    "    print(print_string)\n",
    "    ## Update parm\n",
    "    mu_new = mu - step_size*grad_mu(mu, x)\n",
    "    ## Check for convergence\n",
    "    diff_mu = jnp.abs(mu_new) - mu\n",
    "    ## If convergence achieved that change conv_flag=True and break while loop\n",
    "    if diff_mu < conv_tol:\n",
    "        conv_flag=True\n",
    "    ## Else if convergebce if not acheived maintain flag, increment iteration, update mu\n",
    "    else:\n",
    "        conv_flag=False\n",
    "        i = i +1\n",
    "        mu = mu_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "scenic-management",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='iter', ylabel='loss'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot loss as function of iteration history\n",
    "df = pd.DataFrame({'iter':jnp.arange(len(l)), 'loss':jnp.array(l)})\n",
    "sns.lineplot(data=df, x='iter', y='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-saturn",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-ladder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "imposed-egyptian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence achieved:  False\n",
      "Mean= [2.99631921]\n"
     ]
    }
   ],
   "source": [
    "## Scipy optimize - autograd through an optimization program?\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "## Initial value mu\n",
    "mu0 = 0.5\n",
    "\n",
    "## Optimize for Poisson mean/rate parameter (using Autograd)\n",
    "mu_bfgs = minimize(fun=pois_loss,\n",
    "                                           x0=mu0,\n",
    "                                           args=x,\n",
    "                                           method='BFGS',\n",
    "                                           jac=grad_mu)\n",
    "\n",
    "## Output\n",
    "print(\"Convergence achieved: \", mu_bfgs.success)\n",
    "print(\"Mean=\", mu_bfgs.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-possibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "thorough-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(jax.scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "convenient-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrapper for scipy.optimize.minimize so compatible with JAX\n",
    "import numpy as onp\n",
    "import scipy.optimize\n",
    "from jax import grad, jit\n",
    "from jax.tree_util import tree_flatten, tree_unflatten\n",
    "from jax.flatten_util import ravel_pytree\n",
    "from itertools import count\n",
    "\n",
    "def minimize(fun, \n",
    "                        x0,\n",
    "                        method=None,\n",
    "                        args=(),\n",
    "                        bounds=None,\n",
    "                        constraints=(),\n",
    "                        tol=None,\n",
    "                        callback=None,\n",
    "                        options=None\n",
    "                        ):\n",
    "    \n",
    "    ## Use tree flatten/unflatten to convert initial params to pyTree format\n",
    "    x0_flat, unravel = ravel_pytree(x0)\n",
    "    \n",
    "    ## Wrap objective to ONP arrays and product scalar output    \n",
    "    def fun_wrapper(x_flat, *args):\n",
    "        x = unravel(x_flat)\n",
    "        return float(fun(x, *args))\n",
    "\n",
    "    ## Wrap gradient to consume flat ONP arrays and product scalar output\n",
    "    jac = jit(grad(fun))\n",
    "    def jac_wrapper(x_flat, *args):\n",
    "        x = unravel(x_flat)\n",
    "        g_flat, _ = ravel_pytree(jac(x, *args))\n",
    "        return onp.array(g_flat)\n",
    "    \n",
    "    ## Wrap the callback to consume a pytree\n",
    "    def callback_wrapper(x_flat, *args):\n",
    "        if callback is not None:\n",
    "            x = unravel(x_flat)\n",
    "            return callback(x, *args)\n",
    "        \n",
    "    ## Minimize with scipy\n",
    "    results = scipy.optimize.minimize(fun_wrapper,\n",
    "                                                             x0_flat,\n",
    "                                                             args=args,\n",
    "                                                             method=method,\n",
    "                                                             jac=jac_wrapper,\n",
    "                                                             callback=callback_wrapper,\n",
    "                                                             bounds=bounds,\n",
    "                                                             constraints=constraints,\n",
    "                                                             tol=tol,\n",
    "                                                             options=options)\n",
    "    \n",
    "    ## Pack the output into a PyTree\n",
    "    #results[\"x\"] = unravel(results([\"x\"]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "absolute-impossible",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dshroot/users/cmeaney/.conda/envs/cmeaney_py37/lib/python3.7/site-packages/ipykernel_launcher.py:51: OptimizeWarning: Unknown solver options: ftol\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 1.938973\n",
      "         Iterations: 4\n",
      "         Function evaluations: 61\n",
      "         Gradient evaluations: 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 1.9389734268188477\n",
       " hess_inv: array([[2.96739368]])\n",
       "      jac: array([-0.00050867], dtype=float32)\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 61\n",
       "      nit: 4\n",
       "     njev: 50\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([2.99487634])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(fun=pois_loss, \n",
    "                 x0=jnp.array([2.0]), \n",
    "                 method='BFGS', \n",
    "                 args=jnp.array(x),\n",
    "                 options={'ftol':1e-9, 'disp':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-nation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-public",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-cheese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "victorian-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "## Normal density\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "featured-universal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x', ylabel='y'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Density function\n",
    "x  = jnp.linspace(-10,10,1000)\n",
    "#pd.Series(x).describe()\n",
    "\n",
    "fx = jax.scipy.stats.norm.pdf(x=x, loc=0, scale=3)\n",
    "\n",
    "df = pd.DataFrame({'x':x, 'y':fx})\n",
    "sns.lineplot(data=df, x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "front-hunter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x', ylabel='y'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Log-Density function\n",
    "\n",
    "x  = jnp.linspace(-10,10,1000)\n",
    "#pd.Series(x).describe()\n",
    "\n",
    "log_fx = jax.scipy.stats.norm.logpdf(x=x, loc=0, scale=3)\n",
    "\n",
    "df = pd.DataFrame({'x':x, 'y':log_fx})\n",
    "sns.lineplot(data=df, x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pressing-immune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x', ylabel='y'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Distribution function\n",
    "\n",
    "x  = jnp.linspace(-10,10,1000)\n",
    "#pd.Series(x).describe()\n",
    "\n",
    "y = jax.scipy.stats.norm.cdf(x=x, loc=0, scale=3)\n",
    "\n",
    "df = pd.DataFrame({'x':x, 'y':y})\n",
    "sns.lineplot(data=df, x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-thread",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "liable-newman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################\n",
    "## Normal distirbution\n",
    "############################\n",
    "s = 3\n",
    "m = 10\n",
    "\n",
    "x = jax.random.normal(key, shape=(10000,))\n",
    "x = x*s + m\n",
    "\n",
    "pd.Series(x).plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "three-simpson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean         9.977666\n",
       "std          3.015233\n",
       "min         -2.063173\n",
       "25%          7.968843\n",
       "50%         10.005677\n",
       "75%         12.010670\n",
       "max         23.992352\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Summary of simulated normal data\n",
    "pd.Series(x).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "immune-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple loss function (scalar parm = p; vector input data = x)\n",
    "def normal_loss(theta, x):\n",
    "    mu = theta[0]\n",
    "    sigma = jnp.exp(theta[1])\n",
    "    return -jnp.mean(jax.scipy.stats.norm.logpdf(x=x, loc=mu, scale=sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "infinite-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient of loss function\n",
    "grad_theta = grad(normal_loss, argnums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "going-consensus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=0\t Loss=3.5850222\t mu=2.0\t sigma=2.0\n",
      "Iteration=1\t Loss=3.5818305\t mu=2.0036528\t sigma=2.008304\n",
      "Iteration=2\t Loss=3.579011\t mu=2.0072439\t sigma=2.0160334\n",
      "Iteration=3\t Loss=3.5765102\t mu=2.0107782\t sigma=2.0232353\n",
      "Iteration=4\t Loss=3.574284\t mu=2.0142605\t sigma=2.029952\n",
      "Iteration=5\t Loss=3.572295\t mu=2.017695\t sigma=2.0362217\n",
      "Iteration=6\t Loss=3.5705106\t mu=2.021085\t sigma=2.0420785\n",
      "Iteration=7\t Loss=3.5689044\t mu=2.0244343\t sigma=2.047553\n",
      "Iteration=8\t Loss=3.5674531\t mu=2.0277457\t sigma=2.0526738\n",
      "Iteration=9\t Loss=3.5661368\t mu=2.0310218\t sigma=2.0574658\n",
      "Iteration=10\t Loss=3.5649383\t mu=2.0342655\t sigma=2.0619524\n",
      "Iteration=11\t Loss=3.5638425\t mu=2.037479\t sigma=2.0661547\n",
      "Iteration=12\t Loss=3.5628378\t mu=2.0406642\t sigma=2.0700922\n",
      "Iteration=13\t Loss=3.5619128\t mu=2.043823\t sigma=2.0737824\n",
      "Iteration=14\t Loss=3.5610573\t mu=2.0469575\t sigma=2.0772421\n",
      "Iteration=15\t Loss=3.5602636\t mu=2.050069\t sigma=2.080486\n",
      "Iteration=16\t Loss=3.5595243\t mu=2.0531592\t sigma=2.083528\n",
      "Iteration=17\t Loss=3.558833\t mu=2.0562296\t sigma=2.086381\n",
      "Iteration=18\t Loss=3.5581844\t mu=2.0592813\t sigma=2.0890567\n",
      "Iteration=19\t Loss=3.557573\t mu=2.0623155\t sigma=2.091566\n",
      "Iteration=20\t Loss=3.5569944\t mu=2.0653334\t sigma=2.0939195\n",
      "Iteration=21\t Loss=3.556446\t mu=2.068336\t sigma=2.0961263\n",
      "Iteration=22\t Loss=3.555924\t mu=2.071324\t sigma=2.0981953\n",
      "Iteration=23\t Loss=3.555425\t mu=2.0742989\t sigma=2.1001348\n",
      "Iteration=24\t Loss=3.554947\t mu=2.077261\t sigma=2.1019523\n",
      "Iteration=25\t Loss=3.5544872\t mu=2.0802112\t sigma=2.103655\n",
      "Iteration=26\t Loss=3.5540438\t mu=2.0831504\t sigma=2.10525\n",
      "Iteration=27\t Loss=3.5536144\t mu=2.0860791\t sigma=2.1067426\n",
      "Iteration=28\t Loss=3.5531988\t mu=2.088998\t sigma=2.1081393\n",
      "Iteration=29\t Loss=3.552795\t mu=2.0919077\t sigma=2.1094453\n",
      "Iteration=30\t Loss=3.552401\t mu=2.0948088\t sigma=2.1106658\n",
      "Iteration=31\t Loss=3.5520165\t mu=2.0977015\t sigma=2.1118057\n",
      "Iteration=32\t Loss=3.5516403\t mu=2.1005867\t sigma=2.1128693\n",
      "Iteration=33\t Loss=3.5512714\t mu=2.1034646\t sigma=2.1138608\n",
      "Iteration=34\t Loss=3.550909\t mu=2.1063359\t sigma=2.1147845\n",
      "Iteration=35\t Loss=3.5505528\t mu=2.1092007\t sigma=2.1156437\n",
      "Iteration=36\t Loss=3.5502017\t mu=2.1120596\t sigma=2.1164422\n",
      "Iteration=37\t Loss=3.5498548\t mu=2.114913\t sigma=2.1171832\n",
      "Iteration=38\t Loss=3.5495129\t mu=2.1177611\t sigma=2.1178699\n",
      "Iteration=39\t Loss=3.5491738\t mu=2.1206043\t sigma=2.118505\n",
      "Iteration=40\t Loss=3.5488386\t mu=2.123443\t sigma=2.1190915\n",
      "Iteration=41\t Loss=3.5485067\t mu=2.126277\t sigma=2.119632\n",
      "Iteration=42\t Loss=3.548177\t mu=2.129107\t sigma=2.1201289\n",
      "Iteration=43\t Loss=3.5478497\t mu=2.1319332\t sigma=2.1205842\n",
      "Iteration=44\t Loss=3.5475247\t mu=2.1347558\t sigma=2.1210005\n",
      "Iteration=45\t Loss=3.5472012\t mu=2.1375751\t sigma=2.1213799\n",
      "Iteration=46\t Loss=3.5468798\t mu=2.1403913\t sigma=2.121724\n",
      "Iteration=47\t Loss=3.5465593\t mu=2.1432045\t sigma=2.1220348\n",
      "Iteration=48\t Loss=3.546241\t mu=2.146015\t sigma=2.1223142\n",
      "Iteration=49\t Loss=3.5459235\t mu=2.1488228\t sigma=2.1225636\n",
      "Iteration=50\t Loss=3.5456066\t mu=2.1516283\t sigma=2.1227846\n",
      "Iteration=51\t Loss=3.5452914\t mu=2.1544313\t sigma=2.1229787\n",
      "Iteration=52\t Loss=3.5449765\t mu=2.1572325\t sigma=2.1231475\n",
      "Iteration=53\t Loss=3.5446625\t mu=2.1600318\t sigma=2.123292\n",
      "Iteration=54\t Loss=3.5443487\t mu=2.1628292\t sigma=2.1234136\n",
      "Iteration=55\t Loss=3.544036\t mu=2.1656249\t sigma=2.1235135\n",
      "Iteration=56\t Loss=3.5437233\t mu=2.168419\t sigma=2.1235926\n",
      "Iteration=57\t Loss=3.5434113\t mu=2.1712115\t sigma=2.1236522\n",
      "Iteration=58\t Loss=3.5431\t mu=2.174003\t sigma=2.1236932\n",
      "Iteration=59\t Loss=3.5427887\t mu=2.176793\t sigma=2.1237166\n",
      "Iteration=60\t Loss=3.5424774\t mu=2.179582\t sigma=2.1237233\n",
      "Iteration=61\t Loss=3.5421667\t mu=2.1823702\t sigma=2.123714\n",
      "Iteration=62\t Loss=3.5418558\t mu=2.1851573\t sigma=2.1236897\n",
      "Iteration=63\t Loss=3.5415456\t mu=2.1879435\t sigma=2.123651\n",
      "Iteration=64\t Loss=3.5412347\t mu=2.190729\t sigma=2.1235988\n",
      "Iteration=65\t Loss=3.5409245\t mu=2.1935136\t sigma=2.1235337\n",
      "Iteration=66\t Loss=3.5406141\t mu=2.1962976\t sigma=2.1234562\n",
      "Iteration=67\t Loss=3.540304\t mu=2.1990812\t sigma=2.1233673\n",
      "Iteration=68\t Loss=3.5399942\t mu=2.2018642\t sigma=2.1232672\n",
      "Iteration=69\t Loss=3.5396836\t mu=2.2046468\t sigma=2.1231565\n",
      "Iteration=70\t Loss=3.5393734\t mu=2.207429\t sigma=2.123036\n",
      "Iteration=71\t Loss=3.5390632\t mu=2.2102108\t sigma=2.122906\n",
      "Iteration=72\t Loss=3.538753\t mu=2.2129924\t sigma=2.122767\n",
      "Iteration=73\t Loss=3.5384429\t mu=2.2157738\t sigma=2.1226194\n",
      "Iteration=74\t Loss=3.538132\t mu=2.218555\t sigma=2.1224637\n",
      "Iteration=75\t Loss=3.5378218\t mu=2.221336\t sigma=2.1223001\n",
      "Iteration=76\t Loss=3.5375113\t mu=2.2241168\t sigma=2.1221292\n",
      "Iteration=77\t Loss=3.5372007\t mu=2.2268977\t sigma=2.1219513\n",
      "Iteration=78\t Loss=3.5368903\t mu=2.2296786\t sigma=2.1217668\n",
      "Iteration=79\t Loss=3.536579\t mu=2.2324595\t sigma=2.121576\n",
      "Iteration=80\t Loss=3.5362685\t mu=2.2352405\t sigma=2.1213794\n",
      "Iteration=81\t Loss=3.535957\t mu=2.2380216\t sigma=2.121177\n",
      "Iteration=82\t Loss=3.5356457\t mu=2.2408028\t sigma=2.120969\n",
      "Iteration=83\t Loss=3.535335\t mu=2.2435842\t sigma=2.120756\n",
      "Iteration=84\t Loss=3.5350235\t mu=2.2463658\t sigma=2.120538\n",
      "Iteration=85\t Loss=3.5347118\t mu=2.2491474\t sigma=2.1203153\n",
      "Iteration=86\t Loss=3.5344\t mu=2.2519293\t sigma=2.120088\n",
      "Iteration=87\t Loss=3.5340884\t mu=2.2547116\t sigma=2.1198568\n",
      "Iteration=88\t Loss=3.5337763\t mu=2.2574942\t sigma=2.1196215\n",
      "Iteration=89\t Loss=3.5334644\t mu=2.260277\t sigma=2.1193824\n",
      "Iteration=90\t Loss=3.5331519\t mu=2.26306\t sigma=2.1191394\n",
      "Iteration=91\t Loss=3.5328398\t mu=2.2658436\t sigma=2.1188931\n",
      "Iteration=92\t Loss=3.5325274\t mu=2.2686274\t sigma=2.1186435\n",
      "Iteration=93\t Loss=3.5322144\t mu=2.2714117\t sigma=2.1183908\n",
      "Iteration=94\t Loss=3.5319016\t mu=2.2741964\t sigma=2.118135\n",
      "Iteration=95\t Loss=3.5315883\t mu=2.2769814\t sigma=2.1178763\n",
      "Iteration=96\t Loss=3.5312757\t mu=2.2797668\t sigma=2.117615\n",
      "Iteration=97\t Loss=3.530962\t mu=2.2825527\t sigma=2.117351\n",
      "Iteration=98\t Loss=3.530649\t mu=2.285339\t sigma=2.1170847\n",
      "Iteration=99\t Loss=3.5303357\t mu=2.288126\t sigma=2.116816\n",
      "Iteration=100\t Loss=3.5300214\t mu=2.2909133\t sigma=2.116545\n",
      "Iteration=101\t Loss=3.5297074\t mu=2.2937012\t sigma=2.1162717\n",
      "Iteration=102\t Loss=3.5293934\t mu=2.2964895\t sigma=2.1159966\n",
      "Iteration=103\t Loss=3.5290792\t mu=2.2992785\t sigma=2.1157196\n",
      "Iteration=104\t Loss=3.5287647\t mu=2.302068\t sigma=2.1154406\n",
      "Iteration=105\t Loss=3.52845\t mu=2.304858\t sigma=2.11516\n",
      "Iteration=106\t Loss=3.5281355\t mu=2.3076484\t sigma=2.1148775\n",
      "Iteration=107\t Loss=3.5278206\t mu=2.3104396\t sigma=2.1145935\n",
      "Iteration=108\t Loss=3.5275059\t mu=2.3132312\t sigma=2.1143079\n",
      "Iteration=109\t Loss=3.5271907\t mu=2.3160236\t sigma=2.1140208\n",
      "Iteration=110\t Loss=3.526875\t mu=2.3188164\t sigma=2.1137323\n",
      "Iteration=111\t Loss=3.5265594\t mu=2.32161\t sigma=2.1134424\n",
      "Iteration=112\t Loss=3.5262442\t mu=2.324404\t sigma=2.1131513\n",
      "Iteration=113\t Loss=3.5259278\t mu=2.3271987\t sigma=2.112859\n",
      "Iteration=114\t Loss=3.525612\t mu=2.329994\t sigma=2.1125655\n",
      "Iteration=115\t Loss=3.5252953\t mu=2.33279\t sigma=2.1122708\n",
      "Iteration=116\t Loss=3.5249794\t mu=2.3355863\t sigma=2.1119752\n",
      "Iteration=117\t Loss=3.524663\t mu=2.3383834\t sigma=2.1116784\n",
      "Iteration=118\t Loss=3.524346\t mu=2.3411813\t sigma=2.1113806\n",
      "Iteration=119\t Loss=3.5240293\t mu=2.3439796\t sigma=2.1110818\n",
      "Iteration=120\t Loss=3.5237124\t mu=2.3467786\t sigma=2.1107824\n",
      "Iteration=121\t Loss=3.5233948\t mu=2.3495784\t sigma=2.110482\n",
      "Iteration=122\t Loss=3.5230777\t mu=2.3523788\t sigma=2.1101806\n",
      "Iteration=123\t Loss=3.5227602\t mu=2.3551798\t sigma=2.1098785\n",
      "Iteration=124\t Loss=3.5224426\t mu=2.3579814\t sigma=2.1095757\n",
      "Iteration=125\t Loss=3.5221245\t mu=2.3607838\t sigma=2.1092722\n",
      "Iteration=126\t Loss=3.5218067\t mu=2.363587\t sigma=2.108968\n",
      "Iteration=127\t Loss=3.5214882\t mu=2.3663907\t sigma=2.108663\n",
      "Iteration=128\t Loss=3.5211704\t mu=2.369195\t sigma=2.1083574\n",
      "Iteration=129\t Loss=3.5208516\t mu=2.372\t sigma=2.108051\n",
      "Iteration=130\t Loss=3.5205328\t mu=2.3748057\t sigma=2.1077442\n",
      "Iteration=131\t Loss=3.520214\t mu=2.377612\t sigma=2.1074367\n",
      "Iteration=132\t Loss=3.5198948\t mu=2.3804193\t sigma=2.1071286\n",
      "Iteration=133\t Loss=3.5195758\t mu=2.383227\t sigma=2.10682\n",
      "Iteration=134\t Loss=3.5192564\t mu=2.3860357\t sigma=2.1065109\n",
      "Iteration=135\t Loss=3.518937\t mu=2.388845\t sigma=2.1062012\n",
      "Iteration=136\t Loss=3.518617\t mu=2.391655\t sigma=2.105891\n",
      "Iteration=137\t Loss=3.5182972\t mu=2.3944657\t sigma=2.1055803\n",
      "Iteration=138\t Loss=3.5179772\t mu=2.3972769\t sigma=2.1052692\n",
      "Iteration=139\t Loss=3.517657\t mu=2.4000888\t sigma=2.1049576\n",
      "Iteration=140\t Loss=3.5173366\t mu=2.4029014\t sigma=2.1046457\n",
      "Iteration=141\t Loss=3.517016\t mu=2.4057148\t sigma=2.1043334\n",
      "Iteration=142\t Loss=3.5166953\t mu=2.4085288\t sigma=2.1040206\n",
      "Iteration=143\t Loss=3.516374\t mu=2.4113436\t sigma=2.1037073\n",
      "Iteration=144\t Loss=3.5160534\t mu=2.414159\t sigma=2.1033938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=145\t Loss=3.515732\t mu=2.4169753\t sigma=2.1030798\n",
      "Iteration=146\t Loss=3.515411\t mu=2.4197922\t sigma=2.1027656\n",
      "Iteration=147\t Loss=3.515089\t mu=2.4226098\t sigma=2.1024508\n",
      "Iteration=148\t Loss=3.5147676\t mu=2.4254282\t sigma=2.102136\n",
      "Iteration=149\t Loss=3.5144453\t mu=2.4282475\t sigma=2.1018205\n",
      "Iteration=150\t Loss=3.5141234\t mu=2.4310675\t sigma=2.1015048\n",
      "Iteration=151\t Loss=3.5138009\t mu=2.4338882\t sigma=2.101189\n",
      "Iteration=152\t Loss=3.5134785\t mu=2.4367096\t sigma=2.1008725\n",
      "Iteration=153\t Loss=3.513156\t mu=2.4395318\t sigma=2.100556\n",
      "Iteration=154\t Loss=3.512833\t mu=2.4423547\t sigma=2.100239\n",
      "Iteration=155\t Loss=3.51251\t mu=2.4451783\t sigma=2.0999217\n",
      "Iteration=156\t Loss=3.512187\t mu=2.4480026\t sigma=2.0996041\n",
      "Iteration=157\t Loss=3.5118637\t mu=2.4508276\t sigma=2.0992863\n",
      "Iteration=158\t Loss=3.5115402\t mu=2.4536533\t sigma=2.0989683\n",
      "Iteration=159\t Loss=3.5112164\t mu=2.4564798\t sigma=2.09865\n",
      "Iteration=160\t Loss=3.5108929\t mu=2.459307\t sigma=2.0983315\n",
      "Iteration=161\t Loss=3.510569\t mu=2.4621348\t sigma=2.0980127\n",
      "Iteration=162\t Loss=3.5102446\t mu=2.4649634\t sigma=2.0976934\n",
      "Iteration=163\t Loss=3.5099204\t mu=2.467793\t sigma=2.097374\n",
      "Iteration=164\t Loss=3.5095956\t mu=2.4706233\t sigma=2.0970542\n",
      "Iteration=165\t Loss=3.5092711\t mu=2.4734542\t sigma=2.0967343\n",
      "Iteration=166\t Loss=3.5089462\t mu=2.476286\t sigma=2.096414\n",
      "Iteration=167\t Loss=3.508621\t mu=2.4791183\t sigma=2.0960937\n",
      "Iteration=168\t Loss=3.5082958\t mu=2.4819515\t sigma=2.095773\n",
      "Iteration=169\t Loss=3.5079708\t mu=2.4847853\t sigma=2.0954523\n",
      "Iteration=170\t Loss=3.507645\t mu=2.4876199\t sigma=2.0951314\n",
      "Iteration=171\t Loss=3.5073192\t mu=2.4904554\t sigma=2.0948102\n",
      "Iteration=172\t Loss=3.506993\t mu=2.4932916\t sigma=2.0944889\n",
      "Iteration=173\t Loss=3.5066671\t mu=2.4961286\t sigma=2.0941672\n",
      "Iteration=174\t Loss=3.5063407\t mu=2.4989662\t sigma=2.0938454\n",
      "Iteration=175\t Loss=3.5060143\t mu=2.5018046\t sigma=2.0935233\n",
      "Iteration=176\t Loss=3.5056875\t mu=2.5046437\t sigma=2.093201\n",
      "Iteration=177\t Loss=3.5053608\t mu=2.5074835\t sigma=2.0928783\n",
      "Iteration=178\t Loss=3.505034\t mu=2.5103242\t sigma=2.0925555\n",
      "Iteration=179\t Loss=3.504707\t mu=2.5131657\t sigma=2.0922325\n",
      "Iteration=180\t Loss=3.5043793\t mu=2.516008\t sigma=2.0919092\n",
      "Iteration=181\t Loss=3.504052\t mu=2.5188508\t sigma=2.0915856\n",
      "Iteration=182\t Loss=3.5037243\t mu=2.5216944\t sigma=2.091262\n",
      "Iteration=183\t Loss=3.5033965\t mu=2.5245388\t sigma=2.0909383\n",
      "Iteration=184\t Loss=3.503068\t mu=2.527384\t sigma=2.0906143\n",
      "Iteration=185\t Loss=3.50274\t mu=2.53023\t sigma=2.09029\n",
      "Iteration=186\t Loss=3.5024116\t mu=2.5330768\t sigma=2.0899656\n",
      "Iteration=187\t Loss=3.5020833\t mu=2.5359242\t sigma=2.0896409\n",
      "Iteration=188\t Loss=3.5017543\t mu=2.5387723\t sigma=2.0893161\n",
      "Iteration=189\t Loss=3.5014257\t mu=2.5416214\t sigma=2.0889912\n",
      "Iteration=190\t Loss=3.5010965\t mu=2.5444713\t sigma=2.088666\n",
      "Iteration=191\t Loss=3.5007668\t mu=2.5473218\t sigma=2.0883405\n",
      "Iteration=192\t Loss=3.5004375\t mu=2.550173\t sigma=2.0880148\n",
      "Iteration=193\t Loss=3.5001078\t mu=2.553025\t sigma=2.087689\n",
      "Iteration=194\t Loss=3.499778\t mu=2.555878\t sigma=2.087363\n",
      "Iteration=195\t Loss=3.4994485\t mu=2.5587316\t sigma=2.0870368\n",
      "Iteration=196\t Loss=3.4991176\t mu=2.561586\t sigma=2.0867105\n",
      "Iteration=197\t Loss=3.4987874\t mu=2.564441\t sigma=2.0863838\n",
      "Iteration=198\t Loss=3.4984567\t mu=2.5672967\t sigma=2.086057\n",
      "Iteration=199\t Loss=3.4981258\t mu=2.5701535\t sigma=2.08573\n",
      "Iteration=200\t Loss=3.4977949\t mu=2.573011\t sigma=2.085403\n",
      "Iteration=201\t Loss=3.4974642\t mu=2.575869\t sigma=2.0850756\n",
      "Iteration=202\t Loss=3.4971328\t mu=2.578728\t sigma=2.084748\n",
      "Iteration=203\t Loss=3.4968011\t mu=2.5815876\t sigma=2.0844204\n",
      "Iteration=204\t Loss=3.4964695\t mu=2.584448\t sigma=2.0840926\n",
      "Iteration=205\t Loss=3.4961379\t mu=2.5873094\t sigma=2.0837646\n",
      "Iteration=206\t Loss=3.4958055\t mu=2.5901713\t sigma=2.0834363\n",
      "Iteration=207\t Loss=3.4954734\t mu=2.593034\t sigma=2.0831077\n",
      "Iteration=208\t Loss=3.4951415\t mu=2.5958977\t sigma=2.0827792\n",
      "Iteration=209\t Loss=3.494809\t mu=2.598762\t sigma=2.0824504\n",
      "Iteration=210\t Loss=3.494476\t mu=2.601627\t sigma=2.0821214\n",
      "Iteration=211\t Loss=3.494143\t mu=2.604493\t sigma=2.081792\n",
      "Iteration=212\t Loss=3.4938102\t mu=2.6073596\t sigma=2.0814626\n",
      "Iteration=213\t Loss=3.4934769\t mu=2.610227\t sigma=2.0811331\n",
      "Iteration=214\t Loss=3.4931433\t mu=2.6130953\t sigma=2.0808034\n",
      "Iteration=215\t Loss=3.4928098\t mu=2.6159642\t sigma=2.0804734\n",
      "Iteration=216\t Loss=3.4924762\t mu=2.618834\t sigma=2.0801432\n",
      "Iteration=217\t Loss=3.4921417\t mu=2.6217046\t sigma=2.079813\n",
      "Iteration=218\t Loss=3.4918077\t mu=2.6245759\t sigma=2.0794826\n",
      "Iteration=219\t Loss=3.4914734\t mu=2.6274478\t sigma=2.0791519\n",
      "Iteration=220\t Loss=3.4911387\t mu=2.6303208\t sigma=2.078821\n",
      "Iteration=221\t Loss=3.490804\t mu=2.6331944\t sigma=2.07849\n",
      "Iteration=222\t Loss=3.4904692\t mu=2.6360688\t sigma=2.0781589\n",
      "Iteration=223\t Loss=3.490134\t mu=2.638944\t sigma=2.0778275\n",
      "Iteration=224\t Loss=3.4897988\t mu=2.64182\t sigma=2.0774958\n",
      "Iteration=225\t Loss=3.4894633\t mu=2.6446967\t sigma=2.077164\n",
      "Iteration=226\t Loss=3.4891274\t mu=2.6475742\t sigma=2.076832\n",
      "Iteration=227\t Loss=3.4887915\t mu=2.6504524\t sigma=2.0765\n",
      "Iteration=228\t Loss=3.4884558\t mu=2.6533315\t sigma=2.0761676\n",
      "Iteration=229\t Loss=3.4881196\t mu=2.6562114\t sigma=2.075835\n",
      "Iteration=230\t Loss=3.4877832\t mu=2.659092\t sigma=2.0755024\n",
      "Iteration=231\t Loss=3.4874465\t mu=2.6619735\t sigma=2.0751696\n",
      "Iteration=232\t Loss=3.4871097\t mu=2.6648557\t sigma=2.0748365\n",
      "Iteration=233\t Loss=3.4867725\t mu=2.6677387\t sigma=2.0745032\n",
      "Iteration=234\t Loss=3.4864357\t mu=2.6706223\t sigma=2.0741696\n",
      "Iteration=235\t Loss=3.4860985\t mu=2.673507\t sigma=2.073836\n",
      "Iteration=236\t Loss=3.485761\t mu=2.6763923\t sigma=2.0735023\n",
      "Iteration=237\t Loss=3.485423\t mu=2.6792784\t sigma=2.0731683\n",
      "Iteration=238\t Loss=3.4850855\t mu=2.6821654\t sigma=2.072834\n",
      "Iteration=239\t Loss=3.4847472\t mu=2.685053\t sigma=2.0724998\n",
      "Iteration=240\t Loss=3.484409\t mu=2.6879416\t sigma=2.0721653\n",
      "Iteration=241\t Loss=3.4840703\t mu=2.690831\t sigma=2.0718305\n",
      "Iteration=242\t Loss=3.4837325\t mu=2.693721\t sigma=2.0714955\n",
      "Iteration=243\t Loss=3.483393\t mu=2.696612\t sigma=2.0711603\n",
      "Iteration=244\t Loss=3.483054\t mu=2.6995037\t sigma=2.070825\n",
      "Iteration=245\t Loss=3.4827144\t mu=2.7023962\t sigma=2.0704896\n",
      "Iteration=246\t Loss=3.4823754\t mu=2.7052894\t sigma=2.070154\n",
      "Iteration=247\t Loss=3.4820359\t mu=2.7081833\t sigma=2.069818\n",
      "Iteration=248\t Loss=3.4816957\t mu=2.7110782\t sigma=2.069482\n",
      "Iteration=249\t Loss=3.4813561\t mu=2.7139738\t sigma=2.069146\n",
      "Iteration=250\t Loss=3.481016\t mu=2.71687\t sigma=2.0688095\n",
      "Iteration=251\t Loss=3.4806755\t mu=2.7197673\t sigma=2.0684729\n",
      "Iteration=252\t Loss=3.4803348\t mu=2.7226653\t sigma=2.068136\n",
      "Iteration=253\t Loss=3.4799945\t mu=2.725564\t sigma=2.067799\n",
      "Iteration=254\t Loss=3.4796536\t mu=2.7284636\t sigma=2.067462\n",
      "Iteration=255\t Loss=3.4793124\t mu=2.731364\t sigma=2.0671246\n",
      "Iteration=256\t Loss=3.478971\t mu=2.734265\t sigma=2.066787\n",
      "Iteration=257\t Loss=3.4786296\t mu=2.7371671\t sigma=2.0664492\n",
      "Iteration=258\t Loss=3.478288\t mu=2.7400699\t sigma=2.0661113\n",
      "Iteration=259\t Loss=3.477946\t mu=2.7429733\t sigma=2.0657732\n",
      "Iteration=260\t Loss=3.477604\t mu=2.7458777\t sigma=2.065435\n",
      "Iteration=261\t Loss=3.4772618\t mu=2.7487829\t sigma=2.0650964\n",
      "Iteration=262\t Loss=3.4769194\t mu=2.751689\t sigma=2.0647578\n",
      "Iteration=263\t Loss=3.476577\t mu=2.7545958\t sigma=2.064419\n",
      "Iteration=264\t Loss=3.476234\t mu=2.7575033\t sigma=2.06408\n",
      "Iteration=265\t Loss=3.475891\t mu=2.7604117\t sigma=2.0637407\n",
      "Iteration=266\t Loss=3.475548\t mu=2.763321\t sigma=2.0634012\n",
      "Iteration=267\t Loss=3.4752047\t mu=2.7662308\t sigma=2.0630617\n",
      "Iteration=268\t Loss=3.474861\t mu=2.7691417\t sigma=2.062722\n",
      "Iteration=269\t Loss=3.4745169\t mu=2.7720532\t sigma=2.062382\n",
      "Iteration=270\t Loss=3.4741735\t mu=2.7749655\t sigma=2.0620418\n",
      "Iteration=271\t Loss=3.4738293\t mu=2.7778788\t sigma=2.0617013\n",
      "Iteration=272\t Loss=3.4734852\t mu=2.7807927\t sigma=2.0613608\n",
      "Iteration=273\t Loss=3.4731402\t mu=2.7837076\t sigma=2.0610201\n",
      "Iteration=274\t Loss=3.4727952\t mu=2.7866232\t sigma=2.0606792\n",
      "Iteration=275\t Loss=3.4724507\t mu=2.7895396\t sigma=2.060338\n",
      "Iteration=276\t Loss=3.4721055\t mu=2.7924569\t sigma=2.0599966\n",
      "Iteration=277\t Loss=3.4717603\t mu=2.7953749\t sigma=2.0596552\n",
      "Iteration=278\t Loss=3.4714146\t mu=2.7982936\t sigma=2.0593135\n",
      "Iteration=279\t Loss=3.4710689\t mu=2.8012133\t sigma=2.0589716\n",
      "Iteration=280\t Loss=3.4707232\t mu=2.8041337\t sigma=2.0586295\n",
      "Iteration=281\t Loss=3.4703765\t mu=2.807055\t sigma=2.0582871\n",
      "Iteration=282\t Loss=3.4700308\t mu=2.809977\t sigma=2.0579448\n",
      "Iteration=283\t Loss=3.469684\t mu=2.8128998\t sigma=2.0576022\n",
      "Iteration=284\t Loss=3.4693375\t mu=2.8158236\t sigma=2.0572593\n",
      "Iteration=285\t Loss=3.4689906\t mu=2.818748\t sigma=2.0569162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=286\t Loss=3.4686437\t mu=2.8216734\t sigma=2.056573\n",
      "Iteration=287\t Loss=3.468296\t mu=2.8245995\t sigma=2.0562296\n",
      "Iteration=288\t Loss=3.467949\t mu=2.8275263\t sigma=2.055886\n",
      "Iteration=289\t Loss=3.4676015\t mu=2.830454\t sigma=2.0555422\n",
      "Iteration=290\t Loss=3.4672534\t mu=2.8333826\t sigma=2.0551982\n",
      "Iteration=291\t Loss=3.466905\t mu=2.836312\t sigma=2.054854\n",
      "Iteration=292\t Loss=3.466557\t mu=2.8392422\t sigma=2.0545096\n",
      "Iteration=293\t Loss=3.4662087\t mu=2.8421733\t sigma=2.0541651\n",
      "Iteration=294\t Loss=3.4658601\t mu=2.8451052\t sigma=2.0538204\n",
      "Iteration=295\t Loss=3.4655108\t mu=2.8480377\t sigma=2.0534754\n",
      "Iteration=296\t Loss=3.465162\t mu=2.8509712\t sigma=2.0531301\n",
      "Iteration=297\t Loss=3.464813\t mu=2.8539054\t sigma=2.052785\n",
      "Iteration=298\t Loss=3.4644637\t mu=2.8568406\t sigma=2.0524395\n",
      "Iteration=299\t Loss=3.464114\t mu=2.8597765\t sigma=2.0520937\n",
      "Iteration=300\t Loss=3.4637644\t mu=2.8627133\t sigma=2.0517478\n",
      "Iteration=301\t Loss=3.463414\t mu=2.865651\t sigma=2.0514016\n",
      "Iteration=302\t Loss=3.463064\t mu=2.8685892\t sigma=2.0510552\n",
      "Iteration=303\t Loss=3.4627132\t mu=2.8715284\t sigma=2.0507088\n",
      "Iteration=304\t Loss=3.462363\t mu=2.8744683\t sigma=2.050362\n",
      "Iteration=305\t Loss=3.462012\t mu=2.8774092\t sigma=2.0500152\n",
      "Iteration=306\t Loss=3.4616609\t mu=2.8803508\t sigma=2.049668\n",
      "Iteration=307\t Loss=3.4613101\t mu=2.8832934\t sigma=2.0493207\n",
      "Iteration=308\t Loss=3.4609585\t mu=2.8862367\t sigma=2.0489733\n",
      "Iteration=309\t Loss=3.460607\t mu=2.889181\t sigma=2.0486257\n",
      "Iteration=310\t Loss=3.4602554\t mu=2.8921258\t sigma=2.0482779\n",
      "Iteration=311\t Loss=3.4599032\t mu=2.8950717\t sigma=2.0479298\n",
      "Iteration=312\t Loss=3.4595509\t mu=2.8980184\t sigma=2.0475814\n",
      "Iteration=313\t Loss=3.4591985\t mu=2.9009657\t sigma=2.0472329\n",
      "Iteration=314\t Loss=3.4588456\t mu=2.903914\t sigma=2.0468843\n",
      "Iteration=315\t Loss=3.458493\t mu=2.906863\t sigma=2.0465355\n",
      "Iteration=316\t Loss=3.45814\t mu=2.909813\t sigma=2.0461864\n",
      "Iteration=317\t Loss=3.4577868\t mu=2.9127636\t sigma=2.0458372\n",
      "Iteration=318\t Loss=3.4574337\t mu=2.9157152\t sigma=2.0454876\n",
      "Iteration=319\t Loss=3.4570796\t mu=2.9186676\t sigma=2.045138\n",
      "Iteration=320\t Loss=3.456726\t mu=2.9216208\t sigma=2.0447881\n",
      "Iteration=321\t Loss=3.4563718\t mu=2.9245749\t sigma=2.0444381\n",
      "Iteration=322\t Loss=3.456018\t mu=2.9275298\t sigma=2.044088\n",
      "Iteration=323\t Loss=3.4556632\t mu=2.9304855\t sigma=2.0437374\n",
      "Iteration=324\t Loss=3.455309\t mu=2.933442\t sigma=2.0433867\n",
      "Iteration=325\t Loss=3.4549544\t mu=2.9363995\t sigma=2.043036\n",
      "Iteration=326\t Loss=3.4545991\t mu=2.9393578\t sigma=2.042685\n",
      "Iteration=327\t Loss=3.4542434\t mu=2.9423168\t sigma=2.0423338\n",
      "Iteration=328\t Loss=3.4538882\t mu=2.9452767\t sigma=2.0419824\n",
      "Iteration=329\t Loss=3.4535327\t mu=2.9482374\t sigma=2.0416307\n",
      "Iteration=330\t Loss=3.453177\t mu=2.951199\t sigma=2.0412788\n",
      "Iteration=331\t Loss=3.4528208\t mu=2.9541614\t sigma=2.0409267\n",
      "Iteration=332\t Loss=3.4524643\t mu=2.9571247\t sigma=2.0405746\n",
      "Iteration=333\t Loss=3.452108\t mu=2.9600887\t sigma=2.0402222\n",
      "Iteration=334\t Loss=3.4517512\t mu=2.9630537\t sigma=2.0398695\n",
      "Iteration=335\t Loss=3.4513946\t mu=2.9660194\t sigma=2.0395167\n",
      "Iteration=336\t Loss=3.4510372\t mu=2.968986\t sigma=2.0391636\n",
      "Iteration=337\t Loss=3.45068\t mu=2.9719534\t sigma=2.0388103\n",
      "Iteration=338\t Loss=3.4503226\t mu=2.9749217\t sigma=2.038457\n",
      "Iteration=339\t Loss=3.4499652\t mu=2.9778907\t sigma=2.0381033\n",
      "Iteration=340\t Loss=3.4496071\t mu=2.9808607\t sigma=2.0377495\n",
      "Iteration=341\t Loss=3.4492495\t mu=2.9838314\t sigma=2.0373955\n",
      "Iteration=342\t Loss=3.4488907\t mu=2.986803\t sigma=2.0370412\n",
      "Iteration=343\t Loss=3.4485323\t mu=2.9897754\t sigma=2.0366867\n",
      "Iteration=344\t Loss=3.4481738\t mu=2.9927487\t sigma=2.036332\n",
      "Iteration=345\t Loss=3.4478145\t mu=2.995723\t sigma=2.0359771\n",
      "Iteration=346\t Loss=3.4474554\t mu=2.998698\t sigma=2.0356221\n",
      "Iteration=347\t Loss=3.447096\t mu=3.001674\t sigma=2.0352669\n",
      "Iteration=348\t Loss=3.4467368\t mu=3.0046506\t sigma=2.0349114\n",
      "Iteration=349\t Loss=3.446377\t mu=3.0076282\t sigma=2.0345557\n",
      "Iteration=350\t Loss=3.4460168\t mu=3.0106065\t sigma=2.0341997\n",
      "Iteration=351\t Loss=3.4456565\t mu=3.0135858\t sigma=2.0338438\n",
      "Iteration=352\t Loss=3.445296\t mu=3.0165658\t sigma=2.0334876\n",
      "Iteration=353\t Loss=3.4449363\t mu=3.0195467\t sigma=2.0331311\n",
      "Iteration=354\t Loss=3.4445753\t mu=3.0225286\t sigma=2.0327744\n",
      "Iteration=355\t Loss=3.4442136\t mu=3.0255113\t sigma=2.0324175\n",
      "Iteration=356\t Loss=3.4438527\t mu=3.0284948\t sigma=2.0320604\n",
      "Iteration=357\t Loss=3.443491\t mu=3.0314791\t sigma=2.031703\n",
      "Iteration=358\t Loss=3.4431298\t mu=3.0344644\t sigma=2.0313454\n",
      "Iteration=359\t Loss=3.4427683\t mu=3.0374503\t sigma=2.0309877\n",
      "Iteration=360\t Loss=3.442406\t mu=3.0404372\t sigma=2.0306299\n",
      "Iteration=361\t Loss=3.4420438\t mu=3.043425\t sigma=2.0302718\n",
      "Iteration=362\t Loss=3.4416811\t mu=3.0464137\t sigma=2.0299134\n",
      "Iteration=363\t Loss=3.4413188\t mu=3.0494032\t sigma=2.0295548\n",
      "Iteration=364\t Loss=3.4409559\t mu=3.0523934\t sigma=2.029196\n",
      "Iteration=365\t Loss=3.4405925\t mu=3.0553846\t sigma=2.028837\n",
      "Iteration=366\t Loss=3.4402294\t mu=3.0583766\t sigma=2.028478\n",
      "Iteration=367\t Loss=3.439866\t mu=3.0613694\t sigma=2.0281186\n",
      "Iteration=368\t Loss=3.439502\t mu=3.0643632\t sigma=2.027759\n",
      "Iteration=369\t Loss=3.4391382\t mu=3.0673578\t sigma=2.0273993\n",
      "Iteration=370\t Loss=3.438774\t mu=3.0703533\t sigma=2.0270393\n",
      "Iteration=371\t Loss=3.4384093\t mu=3.0733495\t sigma=2.026679\n",
      "Iteration=372\t Loss=3.438045\t mu=3.0763466\t sigma=2.0263186\n",
      "Iteration=373\t Loss=3.43768\t mu=3.0793447\t sigma=2.025958\n",
      "Iteration=374\t Loss=3.4373152\t mu=3.0823436\t sigma=2.0255973\n",
      "Iteration=375\t Loss=3.43695\t mu=3.0853434\t sigma=2.0252364\n",
      "Iteration=376\t Loss=3.4365847\t mu=3.0883439\t sigma=2.0248752\n",
      "Iteration=377\t Loss=3.4362192\t mu=3.0913453\t sigma=2.0245137\n",
      "Iteration=378\t Loss=3.4358532\t mu=3.0943477\t sigma=2.024152\n",
      "Iteration=379\t Loss=3.435487\t mu=3.0973508\t sigma=2.0237901\n",
      "Iteration=380\t Loss=3.4351208\t mu=3.100355\t sigma=2.023428\n",
      "Iteration=381\t Loss=3.4347544\t mu=3.10336\t sigma=2.0230656\n",
      "Iteration=382\t Loss=3.4343874\t mu=3.1063657\t sigma=2.0227032\n",
      "Iteration=383\t Loss=3.434021\t mu=3.1093724\t sigma=2.0223405\n",
      "Iteration=384\t Loss=3.4336538\t mu=3.1123798\t sigma=2.0219777\n",
      "Iteration=385\t Loss=3.4332864\t mu=3.1153882\t sigma=2.0216146\n",
      "Iteration=386\t Loss=3.4329188\t mu=3.1183975\t sigma=2.0212512\n",
      "Iteration=387\t Loss=3.4325511\t mu=3.1214075\t sigma=2.0208876\n",
      "Iteration=388\t Loss=3.4321833\t mu=3.1244185\t sigma=2.0205238\n",
      "Iteration=389\t Loss=3.431815\t mu=3.1274304\t sigma=2.0201597\n",
      "Iteration=390\t Loss=3.4314468\t mu=3.130443\t sigma=2.0197957\n",
      "Iteration=391\t Loss=3.4310777\t mu=3.1334567\t sigma=2.0194314\n",
      "Iteration=392\t Loss=3.430709\t mu=3.1364713\t sigma=2.0190668\n",
      "Iteration=393\t Loss=3.4303398\t mu=3.1394866\t sigma=2.018702\n",
      "Iteration=394\t Loss=3.4299707\t mu=3.1425028\t sigma=2.018337\n",
      "Iteration=395\t Loss=3.4296017\t mu=3.1455197\t sigma=2.0179718\n",
      "Iteration=396\t Loss=3.4292312\t mu=3.1485376\t sigma=2.0176063\n",
      "Iteration=397\t Loss=3.4288616\t mu=3.1515565\t sigma=2.0172405\n",
      "Iteration=398\t Loss=3.428491\t mu=3.154576\t sigma=2.0168746\n",
      "Iteration=399\t Loss=3.428121\t mu=3.1575966\t sigma=2.0165083\n",
      "Iteration=400\t Loss=3.4277503\t mu=3.160618\t sigma=2.0161421\n",
      "Iteration=401\t Loss=3.4273796\t mu=3.1636403\t sigma=2.0157757\n",
      "Iteration=402\t Loss=3.4270086\t mu=3.1666634\t sigma=2.015409\n",
      "Iteration=403\t Loss=3.4266372\t mu=3.1696875\t sigma=2.015042\n",
      "Iteration=404\t Loss=3.4262657\t mu=3.1727123\t sigma=2.014675\n",
      "Iteration=405\t Loss=3.425894\t mu=3.175738\t sigma=2.0143075\n",
      "Iteration=406\t Loss=3.4255219\t mu=3.1787648\t sigma=2.0139399\n",
      "Iteration=407\t Loss=3.4251504\t mu=3.1817925\t sigma=2.013572\n",
      "Iteration=408\t Loss=3.4247777\t mu=3.184821\t sigma=2.0132039\n",
      "Iteration=409\t Loss=3.4244056\t mu=3.1878502\t sigma=2.0128357\n",
      "Iteration=410\t Loss=3.4240324\t mu=3.1908805\t sigma=2.0124674\n",
      "Iteration=411\t Loss=3.4236593\t mu=3.1939116\t sigma=2.0120988\n",
      "Iteration=412\t Loss=3.4232864\t mu=3.1969435\t sigma=2.01173\n",
      "Iteration=413\t Loss=3.4229133\t mu=3.1999764\t sigma=2.011361\n",
      "Iteration=414\t Loss=3.4225395\t mu=3.20301\t sigma=2.0109916\n",
      "Iteration=415\t Loss=3.4221652\t mu=3.2060447\t sigma=2.010622\n",
      "Iteration=416\t Loss=3.4217906\t mu=3.2090802\t sigma=2.0102522\n",
      "Iteration=417\t Loss=3.4214172\t mu=3.2121165\t sigma=2.0098822\n",
      "Iteration=418\t Loss=3.4210427\t mu=3.2151537\t sigma=2.009512\n",
      "Iteration=419\t Loss=3.4206676\t mu=3.2181919\t sigma=2.0091414\n",
      "Iteration=420\t Loss=3.4202926\t mu=3.221231\t sigma=2.008771\n",
      "Iteration=421\t Loss=3.419918\t mu=3.2242708\t sigma=2.0084002\n",
      "Iteration=422\t Loss=3.419542\t mu=3.2273116\t sigma=2.0080292\n",
      "Iteration=423\t Loss=3.4191668\t mu=3.2303534\t sigma=2.007658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=424\t Loss=3.4187906\t mu=3.2333958\t sigma=2.0072865\n",
      "Iteration=425\t Loss=3.4184148\t mu=3.2364392\t sigma=2.0069149\n",
      "Iteration=426\t Loss=3.4180384\t mu=3.2394836\t sigma=2.006543\n",
      "Iteration=427\t Loss=3.4176614\t mu=3.242529\t sigma=2.0061707\n",
      "Iteration=428\t Loss=3.4172852\t mu=3.245575\t sigma=2.0057983\n",
      "Iteration=429\t Loss=3.4169078\t mu=3.248622\t sigma=2.0054257\n",
      "Iteration=430\t Loss=3.4165308\t mu=3.25167\t sigma=2.0050528\n",
      "Iteration=431\t Loss=3.4161534\t mu=3.2547188\t sigma=2.0046797\n",
      "Iteration=432\t Loss=3.4157758\t mu=3.2577684\t sigma=2.0043063\n",
      "Iteration=433\t Loss=3.4153976\t mu=3.260819\t sigma=2.003933\n",
      "Iteration=434\t Loss=3.4150195\t mu=3.2638705\t sigma=2.0035594\n",
      "Iteration=435\t Loss=3.4146414\t mu=3.266923\t sigma=2.0031855\n",
      "Iteration=436\t Loss=3.4142628\t mu=3.2699761\t sigma=2.0028114\n",
      "Iteration=437\t Loss=3.413884\t mu=3.2730303\t sigma=2.002437\n",
      "Iteration=438\t Loss=3.413505\t mu=3.2760854\t sigma=2.0020626\n",
      "Iteration=439\t Loss=3.4131258\t mu=3.2791414\t sigma=2.0016878\n",
      "Iteration=440\t Loss=3.4127464\t mu=3.2821982\t sigma=2.0013127\n",
      "Iteration=441\t Loss=3.4123669\t mu=3.285256\t sigma=2.0009375\n",
      "Iteration=442\t Loss=3.4119868\t mu=3.2883146\t sigma=2.000562\n",
      "Iteration=443\t Loss=3.4116063\t mu=3.2913742\t sigma=2.0001862\n",
      "Iteration=444\t Loss=3.4112263\t mu=3.2944345\t sigma=1.9998103\n",
      "Iteration=445\t Loss=3.4108458\t mu=3.2974958\t sigma=1.9994342\n",
      "Iteration=446\t Loss=3.4104648\t mu=3.300558\t sigma=1.9990579\n",
      "Iteration=447\t Loss=3.410084\t mu=3.3036213\t sigma=1.9986813\n",
      "Iteration=448\t Loss=3.4097023\t mu=3.3066854\t sigma=1.9983045\n",
      "Iteration=449\t Loss=3.409321\t mu=3.3097503\t sigma=1.9979274\n",
      "Iteration=450\t Loss=3.4089391\t mu=3.3128161\t sigma=1.9975501\n",
      "Iteration=451\t Loss=3.4085574\t mu=3.315883\t sigma=1.9971727\n",
      "Iteration=452\t Loss=3.4081755\t mu=3.3189507\t sigma=1.996795\n",
      "Iteration=453\t Loss=3.4077926\t mu=3.3220193\t sigma=1.9964172\n",
      "Iteration=454\t Loss=3.4074097\t mu=3.3250887\t sigma=1.996039\n",
      "Iteration=455\t Loss=3.407027\t mu=3.328159\t sigma=1.9956607\n",
      "Iteration=456\t Loss=3.4066439\t mu=3.3312304\t sigma=1.995282\n",
      "Iteration=457\t Loss=3.4062605\t mu=3.3343027\t sigma=1.9949032\n",
      "Iteration=458\t Loss=3.4058769\t mu=3.3373759\t sigma=1.9945241\n",
      "Iteration=459\t Loss=3.4054933\t mu=3.3404498\t sigma=1.9941448\n",
      "Iteration=460\t Loss=3.4051094\t mu=3.3435247\t sigma=1.9937652\n",
      "Iteration=461\t Loss=3.404725\t mu=3.3466005\t sigma=1.9933856\n",
      "Iteration=462\t Loss=3.4043407\t mu=3.3496773\t sigma=1.9930056\n",
      "Iteration=463\t Loss=3.403956\t mu=3.352755\t sigma=1.9926255\n",
      "Iteration=464\t Loss=3.4035711\t mu=3.3558335\t sigma=1.9922451\n",
      "Iteration=465\t Loss=3.4031858\t mu=3.358913\t sigma=1.9918644\n",
      "Iteration=466\t Loss=3.4028003\t mu=3.3619933\t sigma=1.9914836\n",
      "Iteration=467\t Loss=3.4024148\t mu=3.3650746\t sigma=1.9911025\n",
      "Iteration=468\t Loss=3.4020288\t mu=3.368157\t sigma=1.9907211\n",
      "Iteration=469\t Loss=3.4016426\t mu=3.3712401\t sigma=1.9903395\n",
      "Iteration=470\t Loss=3.4012563\t mu=3.374324\t sigma=1.9899577\n",
      "Iteration=471\t Loss=3.4008698\t mu=3.377409\t sigma=1.9895757\n",
      "Iteration=472\t Loss=3.4004831\t mu=3.3804948\t sigma=1.9891936\n",
      "Iteration=473\t Loss=3.4000957\t mu=3.3835816\t sigma=1.9888111\n",
      "Iteration=474\t Loss=3.3997085\t mu=3.3866694\t sigma=1.9884285\n",
      "Iteration=475\t Loss=3.399321\t mu=3.389758\t sigma=1.9880456\n",
      "Iteration=476\t Loss=3.3989332\t mu=3.3928475\t sigma=1.9876624\n",
      "Iteration=477\t Loss=3.3985453\t mu=3.395938\t sigma=1.987279\n",
      "Iteration=478\t Loss=3.3981571\t mu=3.3990293\t sigma=1.9868954\n",
      "Iteration=479\t Loss=3.3977687\t mu=3.4021215\t sigma=1.9865116\n",
      "Iteration=480\t Loss=3.39738\t mu=3.4052148\t sigma=1.9861275\n",
      "Iteration=481\t Loss=3.3969915\t mu=3.408309\t sigma=1.9857432\n",
      "Iteration=482\t Loss=3.396602\t mu=3.4114041\t sigma=1.9853586\n",
      "Iteration=483\t Loss=3.3962126\t mu=3.4145\t sigma=1.9849738\n",
      "Iteration=484\t Loss=3.395823\t mu=3.4175968\t sigma=1.9845887\n",
      "Iteration=485\t Loss=3.3954332\t mu=3.4206946\t sigma=1.9842036\n",
      "Iteration=486\t Loss=3.395043\t mu=3.4237933\t sigma=1.9838182\n",
      "Iteration=487\t Loss=3.3946528\t mu=3.426893\t sigma=1.9834325\n",
      "Iteration=488\t Loss=3.394262\t mu=3.4299936\t sigma=1.9830467\n",
      "Iteration=489\t Loss=3.3938718\t mu=3.4330952\t sigma=1.9826605\n",
      "Iteration=490\t Loss=3.3934805\t mu=3.4361978\t sigma=1.9822742\n",
      "Iteration=491\t Loss=3.393089\t mu=3.439301\t sigma=1.9818876\n",
      "Iteration=492\t Loss=3.3926976\t mu=3.4424052\t sigma=1.9815007\n",
      "Iteration=493\t Loss=3.3923059\t mu=3.4455104\t sigma=1.9811137\n",
      "Iteration=494\t Loss=3.3919141\t mu=3.4486165\t sigma=1.9807264\n",
      "Iteration=495\t Loss=3.3915215\t mu=3.4517236\t sigma=1.9803388\n",
      "Iteration=496\t Loss=3.391129\t mu=3.4548316\t sigma=1.979951\n",
      "Iteration=497\t Loss=3.3907363\t mu=3.4579406\t sigma=1.979563\n",
      "Iteration=498\t Loss=3.3903434\t mu=3.4610505\t sigma=1.9791747\n",
      "Iteration=499\t Loss=3.3899503\t mu=3.4641614\t sigma=1.9787862\n",
      "Iteration=500\t Loss=3.3895566\t mu=3.4672732\t sigma=1.9783975\n",
      "Iteration=501\t Loss=3.3891637\t mu=3.4703858\t sigma=1.9780085\n",
      "Iteration=502\t Loss=3.3887691\t mu=3.4734993\t sigma=1.9776193\n",
      "Iteration=503\t Loss=3.388375\t mu=3.4766138\t sigma=1.9772298\n",
      "Iteration=504\t Loss=3.387981\t mu=3.4797292\t sigma=1.9768401\n",
      "Iteration=505\t Loss=3.3875864\t mu=3.4828455\t sigma=1.9764502\n",
      "Iteration=506\t Loss=3.3871918\t mu=3.4859629\t sigma=1.97606\n",
      "Iteration=507\t Loss=3.386796\t mu=3.4890811\t sigma=1.9756696\n",
      "Iteration=508\t Loss=3.3864007\t mu=3.4922004\t sigma=1.975279\n",
      "Iteration=509\t Loss=3.3860059\t mu=3.4953206\t sigma=1.9748881\n",
      "Iteration=510\t Loss=3.3856099\t mu=3.4984417\t sigma=1.974497\n",
      "Iteration=511\t Loss=3.3852136\t mu=3.5015638\t sigma=1.9741057\n",
      "Iteration=512\t Loss=3.3848171\t mu=3.5046868\t sigma=1.9737141\n",
      "Iteration=513\t Loss=3.3844204\t mu=3.5078108\t sigma=1.9733224\n",
      "Iteration=514\t Loss=3.384024\t mu=3.5109358\t sigma=1.9729303\n",
      "Iteration=515\t Loss=3.383627\t mu=3.5140615\t sigma=1.9725381\n",
      "Iteration=516\t Loss=3.3832297\t mu=3.517188\t sigma=1.9721456\n",
      "Iteration=517\t Loss=3.382832\t mu=3.5203156\t sigma=1.9717529\n",
      "Iteration=518\t Loss=3.3824344\t mu=3.5234442\t sigma=1.9713598\n",
      "Iteration=519\t Loss=3.382036\t mu=3.5265737\t sigma=1.9709667\n",
      "Iteration=520\t Loss=3.3816378\t mu=3.529704\t sigma=1.9705732\n",
      "Iteration=521\t Loss=3.3812392\t mu=3.5328355\t sigma=1.9701794\n",
      "Iteration=522\t Loss=3.3808405\t mu=3.5359678\t sigma=1.9697855\n",
      "Iteration=523\t Loss=3.3804421\t mu=3.5391011\t sigma=1.9693913\n",
      "Iteration=524\t Loss=3.3800426\t mu=3.5422354\t sigma=1.9689969\n",
      "Iteration=525\t Loss=3.379643\t mu=3.5453706\t sigma=1.9686022\n",
      "Iteration=526\t Loss=3.3792434\t mu=3.5485067\t sigma=1.9682072\n",
      "Iteration=527\t Loss=3.3788433\t mu=3.5516438\t sigma=1.9678121\n",
      "Iteration=528\t Loss=3.378443\t mu=3.554782\t sigma=1.9674166\n",
      "Iteration=529\t Loss=3.3780425\t mu=3.557921\t sigma=1.967021\n",
      "Iteration=530\t Loss=3.3776422\t mu=3.561061\t sigma=1.9666251\n",
      "Iteration=531\t Loss=3.3772411\t mu=3.5642018\t sigma=1.966229\n",
      "Iteration=532\t Loss=3.3768399\t mu=3.5673437\t sigma=1.9658326\n",
      "Iteration=533\t Loss=3.3764386\t mu=3.5704865\t sigma=1.965436\n",
      "Iteration=534\t Loss=3.3760364\t mu=3.5736303\t sigma=1.9650391\n",
      "Iteration=535\t Loss=3.3756351\t mu=3.576775\t sigma=1.964642\n",
      "Iteration=536\t Loss=3.3752327\t mu=3.5799208\t sigma=1.9642447\n",
      "Iteration=537\t Loss=3.37483\t mu=3.5830674\t sigma=1.9638472\n",
      "Iteration=538\t Loss=3.3744273\t mu=3.586215\t sigma=1.9634494\n",
      "Iteration=539\t Loss=3.3740246\t mu=3.5893636\t sigma=1.9630513\n",
      "Iteration=540\t Loss=3.373621\t mu=3.592513\t sigma=1.962653\n",
      "Iteration=541\t Loss=3.3732183\t mu=3.5956635\t sigma=1.9622545\n",
      "Iteration=542\t Loss=3.3728144\t mu=3.598815\t sigma=1.9618558\n",
      "Iteration=543\t Loss=3.3724105\t mu=3.6019673\t sigma=1.9614568\n",
      "Iteration=544\t Loss=3.372006\t mu=3.6051207\t sigma=1.9610575\n",
      "Iteration=545\t Loss=3.371602\t mu=3.608275\t sigma=1.9606581\n",
      "Iteration=546\t Loss=3.371197\t mu=3.6114302\t sigma=1.9602584\n",
      "Iteration=547\t Loss=3.3707922\t mu=3.6145864\t sigma=1.9598584\n",
      "Iteration=548\t Loss=3.3703866\t mu=3.6177435\t sigma=1.9594581\n",
      "Iteration=549\t Loss=3.3699815\t mu=3.6209016\t sigma=1.9590576\n",
      "Iteration=550\t Loss=3.3695757\t mu=3.6240606\t sigma=1.9586568\n",
      "Iteration=551\t Loss=3.36917\t mu=3.6272206\t sigma=1.9582558\n",
      "Iteration=552\t Loss=3.3687637\t mu=3.6303816\t sigma=1.9578545\n",
      "Iteration=553\t Loss=3.3683574\t mu=3.6335435\t sigma=1.957453\n",
      "Iteration=554\t Loss=3.3679504\t mu=3.6367064\t sigma=1.9570513\n",
      "Iteration=555\t Loss=3.3675442\t mu=3.6398702\t sigma=1.9566493\n",
      "Iteration=556\t Loss=3.3671367\t mu=3.643035\t sigma=1.9562471\n",
      "Iteration=557\t Loss=3.366729\t mu=3.6462007\t sigma=1.9558446\n",
      "Iteration=558\t Loss=3.3663216\t mu=3.6493673\t sigma=1.955442\n",
      "Iteration=559\t Loss=3.3659136\t mu=3.6525352\t sigma=1.955039\n",
      "Iteration=560\t Loss=3.3655055\t mu=3.655704\t sigma=1.9546359\n",
      "Iteration=561\t Loss=3.3650968\t mu=3.6588738\t sigma=1.9542325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=562\t Loss=3.3646884\t mu=3.6620445\t sigma=1.9538287\n",
      "Iteration=563\t Loss=3.3642788\t mu=3.6652162\t sigma=1.9534247\n",
      "Iteration=564\t Loss=3.36387\t mu=3.6683888\t sigma=1.9530205\n",
      "Iteration=565\t Loss=3.3634605\t mu=3.6715624\t sigma=1.952616\n",
      "Iteration=566\t Loss=3.3630505\t mu=3.674737\t sigma=1.9522113\n",
      "Iteration=567\t Loss=3.3626406\t mu=3.6779125\t sigma=1.9518063\n",
      "Iteration=568\t Loss=3.3622305\t mu=3.681089\t sigma=1.9514011\n",
      "Iteration=569\t Loss=3.36182\t mu=3.6842663\t sigma=1.9509957\n",
      "Iteration=570\t Loss=3.3614094\t mu=3.6874447\t sigma=1.95059\n",
      "Iteration=571\t Loss=3.3609982\t mu=3.690624\t sigma=1.9501841\n",
      "Iteration=572\t Loss=3.3605871\t mu=3.6938043\t sigma=1.9497778\n",
      "Iteration=573\t Loss=3.3601758\t mu=3.6969857\t sigma=1.9493713\n",
      "Iteration=574\t Loss=3.359764\t mu=3.7001681\t sigma=1.9489646\n",
      "Iteration=575\t Loss=3.3593516\t mu=3.7033515\t sigma=1.9485576\n",
      "Iteration=576\t Loss=3.3589394\t mu=3.7065358\t sigma=1.9481504\n",
      "Iteration=577\t Loss=3.358527\t mu=3.709721\t sigma=1.9477429\n",
      "Iteration=578\t Loss=3.3581138\t mu=3.7129073\t sigma=1.9473352\n",
      "Iteration=579\t Loss=3.357701\t mu=3.7160945\t sigma=1.9469273\n",
      "Iteration=580\t Loss=3.3572874\t mu=3.7192826\t sigma=1.946519\n",
      "Iteration=581\t Loss=3.3568742\t mu=3.7224717\t sigma=1.9461105\n",
      "Iteration=582\t Loss=3.3564606\t mu=3.7256618\t sigma=1.9457017\n",
      "Iteration=583\t Loss=3.3560462\t mu=3.728853\t sigma=1.9452927\n",
      "Iteration=584\t Loss=3.3556316\t mu=3.7320452\t sigma=1.9448835\n",
      "Iteration=585\t Loss=3.3552172\t mu=3.7352383\t sigma=1.944474\n",
      "Iteration=586\t Loss=3.3548024\t mu=3.7384324\t sigma=1.9440643\n",
      "Iteration=587\t Loss=3.354387\t mu=3.7416275\t sigma=1.9436542\n",
      "Iteration=588\t Loss=3.353972\t mu=3.7448235\t sigma=1.9432439\n",
      "Iteration=589\t Loss=3.3535562\t mu=3.7480204\t sigma=1.9428333\n",
      "Iteration=590\t Loss=3.35314\t mu=3.7512183\t sigma=1.9424225\n",
      "Iteration=591\t Loss=3.3527238\t mu=3.7544174\t sigma=1.9420115\n",
      "Iteration=592\t Loss=3.3523078\t mu=3.7576175\t sigma=1.9416002\n",
      "Iteration=593\t Loss=3.351891\t mu=3.7608185\t sigma=1.9411887\n",
      "Iteration=594\t Loss=3.3514743\t mu=3.7640204\t sigma=1.9407768\n",
      "Iteration=595\t Loss=3.351057\t mu=3.7672234\t sigma=1.9403647\n",
      "Iteration=596\t Loss=3.3506393\t mu=3.7704272\t sigma=1.9399524\n",
      "Iteration=597\t Loss=3.3502214\t mu=3.773632\t sigma=1.9395398\n",
      "Iteration=598\t Loss=3.3498034\t mu=3.776838\t sigma=1.939127\n",
      "Iteration=599\t Loss=3.3493853\t mu=3.780045\t sigma=1.9387139\n",
      "Iteration=600\t Loss=3.3489668\t mu=3.783253\t sigma=1.9383006\n",
      "Iteration=601\t Loss=3.3485484\t mu=3.7864618\t sigma=1.937887\n",
      "Iteration=602\t Loss=3.3481293\t mu=3.7896717\t sigma=1.937473\n",
      "Iteration=603\t Loss=3.3477097\t mu=3.7928824\t sigma=1.9370589\n",
      "Iteration=604\t Loss=3.3472903\t mu=3.7960944\t sigma=1.9366446\n",
      "Iteration=605\t Loss=3.3468704\t mu=3.7993073\t sigma=1.93623\n",
      "Iteration=606\t Loss=3.34645\t mu=3.8025212\t sigma=1.935815\n",
      "Iteration=607\t Loss=3.34603\t mu=3.805736\t sigma=1.9353998\n",
      "Iteration=608\t Loss=3.345609\t mu=3.8089519\t sigma=1.9349843\n",
      "Iteration=609\t Loss=3.3451884\t mu=3.8121686\t sigma=1.9345686\n",
      "Iteration=610\t Loss=3.344767\t mu=3.8153865\t sigma=1.9341527\n",
      "Iteration=611\t Loss=3.3443453\t mu=3.8186054\t sigma=1.9337366\n",
      "Iteration=612\t Loss=3.3439243\t mu=3.8218253\t sigma=1.93332\n",
      "Iteration=613\t Loss=3.3435023\t mu=3.825046\t sigma=1.9329033\n",
      "Iteration=614\t Loss=3.3430798\t mu=3.8282678\t sigma=1.9324863\n",
      "Iteration=615\t Loss=3.3426573\t mu=3.8314905\t sigma=1.9320691\n",
      "Iteration=616\t Loss=3.3422344\t mu=3.8347144\t sigma=1.9316516\n",
      "Iteration=617\t Loss=3.3418114\t mu=3.8379393\t sigma=1.9312338\n",
      "Iteration=618\t Loss=3.3413882\t mu=3.841165\t sigma=1.9308157\n",
      "Iteration=619\t Loss=3.3409646\t mu=3.8443918\t sigma=1.9303974\n",
      "Iteration=620\t Loss=3.3405411\t mu=3.8476195\t sigma=1.9299788\n",
      "Iteration=621\t Loss=3.3401167\t mu=3.8508484\t sigma=1.9295601\n",
      "Iteration=622\t Loss=3.3396926\t mu=3.8540783\t sigma=1.9291409\n",
      "Iteration=623\t Loss=3.339268\t mu=3.857309\t sigma=1.9287215\n",
      "Iteration=624\t Loss=3.3388433\t mu=3.8605409\t sigma=1.9283019\n",
      "Iteration=625\t Loss=3.338418\t mu=3.8637738\t sigma=1.9278821\n",
      "Iteration=626\t Loss=3.3379922\t mu=3.8670077\t sigma=1.927462\n",
      "Iteration=627\t Loss=3.3375664\t mu=3.8702426\t sigma=1.9270415\n",
      "Iteration=628\t Loss=3.3371406\t mu=3.8734784\t sigma=1.9266208\n",
      "Iteration=629\t Loss=3.3367145\t mu=3.8767152\t sigma=1.9261999\n",
      "Iteration=630\t Loss=3.336288\t mu=3.8799531\t sigma=1.9257787\n",
      "Iteration=631\t Loss=3.335861\t mu=3.883192\t sigma=1.9253572\n",
      "Iteration=632\t Loss=3.3354344\t mu=3.886432\t sigma=1.9249355\n",
      "Iteration=633\t Loss=3.3350067\t mu=3.8896728\t sigma=1.9245135\n",
      "Iteration=634\t Loss=3.334579\t mu=3.8929148\t sigma=1.9240912\n",
      "Iteration=635\t Loss=3.3341513\t mu=3.8961577\t sigma=1.9236686\n",
      "Iteration=636\t Loss=3.3337226\t mu=3.8994017\t sigma=1.9232458\n",
      "Iteration=637\t Loss=3.3332949\t mu=3.9026465\t sigma=1.9228227\n",
      "Iteration=638\t Loss=3.332866\t mu=3.9058926\t sigma=1.9223994\n",
      "Iteration=639\t Loss=3.3324368\t mu=3.9091396\t sigma=1.9219759\n",
      "Iteration=640\t Loss=3.332008\t mu=3.9123876\t sigma=1.921552\n",
      "Iteration=641\t Loss=3.331578\t mu=3.9156365\t sigma=1.9211278\n",
      "Iteration=642\t Loss=3.3311484\t mu=3.9188867\t sigma=1.9207034\n",
      "Iteration=643\t Loss=3.3307183\t mu=3.9221377\t sigma=1.9202788\n",
      "Iteration=644\t Loss=3.330288\t mu=3.9253898\t sigma=1.9198538\n",
      "Iteration=645\t Loss=3.3298578\t mu=3.9286427\t sigma=1.9194286\n",
      "Iteration=646\t Loss=3.3294265\t mu=3.931897\t sigma=1.9190031\n",
      "Iteration=647\t Loss=3.3289952\t mu=3.935152\t sigma=1.9185773\n",
      "Iteration=648\t Loss=3.3285642\t mu=3.9384081\t sigma=1.9181513\n",
      "Iteration=649\t Loss=3.3281324\t mu=3.9416654\t sigma=1.917725\n",
      "Iteration=650\t Loss=3.3277004\t mu=3.9449236\t sigma=1.9172984\n",
      "Iteration=651\t Loss=3.327268\t mu=3.9481828\t sigma=1.9168715\n",
      "Iteration=652\t Loss=3.3268356\t mu=3.951443\t sigma=1.9164444\n",
      "Iteration=653\t Loss=3.3264027\t mu=3.9547043\t sigma=1.916017\n",
      "Iteration=654\t Loss=3.3259695\t mu=3.9579666\t sigma=1.9155895\n",
      "Iteration=655\t Loss=3.3255363\t mu=3.9612298\t sigma=1.9151615\n",
      "Iteration=656\t Loss=3.3251028\t mu=3.9644942\t sigma=1.9147333\n",
      "Iteration=657\t Loss=3.3246684\t mu=3.9677596\t sigma=1.9143049\n",
      "Iteration=658\t Loss=3.3242347\t mu=3.971026\t sigma=1.913876\n",
      "Iteration=659\t Loss=3.3238\t mu=3.9742932\t sigma=1.913447\n",
      "Iteration=660\t Loss=3.3233657\t mu=3.9775617\t sigma=1.9130177\n",
      "Iteration=661\t Loss=3.32293\t mu=3.9808311\t sigma=1.9125882\n",
      "Iteration=662\t Loss=3.322495\t mu=3.9841015\t sigma=1.9121584\n",
      "Iteration=663\t Loss=3.3220594\t mu=3.987373\t sigma=1.9117283\n",
      "Iteration=664\t Loss=3.3216233\t mu=3.9906456\t sigma=1.9112979\n",
      "Iteration=665\t Loss=3.3211875\t mu=3.9939191\t sigma=1.9108672\n",
      "Iteration=666\t Loss=3.3207512\t mu=3.9971938\t sigma=1.9104363\n",
      "Iteration=667\t Loss=3.3203144\t mu=4.000469\t sigma=1.9100051\n",
      "Iteration=668\t Loss=3.3198774\t mu=4.003746\t sigma=1.9095737\n",
      "Iteration=669\t Loss=3.3194401\t mu=4.007024\t sigma=1.9091419\n",
      "Iteration=670\t Loss=3.3190024\t mu=4.0103025\t sigma=1.9087099\n",
      "Iteration=671\t Loss=3.318565\t mu=4.013582\t sigma=1.9082776\n",
      "Iteration=672\t Loss=3.318127\t mu=4.016863\t sigma=1.907845\n",
      "Iteration=673\t Loss=3.3176887\t mu=4.0201445\t sigma=1.9074122\n",
      "Iteration=674\t Loss=3.31725\t mu=4.0234275\t sigma=1.9069791\n",
      "Iteration=675\t Loss=3.3168108\t mu=4.0267115\t sigma=1.9065456\n",
      "Iteration=676\t Loss=3.316372\t mu=4.0299964\t sigma=1.906112\n",
      "Iteration=677\t Loss=3.3159325\t mu=4.0332823\t sigma=1.905678\n",
      "Iteration=678\t Loss=3.3154922\t mu=4.036569\t sigma=1.9052438\n",
      "Iteration=679\t Loss=3.3150527\t mu=4.039857\t sigma=1.9048092\n",
      "Iteration=680\t Loss=3.3146122\t mu=4.043146\t sigma=1.9043745\n",
      "Iteration=681\t Loss=3.3141716\t mu=4.0464363\t sigma=1.9039394\n",
      "Iteration=682\t Loss=3.3137305\t mu=4.0497274\t sigma=1.903504\n",
      "Iteration=683\t Loss=3.3132892\t mu=4.0530195\t sigma=1.9030684\n",
      "Iteration=684\t Loss=3.312848\t mu=4.0563126\t sigma=1.9026325\n",
      "Iteration=685\t Loss=3.3124063\t mu=4.059607\t sigma=1.9021963\n",
      "Iteration=686\t Loss=3.3119636\t mu=4.0629025\t sigma=1.9017599\n",
      "Iteration=687\t Loss=3.311521\t mu=4.066199\t sigma=1.9013231\n",
      "Iteration=688\t Loss=3.3110785\t mu=4.069496\t sigma=1.900886\n",
      "Iteration=689\t Loss=3.310636\t mu=4.0727944\t sigma=1.9004488\n",
      "Iteration=690\t Loss=3.3101926\t mu=4.0760937\t sigma=1.9000112\n",
      "Iteration=691\t Loss=3.3097491\t mu=4.0793943\t sigma=1.8995733\n",
      "Iteration=692\t Loss=3.3093054\t mu=4.082696\t sigma=1.8991352\n",
      "Iteration=693\t Loss=3.3088613\t mu=4.0859985\t sigma=1.8986968\n",
      "Iteration=694\t Loss=3.3084176\t mu=4.089302\t sigma=1.8982581\n",
      "Iteration=695\t Loss=3.3079727\t mu=4.0926065\t sigma=1.8978192\n",
      "Iteration=696\t Loss=3.3075278\t mu=4.0959125\t sigma=1.8973799\n",
      "Iteration=697\t Loss=3.3070824\t mu=4.0992193\t sigma=1.8969404\n",
      "Iteration=698\t Loss=3.306637\t mu=4.102527\t sigma=1.8965006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=699\t Loss=3.3061914\t mu=4.105836\t sigma=1.8960605\n",
      "Iteration=700\t Loss=3.3057454\t mu=4.1091456\t sigma=1.8956201\n",
      "Iteration=701\t Loss=3.3052988\t mu=4.112457\t sigma=1.8951794\n",
      "Iteration=702\t Loss=3.3048522\t mu=4.115769\t sigma=1.8947384\n",
      "Iteration=703\t Loss=3.3044055\t mu=4.119082\t sigma=1.8942972\n",
      "Iteration=704\t Loss=3.3039577\t mu=4.122396\t sigma=1.8938557\n",
      "Iteration=705\t Loss=3.303511\t mu=4.125711\t sigma=1.8934139\n",
      "Iteration=706\t Loss=3.3030624\t mu=4.1290274\t sigma=1.8929718\n",
      "Iteration=707\t Loss=3.302615\t mu=4.1323447\t sigma=1.8925294\n",
      "Iteration=708\t Loss=3.3021665\t mu=4.135663\t sigma=1.8920867\n",
      "Iteration=709\t Loss=3.301718\t mu=4.1389823\t sigma=1.8916438\n",
      "Iteration=710\t Loss=3.301269\t mu=4.1423025\t sigma=1.8912005\n",
      "Iteration=711\t Loss=3.3008199\t mu=4.145624\t sigma=1.8907571\n",
      "Iteration=712\t Loss=3.3003702\t mu=4.148947\t sigma=1.8903133\n",
      "Iteration=713\t Loss=3.2999203\t mu=4.1522703\t sigma=1.8898692\n",
      "Iteration=714\t Loss=3.2994704\t mu=4.155595\t sigma=1.8894248\n",
      "Iteration=715\t Loss=3.2990196\t mu=4.158921\t sigma=1.8889802\n",
      "Iteration=716\t Loss=3.2985692\t mu=4.1622477\t sigma=1.8885353\n",
      "Iteration=717\t Loss=3.2981184\t mu=4.1655755\t sigma=1.88809\n",
      "Iteration=718\t Loss=3.2976663\t mu=4.1689043\t sigma=1.8876445\n",
      "Iteration=719\t Loss=3.2972152\t mu=4.172234\t sigma=1.8871987\n",
      "Iteration=720\t Loss=3.2967632\t mu=4.1755652\t sigma=1.8867526\n",
      "Iteration=721\t Loss=3.2963114\t mu=4.1788974\t sigma=1.8863062\n",
      "Iteration=722\t Loss=3.2958586\t mu=4.1822305\t sigma=1.8858595\n",
      "Iteration=723\t Loss=3.2954059\t mu=4.1855645\t sigma=1.8854126\n",
      "Iteration=724\t Loss=3.294953\t mu=4.1889\t sigma=1.8849653\n",
      "Iteration=725\t Loss=3.2944996\t mu=4.1922364\t sigma=1.8845178\n",
      "Iteration=726\t Loss=3.2940462\t mu=4.195574\t sigma=1.8840699\n",
      "Iteration=727\t Loss=3.2935922\t mu=4.198912\t sigma=1.8836218\n",
      "Iteration=728\t Loss=3.2931378\t mu=4.2022514\t sigma=1.8831733\n",
      "Iteration=729\t Loss=3.2926831\t mu=4.205592\t sigma=1.8827246\n",
      "Iteration=730\t Loss=3.2922285\t mu=4.208934\t sigma=1.8822757\n",
      "Iteration=731\t Loss=3.2917738\t mu=4.2122765\t sigma=1.8818264\n",
      "Iteration=732\t Loss=3.2913184\t mu=4.21562\t sigma=1.8813769\n",
      "Iteration=733\t Loss=3.2908626\t mu=4.218965\t sigma=1.880927\n",
      "Iteration=734\t Loss=3.2904067\t mu=4.222311\t sigma=1.8804768\n",
      "Iteration=735\t Loss=3.2899504\t mu=4.225658\t sigma=1.8800263\n",
      "Iteration=736\t Loss=3.2894938\t mu=4.229006\t sigma=1.8795756\n",
      "Iteration=737\t Loss=3.2890372\t mu=4.232355\t sigma=1.8791246\n",
      "Iteration=738\t Loss=3.2885797\t mu=4.2357054\t sigma=1.8786733\n",
      "Iteration=739\t Loss=3.2881222\t mu=4.2390566\t sigma=1.8782218\n",
      "Iteration=740\t Loss=3.2876644\t mu=4.2424088\t sigma=1.8777698\n",
      "Iteration=741\t Loss=3.2872066\t mu=4.2457623\t sigma=1.8773177\n",
      "Iteration=742\t Loss=3.286748\t mu=4.249117\t sigma=1.8768651\n",
      "Iteration=743\t Loss=3.2862895\t mu=4.2524724\t sigma=1.8764124\n",
      "Iteration=744\t Loss=3.2858305\t mu=4.255829\t sigma=1.8759593\n",
      "Iteration=745\t Loss=3.2853715\t mu=4.2591867\t sigma=1.8755059\n",
      "Iteration=746\t Loss=3.2849116\t mu=4.2625456\t sigma=1.8750522\n",
      "Iteration=747\t Loss=3.284452\t mu=4.2659054\t sigma=1.8745983\n",
      "Iteration=748\t Loss=3.2839913\t mu=4.269266\t sigma=1.874144\n",
      "Iteration=749\t Loss=3.283531\t mu=4.2726283\t sigma=1.8736894\n",
      "Iteration=750\t Loss=3.2830703\t mu=4.2759914\t sigma=1.8732345\n",
      "Iteration=751\t Loss=3.2826095\t mu=4.2793555\t sigma=1.8727794\n",
      "Iteration=752\t Loss=3.2821481\t mu=4.2827206\t sigma=1.872324\n",
      "Iteration=753\t Loss=3.2816863\t mu=4.286087\t sigma=1.8718683\n",
      "Iteration=754\t Loss=3.2812243\t mu=4.2894545\t sigma=1.8714123\n",
      "Iteration=755\t Loss=3.2807622\t mu=4.292823\t sigma=1.870956\n",
      "Iteration=756\t Loss=3.2802997\t mu=4.296192\t sigma=1.8704993\n",
      "Iteration=757\t Loss=3.2798367\t mu=4.299563\t sigma=1.8700423\n",
      "Iteration=758\t Loss=3.2793734\t mu=4.3029346\t sigma=1.8695852\n",
      "Iteration=759\t Loss=3.2789102\t mu=4.3063073\t sigma=1.8691276\n",
      "Iteration=760\t Loss=3.2784462\t mu=4.309681\t sigma=1.8686699\n",
      "Iteration=761\t Loss=3.277982\t mu=4.313056\t sigma=1.8682117\n",
      "Iteration=762\t Loss=3.2775176\t mu=4.316432\t sigma=1.8677534\n",
      "Iteration=763\t Loss=3.277053\t mu=4.319809\t sigma=1.8672947\n",
      "Iteration=764\t Loss=3.2765882\t mu=4.3231874\t sigma=1.8668357\n",
      "Iteration=765\t Loss=3.276123\t mu=4.3265667\t sigma=1.8663764\n",
      "Iteration=766\t Loss=3.275657\t mu=4.329947\t sigma=1.8659167\n",
      "Iteration=767\t Loss=3.2751913\t mu=4.3333282\t sigma=1.8654568\n",
      "Iteration=768\t Loss=3.274725\t mu=4.336711\t sigma=1.8649967\n",
      "Iteration=769\t Loss=3.2742586\t mu=4.3400946\t sigma=1.8645362\n",
      "Iteration=770\t Loss=3.273792\t mu=4.343479\t sigma=1.8640753\n",
      "Iteration=771\t Loss=3.2733245\t mu=4.3468647\t sigma=1.8636142\n",
      "Iteration=772\t Loss=3.2728572\t mu=4.3502517\t sigma=1.8631527\n",
      "Iteration=773\t Loss=3.2723892\t mu=4.3536396\t sigma=1.862691\n",
      "Iteration=774\t Loss=3.2719214\t mu=4.3570285\t sigma=1.862229\n",
      "Iteration=775\t Loss=3.271453\t mu=4.360419\t sigma=1.8617667\n",
      "Iteration=776\t Loss=3.2709844\t mu=4.36381\t sigma=1.861304\n",
      "Iteration=777\t Loss=3.2705152\t mu=4.3672023\t sigma=1.8608412\n",
      "Iteration=778\t Loss=3.270046\t mu=4.3705955\t sigma=1.8603779\n",
      "Iteration=779\t Loss=3.2695765\t mu=4.37399\t sigma=1.8599144\n",
      "Iteration=780\t Loss=3.269107\t mu=4.3773856\t sigma=1.8594506\n",
      "Iteration=781\t Loss=3.2686367\t mu=4.380782\t sigma=1.8589865\n",
      "Iteration=782\t Loss=3.268166\t mu=4.38418\t sigma=1.858522\n",
      "Iteration=783\t Loss=3.2676952\t mu=4.387579\t sigma=1.8580574\n",
      "Iteration=784\t Loss=3.2672243\t mu=4.390979\t sigma=1.8575923\n",
      "Iteration=785\t Loss=3.2667527\t mu=4.3943796\t sigma=1.8571271\n",
      "Iteration=786\t Loss=3.2662811\t mu=4.397782\t sigma=1.8566614\n",
      "Iteration=787\t Loss=3.265809\t mu=4.401185\t sigma=1.8561954\n",
      "Iteration=788\t Loss=3.265337\t mu=4.404589\t sigma=1.8557292\n",
      "Iteration=789\t Loss=3.2648642\t mu=4.4079947\t sigma=1.8552626\n",
      "Iteration=790\t Loss=3.2643912\t mu=4.4114013\t sigma=1.8547958\n",
      "Iteration=791\t Loss=3.2639182\t mu=4.4148088\t sigma=1.8543286\n",
      "Iteration=792\t Loss=3.2634444\t mu=4.4182177\t sigma=1.8538612\n",
      "Iteration=793\t Loss=3.2629702\t mu=4.4216275\t sigma=1.8533934\n",
      "Iteration=794\t Loss=3.2624962\t mu=4.4250383\t sigma=1.8529253\n",
      "Iteration=795\t Loss=3.2620218\t mu=4.42845\t sigma=1.8524569\n",
      "Iteration=796\t Loss=3.2615469\t mu=4.4318633\t sigma=1.8519882\n",
      "Iteration=797\t Loss=3.261072\t mu=4.4352775\t sigma=1.8515192\n",
      "Iteration=798\t Loss=3.2605963\t mu=4.4386926\t sigma=1.8510499\n",
      "Iteration=799\t Loss=3.2601204\t mu=4.442109\t sigma=1.8505803\n",
      "Iteration=800\t Loss=3.2596445\t mu=4.4455266\t sigma=1.8501104\n",
      "Iteration=801\t Loss=3.2591681\t mu=4.448945\t sigma=1.8496401\n",
      "Iteration=802\t Loss=3.258691\t mu=4.452365\t sigma=1.8491696\n",
      "Iteration=803\t Loss=3.2582145\t mu=4.4557858\t sigma=1.8486987\n",
      "Iteration=804\t Loss=3.257737\t mu=4.4592075\t sigma=1.8482276\n",
      "Iteration=805\t Loss=3.2572594\t mu=4.4626307\t sigma=1.8477561\n",
      "Iteration=806\t Loss=3.2567813\t mu=4.466055\t sigma=1.8472843\n",
      "Iteration=807\t Loss=3.2563028\t mu=4.46948\t sigma=1.8468122\n",
      "Iteration=808\t Loss=3.2558243\t mu=4.4729066\t sigma=1.8463398\n",
      "Iteration=809\t Loss=3.2553456\t mu=4.476334\t sigma=1.8458672\n",
      "Iteration=810\t Loss=3.2548661\t mu=4.4797626\t sigma=1.8453941\n",
      "Iteration=811\t Loss=3.2543867\t mu=4.483192\t sigma=1.8449208\n",
      "Iteration=812\t Loss=3.253907\t mu=4.486623\t sigma=1.8444471\n",
      "Iteration=813\t Loss=3.253427\t mu=4.4900546\t sigma=1.8439732\n",
      "Iteration=814\t Loss=3.2529464\t mu=4.4934874\t sigma=1.843499\n",
      "Iteration=815\t Loss=3.2524652\t mu=4.4969215\t sigma=1.8430244\n",
      "Iteration=816\t Loss=3.2519844\t mu=4.5003567\t sigma=1.8425494\n",
      "Iteration=817\t Loss=3.2515032\t mu=4.503793\t sigma=1.8420743\n",
      "Iteration=818\t Loss=3.2510211\t mu=4.5072303\t sigma=1.8415987\n",
      "Iteration=819\t Loss=3.250539\t mu=4.5106688\t sigma=1.841123\n",
      "Iteration=820\t Loss=3.2500567\t mu=4.514108\t sigma=1.8406469\n",
      "Iteration=821\t Loss=3.2495742\t mu=4.517549\t sigma=1.8401704\n",
      "Iteration=822\t Loss=3.249091\t mu=4.520991\t sigma=1.8396937\n",
      "Iteration=823\t Loss=3.2486079\t mu=4.5244336\t sigma=1.8392166\n",
      "Iteration=824\t Loss=3.248124\t mu=4.527878\t sigma=1.8387393\n",
      "Iteration=825\t Loss=3.2476401\t mu=4.531323\t sigma=1.8382616\n",
      "Iteration=826\t Loss=3.2471557\t mu=4.534769\t sigma=1.8377836\n",
      "Iteration=827\t Loss=3.2466712\t mu=4.5382166\t sigma=1.8373053\n",
      "Iteration=828\t Loss=3.246186\t mu=4.541665\t sigma=1.8368267\n",
      "Iteration=829\t Loss=3.2457008\t mu=4.5451145\t sigma=1.8363477\n",
      "Iteration=830\t Loss=3.2452154\t mu=4.5485654\t sigma=1.8358685\n",
      "Iteration=831\t Loss=3.2447293\t mu=4.552017\t sigma=1.8353889\n",
      "Iteration=832\t Loss=3.2442434\t mu=4.55547\t sigma=1.834909\n",
      "Iteration=833\t Loss=3.2437568\t mu=4.558924\t sigma=1.8344288\n",
      "Iteration=834\t Loss=3.24327\t mu=4.5623794\t sigma=1.8339483\n",
      "Iteration=835\t Loss=3.2427828\t mu=4.5658355\t sigma=1.8334674\n",
      "Iteration=836\t Loss=3.2422953\t mu=4.569293\t sigma=1.8329862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=837\t Loss=3.2418072\t mu=4.5727515\t sigma=1.8325047\n",
      "Iteration=838\t Loss=3.2413197\t mu=4.576211\t sigma=1.8320229\n",
      "Iteration=839\t Loss=3.2408307\t mu=4.579672\t sigma=1.8315408\n",
      "Iteration=840\t Loss=3.240342\t mu=4.5831337\t sigma=1.8310584\n",
      "Iteration=841\t Loss=3.2398531\t mu=4.586597\t sigma=1.8305756\n",
      "Iteration=842\t Loss=3.2393637\t mu=4.590061\t sigma=1.8300925\n",
      "Iteration=843\t Loss=3.2388737\t mu=4.5935264\t sigma=1.8296092\n",
      "Iteration=844\t Loss=3.2383835\t mu=4.596993\t sigma=1.8291254\n",
      "Iteration=845\t Loss=3.2378933\t mu=4.6004605\t sigma=1.8286414\n",
      "Iteration=846\t Loss=3.2374027\t mu=4.603929\t sigma=1.8281571\n",
      "Iteration=847\t Loss=3.2369118\t mu=4.607399\t sigma=1.8276724\n",
      "Iteration=848\t Loss=3.23642\t mu=4.61087\t sigma=1.8271874\n",
      "Iteration=849\t Loss=3.2359288\t mu=4.6143417\t sigma=1.8267021\n",
      "Iteration=850\t Loss=3.2354364\t mu=4.617815\t sigma=1.8262165\n",
      "Iteration=851\t Loss=3.234944\t mu=4.6212893\t sigma=1.8257306\n",
      "Iteration=852\t Loss=3.234451\t mu=4.6247644\t sigma=1.8252443\n",
      "Iteration=853\t Loss=3.2339585\t mu=4.628241\t sigma=1.8247577\n",
      "Iteration=854\t Loss=3.2334652\t mu=4.6317186\t sigma=1.8242708\n",
      "Iteration=855\t Loss=3.2329714\t mu=4.635197\t sigma=1.8237836\n",
      "Iteration=856\t Loss=3.2324774\t mu=4.638677\t sigma=1.8232961\n",
      "Iteration=857\t Loss=3.2319832\t mu=4.642158\t sigma=1.8228083\n",
      "Iteration=858\t Loss=3.2314887\t mu=4.6456404\t sigma=1.8223201\n",
      "Iteration=859\t Loss=3.2309935\t mu=4.6491237\t sigma=1.8218316\n",
      "Iteration=860\t Loss=3.2304986\t mu=4.652608\t sigma=1.8213427\n",
      "Iteration=861\t Loss=3.2300029\t mu=4.6560936\t sigma=1.8208536\n",
      "Iteration=862\t Loss=3.2295067\t mu=4.65958\t sigma=1.8203641\n",
      "Iteration=863\t Loss=3.2290108\t mu=4.663068\t sigma=1.8198743\n",
      "Iteration=864\t Loss=3.228514\t mu=4.666557\t sigma=1.8193842\n",
      "Iteration=865\t Loss=3.2280169\t mu=4.670047\t sigma=1.8188938\n",
      "Iteration=866\t Loss=3.22752\t mu=4.6735377\t sigma=1.818403\n",
      "Iteration=867\t Loss=3.2270222\t mu=4.67703\t sigma=1.8179119\n",
      "Iteration=868\t Loss=3.2265244\t mu=4.6805234\t sigma=1.8174205\n",
      "Iteration=869\t Loss=3.226026\t mu=4.684018\t sigma=1.8169287\n",
      "Iteration=870\t Loss=3.2255275\t mu=4.687514\t sigma=1.8164366\n",
      "Iteration=871\t Loss=3.225029\t mu=4.6910105\t sigma=1.8159443\n",
      "Iteration=872\t Loss=3.2245295\t mu=4.6945086\t sigma=1.8154516\n",
      "Iteration=873\t Loss=3.2240298\t mu=4.6980076\t sigma=1.8149586\n",
      "Iteration=874\t Loss=3.22353\t mu=4.7015076\t sigma=1.8144652\n",
      "Iteration=875\t Loss=3.2230296\t mu=4.705009\t sigma=1.8139715\n",
      "Iteration=876\t Loss=3.2225294\t mu=4.7085114\t sigma=1.8134775\n",
      "Iteration=877\t Loss=3.2220285\t mu=4.712015\t sigma=1.8129832\n",
      "Iteration=878\t Loss=3.221527\t mu=4.71552\t sigma=1.8124884\n",
      "Iteration=879\t Loss=3.2210257\t mu=4.7190256\t sigma=1.8119935\n",
      "Iteration=880\t Loss=3.2205238\t mu=4.7225327\t sigma=1.8114982\n",
      "Iteration=881\t Loss=3.2200217\t mu=4.726041\t sigma=1.8110025\n",
      "Iteration=882\t Loss=3.2195191\t mu=4.72955\t sigma=1.8105065\n",
      "Iteration=883\t Loss=3.2190168\t mu=4.7330604\t sigma=1.8100102\n",
      "Iteration=884\t Loss=3.2185135\t mu=4.736572\t sigma=1.8095136\n",
      "Iteration=885\t Loss=3.2180095\t mu=4.7400846\t sigma=1.8090166\n",
      "Iteration=886\t Loss=3.217506\t mu=4.7435985\t sigma=1.8085194\n",
      "Iteration=887\t Loss=3.2170017\t mu=4.747113\t sigma=1.8080218\n",
      "Iteration=888\t Loss=3.216497\t mu=4.7506294\t sigma=1.8075238\n",
      "Iteration=889\t Loss=3.2159922\t mu=4.7541466\t sigma=1.8070256\n",
      "Iteration=890\t Loss=3.215487\t mu=4.757665\t sigma=1.8065269\n",
      "Iteration=891\t Loss=3.2149816\t mu=4.7611847\t sigma=1.806028\n",
      "Iteration=892\t Loss=3.2144759\t mu=4.764705\t sigma=1.8055288\n",
      "Iteration=893\t Loss=3.2139697\t mu=4.768227\t sigma=1.8050292\n",
      "Iteration=894\t Loss=3.2134628\t mu=4.77175\t sigma=1.8045292\n",
      "Iteration=895\t Loss=3.212956\t mu=4.775274\t sigma=1.804029\n",
      "Iteration=896\t Loss=3.2124488\t mu=4.778799\t sigma=1.8035284\n",
      "Iteration=897\t Loss=3.2119417\t mu=4.7823253\t sigma=1.8030275\n",
      "Iteration=898\t Loss=3.2114332\t mu=4.785853\t sigma=1.8025262\n",
      "Iteration=899\t Loss=3.210925\t mu=4.7893815\t sigma=1.8020247\n",
      "Iteration=900\t Loss=3.2104168\t mu=4.792911\t sigma=1.8015229\n",
      "Iteration=901\t Loss=3.2099082\t mu=4.796442\t sigma=1.8010206\n",
      "Iteration=902\t Loss=3.2093987\t mu=4.799974\t sigma=1.800518\n",
      "Iteration=903\t Loss=3.2088892\t mu=4.8035073\t sigma=1.8000151\n",
      "Iteration=904\t Loss=3.2083795\t mu=4.8070416\t sigma=1.7995119\n",
      "Iteration=905\t Loss=3.207869\t mu=4.810577\t sigma=1.7990084\n",
      "Iteration=906\t Loss=3.207359\t mu=4.8141136\t sigma=1.7985045\n",
      "Iteration=907\t Loss=3.2068477\t mu=4.8176513\t sigma=1.7980002\n",
      "Iteration=908\t Loss=3.2063365\t mu=4.8211904\t sigma=1.7974957\n",
      "Iteration=909\t Loss=3.2058249\t mu=4.8247304\t sigma=1.7969909\n",
      "Iteration=910\t Loss=3.2053132\t mu=4.8282714\t sigma=1.7964857\n",
      "Iteration=911\t Loss=3.2048008\t mu=4.831814\t sigma=1.7959801\n",
      "Iteration=912\t Loss=3.2042882\t mu=4.835357\t sigma=1.7954742\n",
      "Iteration=913\t Loss=3.2037756\t mu=4.838902\t sigma=1.7949679\n",
      "Iteration=914\t Loss=3.203262\t mu=4.8424478\t sigma=1.7944614\n",
      "Iteration=915\t Loss=3.2027488\t mu=4.8459945\t sigma=1.7939545\n",
      "Iteration=916\t Loss=3.2022345\t mu=4.8495426\t sigma=1.7934473\n",
      "Iteration=917\t Loss=3.2017207\t mu=4.8530917\t sigma=1.7929397\n",
      "Iteration=918\t Loss=3.201206\t mu=4.8566422\t sigma=1.7924317\n",
      "Iteration=919\t Loss=3.2006912\t mu=4.8601937\t sigma=1.7919235\n",
      "Iteration=920\t Loss=3.2001755\t mu=4.863746\t sigma=1.791415\n",
      "Iteration=921\t Loss=3.19966\t mu=4.8673\t sigma=1.7909061\n",
      "Iteration=922\t Loss=3.1991441\t mu=4.870855\t sigma=1.7903968\n",
      "Iteration=923\t Loss=3.198628\t mu=4.874411\t sigma=1.7898872\n",
      "Iteration=924\t Loss=3.1981108\t mu=4.8779683\t sigma=1.7893773\n",
      "Iteration=925\t Loss=3.1975937\t mu=4.8815265\t sigma=1.7888671\n",
      "Iteration=926\t Loss=3.197077\t mu=4.885086\t sigma=1.7883565\n",
      "Iteration=927\t Loss=3.196559\t mu=4.8886466\t sigma=1.7878456\n",
      "Iteration=928\t Loss=3.196041\t mu=4.8922086\t sigma=1.7873343\n",
      "Iteration=929\t Loss=3.1955225\t mu=4.8957715\t sigma=1.7868227\n",
      "Iteration=930\t Loss=3.195004\t mu=4.8993354\t sigma=1.7863108\n",
      "Iteration=931\t Loss=3.1944854\t mu=4.9029007\t sigma=1.7857985\n",
      "Iteration=932\t Loss=3.193966\t mu=4.906467\t sigma=1.785286\n",
      "Iteration=933\t Loss=3.1934462\t mu=4.9100347\t sigma=1.784773\n",
      "Iteration=934\t Loss=3.1929257\t mu=4.9136033\t sigma=1.7842597\n",
      "Iteration=935\t Loss=3.1924057\t mu=4.9171734\t sigma=1.783746\n",
      "Iteration=936\t Loss=3.191885\t mu=4.9207444\t sigma=1.7832321\n",
      "Iteration=937\t Loss=3.1913636\t mu=4.9243164\t sigma=1.7827178\n",
      "Iteration=938\t Loss=3.1908426\t mu=4.92789\t sigma=1.7822032\n",
      "Iteration=939\t Loss=3.1903207\t mu=4.931464\t sigma=1.7816882\n",
      "Iteration=940\t Loss=3.1897984\t mu=4.93504\t sigma=1.7811729\n",
      "Iteration=941\t Loss=3.189276\t mu=4.9386168\t sigma=1.7806572\n",
      "Iteration=942\t Loss=3.1887534\t mu=4.9421945\t sigma=1.7801412\n",
      "Iteration=943\t Loss=3.18823\t mu=4.9457736\t sigma=1.7796249\n",
      "Iteration=944\t Loss=3.1877065\t mu=4.9493537\t sigma=1.7791083\n",
      "Iteration=945\t Loss=3.1871824\t mu=4.952935\t sigma=1.7785913\n",
      "Iteration=946\t Loss=3.1866586\t mu=4.9565177\t sigma=1.7780739\n",
      "Iteration=947\t Loss=3.186134\t mu=4.960101\t sigma=1.7775562\n",
      "Iteration=948\t Loss=3.185609\t mu=4.963686\t sigma=1.7770381\n",
      "Iteration=949\t Loss=3.1850839\t mu=4.967272\t sigma=1.7765198\n",
      "Iteration=950\t Loss=3.1845582\t mu=4.970859\t sigma=1.7760011\n",
      "Iteration=951\t Loss=3.1840327\t mu=4.9744473\t sigma=1.775482\n",
      "Iteration=952\t Loss=3.1835063\t mu=4.978037\t sigma=1.7749627\n",
      "Iteration=953\t Loss=3.1829798\t mu=4.9816275\t sigma=1.7744429\n",
      "Iteration=954\t Loss=3.1824527\t mu=4.985219\t sigma=1.7739228\n",
      "Iteration=955\t Loss=3.1819253\t mu=4.988812\t sigma=1.7734023\n",
      "Iteration=956\t Loss=3.181398\t mu=4.992406\t sigma=1.7728816\n",
      "Iteration=957\t Loss=3.1808698\t mu=4.9960012\t sigma=1.7723606\n",
      "Iteration=958\t Loss=3.1803417\t mu=4.9995975\t sigma=1.7718391\n",
      "Iteration=959\t Loss=3.179813\t mu=5.0031953\t sigma=1.7713174\n",
      "Iteration=960\t Loss=3.179284\t mu=5.006794\t sigma=1.7707952\n",
      "Iteration=961\t Loss=3.1787548\t mu=5.0103936\t sigma=1.7702727\n",
      "Iteration=962\t Loss=3.1782246\t mu=5.0139947\t sigma=1.7697499\n",
      "Iteration=963\t Loss=3.177695\t mu=5.0175967\t sigma=1.7692267\n",
      "Iteration=964\t Loss=3.1771646\t mu=5.0212\t sigma=1.7687031\n",
      "Iteration=965\t Loss=3.1766338\t mu=5.0248046\t sigma=1.7681793\n",
      "Iteration=966\t Loss=3.1761026\t mu=5.02841\t sigma=1.7676551\n",
      "Iteration=967\t Loss=3.1755712\t mu=5.0320168\t sigma=1.7671306\n",
      "Iteration=968\t Loss=3.1750393\t mu=5.0356245\t sigma=1.7666057\n",
      "Iteration=969\t Loss=3.1745074\t mu=5.0392337\t sigma=1.7660805\n",
      "Iteration=970\t Loss=3.1739748\t mu=5.042844\t sigma=1.7655549\n",
      "Iteration=971\t Loss=3.173442\t mu=5.0464554\t sigma=1.765029\n",
      "Iteration=972\t Loss=3.1729088\t mu=5.050068\t sigma=1.7645026\n",
      "Iteration=973\t Loss=3.1723757\t mu=5.0536814\t sigma=1.763976\n",
      "Iteration=974\t Loss=3.1718419\t mu=5.0572963\t sigma=1.7634491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=975\t Loss=3.1713073\t mu=5.060912\t sigma=1.7629218\n",
      "Iteration=976\t Loss=3.1707726\t mu=5.0645294\t sigma=1.7623942\n",
      "Iteration=977\t Loss=3.1702378\t mu=5.0681477\t sigma=1.7618662\n",
      "Iteration=978\t Loss=3.169702\t mu=5.0717673\t sigma=1.7613379\n",
      "Iteration=979\t Loss=3.169167\t mu=5.075388\t sigma=1.7608092\n",
      "Iteration=980\t Loss=3.1686308\t mu=5.0790095\t sigma=1.7602801\n",
      "Iteration=981\t Loss=3.1680946\t mu=5.0826325\t sigma=1.7597507\n",
      "Iteration=982\t Loss=3.1675577\t mu=5.0862565\t sigma=1.759221\n",
      "Iteration=983\t Loss=3.167021\t mu=5.089882\t sigma=1.7586908\n",
      "Iteration=984\t Loss=3.1664834\t mu=5.0935082\t sigma=1.7581604\n",
      "Iteration=985\t Loss=3.165946\t mu=5.0971355\t sigma=1.7576296\n",
      "Iteration=986\t Loss=3.165408\t mu=5.1007643\t sigma=1.7570986\n",
      "Iteration=987\t Loss=3.1648693\t mu=5.104394\t sigma=1.7565671\n",
      "Iteration=988\t Loss=3.1643307\t mu=5.108025\t sigma=1.7560353\n",
      "Iteration=989\t Loss=3.1637914\t mu=5.111657\t sigma=1.7555032\n",
      "Iteration=990\t Loss=3.1632519\t mu=5.1152906\t sigma=1.7549707\n",
      "Iteration=991\t Loss=3.1627126\t mu=5.118925\t sigma=1.7544378\n",
      "Iteration=992\t Loss=3.162172\t mu=5.1225605\t sigma=1.7539046\n",
      "Iteration=993\t Loss=3.1616316\t mu=5.1261973\t sigma=1.753371\n",
      "Iteration=994\t Loss=3.1610904\t mu=5.129835\t sigma=1.7528371\n",
      "Iteration=995\t Loss=3.1605494\t mu=5.1334743\t sigma=1.7523028\n",
      "Iteration=996\t Loss=3.1600082\t mu=5.1371145\t sigma=1.7517681\n",
      "Iteration=997\t Loss=3.159466\t mu=5.140756\t sigma=1.7512332\n",
      "Iteration=998\t Loss=3.1589239\t mu=5.1443987\t sigma=1.750698\n",
      "Iteration=999\t Loss=3.1583807\t mu=5.148042\t sigma=1.7501624\n",
      "Iteration=1000\t Loss=3.1578376\t mu=5.151687\t sigma=1.7496264\n",
      "Iteration=1001\t Loss=3.1572945\t mu=5.155333\t sigma=1.7490901\n",
      "Iteration=1002\t Loss=3.1567512\t mu=5.1589804\t sigma=1.7485534\n",
      "Iteration=1003\t Loss=3.156207\t mu=5.1626287\t sigma=1.7480164\n",
      "Iteration=1004\t Loss=3.1556625\t mu=5.1662784\t sigma=1.747479\n",
      "Iteration=1005\t Loss=3.1551175\t mu=5.169929\t sigma=1.7469412\n",
      "Iteration=1006\t Loss=3.1545727\t mu=5.1735806\t sigma=1.7464031\n",
      "Iteration=1007\t Loss=3.1540267\t mu=5.1772337\t sigma=1.7458646\n",
      "Iteration=1008\t Loss=3.1534815\t mu=5.1808877\t sigma=1.7453258\n",
      "Iteration=1009\t Loss=3.1529353\t mu=5.184543\t sigma=1.7447866\n",
      "Iteration=1010\t Loss=3.1523886\t mu=5.1881995\t sigma=1.7442471\n",
      "Iteration=1011\t Loss=3.1518424\t mu=5.191857\t sigma=1.7437072\n",
      "Iteration=1012\t Loss=3.1512942\t mu=5.1955156\t sigma=1.743167\n",
      "Iteration=1013\t Loss=3.1507473\t mu=5.1991754\t sigma=1.7426265\n",
      "Iteration=1014\t Loss=3.1501992\t mu=5.2028365\t sigma=1.7420857\n",
      "Iteration=1015\t Loss=3.1496513\t mu=5.2064986\t sigma=1.7415445\n",
      "Iteration=1016\t Loss=3.1491024\t mu=5.210162\t sigma=1.7410029\n",
      "Iteration=1017\t Loss=3.1485534\t mu=5.2138267\t sigma=1.740461\n",
      "Iteration=1018\t Loss=3.148004\t mu=5.217492\t sigma=1.7399187\n",
      "Iteration=1019\t Loss=3.1474543\t mu=5.221159\t sigma=1.7393761\n",
      "Iteration=1020\t Loss=3.146904\t mu=5.224827\t sigma=1.7388331\n",
      "Iteration=1021\t Loss=3.146354\t mu=5.228496\t sigma=1.7382897\n",
      "Iteration=1022\t Loss=3.1458032\t mu=5.2321663\t sigma=1.737746\n",
      "Iteration=1023\t Loss=3.1452522\t mu=5.235838\t sigma=1.7372019\n",
      "Iteration=1024\t Loss=3.1447008\t mu=5.2395105\t sigma=1.7366575\n",
      "Iteration=1025\t Loss=3.1441488\t mu=5.243184\t sigma=1.7361127\n",
      "Iteration=1026\t Loss=3.1435966\t mu=5.246859\t sigma=1.7355676\n",
      "Iteration=1027\t Loss=3.1430442\t mu=5.250535\t sigma=1.7350221\n",
      "Iteration=1028\t Loss=3.142491\t mu=5.2542124\t sigma=1.7344762\n",
      "Iteration=1029\t Loss=3.141938\t mu=5.2578907\t sigma=1.73393\n",
      "Iteration=1030\t Loss=3.1413844\t mu=5.26157\t sigma=1.7333834\n",
      "Iteration=1031\t Loss=3.1408308\t mu=5.2652507\t sigma=1.7328365\n",
      "Iteration=1032\t Loss=3.1402764\t mu=5.2689323\t sigma=1.7322893\n",
      "Iteration=1033\t Loss=3.1397214\t mu=5.2726154\t sigma=1.7317418\n",
      "Iteration=1034\t Loss=3.1391664\t mu=5.2762995\t sigma=1.7311939\n",
      "Iteration=1035\t Loss=3.1386113\t mu=5.279985\t sigma=1.7306457\n",
      "Iteration=1036\t Loss=3.1380556\t mu=5.2836714\t sigma=1.730097\n",
      "Iteration=1037\t Loss=3.1374993\t mu=5.2873588\t sigma=1.7295481\n",
      "Iteration=1038\t Loss=3.1369429\t mu=5.2910476\t sigma=1.7289988\n",
      "Iteration=1039\t Loss=3.1363864\t mu=5.2947373\t sigma=1.7284491\n",
      "Iteration=1040\t Loss=3.135829\t mu=5.2984285\t sigma=1.7278991\n",
      "Iteration=1041\t Loss=3.1352713\t mu=5.3021207\t sigma=1.7273487\n",
      "Iteration=1042\t Loss=3.1347136\t mu=5.305814\t sigma=1.7267979\n",
      "Iteration=1043\t Loss=3.1341553\t mu=5.3095083\t sigma=1.7262468\n",
      "Iteration=1044\t Loss=3.1335967\t mu=5.313204\t sigma=1.7256954\n",
      "Iteration=1045\t Loss=3.133038\t mu=5.3169007\t sigma=1.7251436\n",
      "Iteration=1046\t Loss=3.132479\t mu=5.3205986\t sigma=1.7245914\n",
      "Iteration=1047\t Loss=3.1319191\t mu=5.3242974\t sigma=1.7240388\n",
      "Iteration=1048\t Loss=3.131359\t mu=5.3279977\t sigma=1.723486\n",
      "Iteration=1049\t Loss=3.1307988\t mu=5.331699\t sigma=1.7229327\n",
      "Iteration=1050\t Loss=3.130238\t mu=5.3354015\t sigma=1.7223791\n",
      "Iteration=1051\t Loss=3.1296773\t mu=5.339105\t sigma=1.7218251\n",
      "Iteration=1052\t Loss=3.1291156\t mu=5.34281\t sigma=1.7212708\n",
      "Iteration=1053\t Loss=3.1285539\t mu=5.346516\t sigma=1.7207161\n",
      "Iteration=1054\t Loss=3.127992\t mu=5.350223\t sigma=1.7201611\n",
      "Iteration=1055\t Loss=3.1274295\t mu=5.3539314\t sigma=1.7196057\n",
      "Iteration=1056\t Loss=3.1268668\t mu=5.3576407\t sigma=1.7190499\n",
      "Iteration=1057\t Loss=3.1263034\t mu=5.3613515\t sigma=1.7184938\n",
      "Iteration=1058\t Loss=3.1257396\t mu=5.365063\t sigma=1.7179374\n",
      "Iteration=1059\t Loss=3.125176\t mu=5.368776\t sigma=1.7173805\n",
      "Iteration=1060\t Loss=3.124612\t mu=5.37249\t sigma=1.7168233\n",
      "Iteration=1061\t Loss=3.1240468\t mu=5.376205\t sigma=1.7162658\n",
      "Iteration=1062\t Loss=3.123482\t mu=5.3799214\t sigma=1.7157079\n",
      "Iteration=1063\t Loss=3.1229167\t mu=5.383639\t sigma=1.7151496\n",
      "Iteration=1064\t Loss=3.1223512\t mu=5.387357\t sigma=1.714591\n",
      "Iteration=1065\t Loss=3.1217852\t mu=5.391077\t sigma=1.714032\n",
      "Iteration=1066\t Loss=3.1212187\t mu=5.394798\t sigma=1.7134727\n",
      "Iteration=1067\t Loss=3.1206524\t mu=5.39852\t sigma=1.712913\n",
      "Iteration=1068\t Loss=3.1200848\t mu=5.402243\t sigma=1.712353\n",
      "Iteration=1069\t Loss=3.1195178\t mu=5.405967\t sigma=1.7117927\n",
      "Iteration=1070\t Loss=3.1189497\t mu=5.409693\t sigma=1.7112321\n",
      "Iteration=1071\t Loss=3.118381\t mu=5.4134192\t sigma=1.7106711\n",
      "Iteration=1072\t Loss=3.1178129\t mu=5.417147\t sigma=1.7101097\n",
      "Iteration=1073\t Loss=3.117244\t mu=5.420876\t sigma=1.709548\n",
      "Iteration=1074\t Loss=3.1166747\t mu=5.424606\t sigma=1.7089859\n",
      "Iteration=1075\t Loss=3.1161053\t mu=5.428337\t sigma=1.7084234\n",
      "Iteration=1076\t Loss=3.1155353\t mu=5.4320693\t sigma=1.7078606\n",
      "Iteration=1077\t Loss=3.114965\t mu=5.4358025\t sigma=1.7072974\n",
      "Iteration=1078\t Loss=3.1143942\t mu=5.439537\t sigma=1.706734\n",
      "Iteration=1079\t Loss=3.1138234\t mu=5.4432726\t sigma=1.7061701\n",
      "Iteration=1080\t Loss=3.1132517\t mu=5.4470096\t sigma=1.7056059\n",
      "Iteration=1081\t Loss=3.1126802\t mu=5.4507475\t sigma=1.7050413\n",
      "Iteration=1082\t Loss=3.1121082\t mu=5.4544864\t sigma=1.7044764\n",
      "Iteration=1083\t Loss=3.1115355\t mu=5.4582267\t sigma=1.7039111\n",
      "Iteration=1084\t Loss=3.1109626\t mu=5.461968\t sigma=1.7033454\n",
      "Iteration=1085\t Loss=3.11039\t mu=5.4657106\t sigma=1.7027794\n",
      "Iteration=1086\t Loss=3.1098163\t mu=5.4694543\t sigma=1.702213\n",
      "Iteration=1087\t Loss=3.1092422\t mu=5.473199\t sigma=1.7016463\n",
      "Iteration=1088\t Loss=3.1086679\t mu=5.476945\t sigma=1.7010792\n",
      "Iteration=1089\t Loss=3.1080937\t mu=5.480692\t sigma=1.7005118\n",
      "Iteration=1090\t Loss=3.1075187\t mu=5.48444\t sigma=1.699944\n",
      "Iteration=1091\t Loss=3.1069431\t mu=5.488189\t sigma=1.6993759\n",
      "Iteration=1092\t Loss=3.1063678\t mu=5.4919395\t sigma=1.6988074\n",
      "Iteration=1093\t Loss=3.1057913\t mu=5.4956913\t sigma=1.6982385\n",
      "Iteration=1094\t Loss=3.1052155\t mu=5.499444\t sigma=1.6976693\n",
      "Iteration=1095\t Loss=3.1046386\t mu=5.5031977\t sigma=1.6970997\n",
      "Iteration=1096\t Loss=3.1040616\t mu=5.506953\t sigma=1.6965297\n",
      "Iteration=1097\t Loss=3.103484\t mu=5.510709\t sigma=1.6959594\n",
      "Iteration=1098\t Loss=3.102907\t mu=5.514466\t sigma=1.6953888\n",
      "Iteration=1099\t Loss=3.102328\t mu=5.5182242\t sigma=1.6948178\n",
      "Iteration=1100\t Loss=3.10175\t mu=5.5219836\t sigma=1.6942464\n",
      "Iteration=1101\t Loss=3.101171\t mu=5.525744\t sigma=1.6936747\n",
      "Iteration=1102\t Loss=3.1005917\t mu=5.5295057\t sigma=1.6931026\n",
      "Iteration=1103\t Loss=3.100012\t mu=5.5332685\t sigma=1.6925302\n",
      "Iteration=1104\t Loss=3.0994325\t mu=5.5370326\t sigma=1.6919574\n",
      "Iteration=1105\t Loss=3.0988522\t mu=5.5407977\t sigma=1.6913842\n",
      "Iteration=1106\t Loss=3.0982714\t mu=5.544564\t sigma=1.6908107\n",
      "Iteration=1107\t Loss=3.0976903\t mu=5.5483313\t sigma=1.6902368\n",
      "Iteration=1108\t Loss=3.097109\t mu=5.5520997\t sigma=1.6896626\n",
      "Iteration=1109\t Loss=3.0965273\t mu=5.555869\t sigma=1.689088\n",
      "Iteration=1110\t Loss=3.0959456\t mu=5.55964\t sigma=1.688513\n",
      "Iteration=1111\t Loss=3.095363\t mu=5.5634117\t sigma=1.6879377\n",
      "Iteration=1112\t Loss=3.09478\t mu=5.5671844\t sigma=1.6873621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=1113\t Loss=3.0941973\t mu=5.5709586\t sigma=1.686786\n",
      "Iteration=1114\t Loss=3.0936136\t mu=5.5747337\t sigma=1.6862097\n",
      "Iteration=1115\t Loss=3.09303\t mu=5.57851\t sigma=1.685633\n",
      "Iteration=1116\t Loss=3.092446\t mu=5.5822873\t sigma=1.6850559\n",
      "Iteration=1117\t Loss=3.0918612\t mu=5.586066\t sigma=1.6844784\n",
      "Iteration=1118\t Loss=3.0912764\t mu=5.589845\t sigma=1.6839006\n",
      "Iteration=1119\t Loss=3.0906916\t mu=5.593626\t sigma=1.6833224\n",
      "Iteration=1120\t Loss=3.0901058\t mu=5.597408\t sigma=1.6827439\n",
      "Iteration=1121\t Loss=3.0895197\t mu=5.6011906\t sigma=1.682165\n",
      "Iteration=1122\t Loss=3.0889337\t mu=5.6049747\t sigma=1.6815858\n",
      "Iteration=1123\t Loss=3.088347\t mu=5.60876\t sigma=1.6810062\n",
      "Iteration=1124\t Loss=3.0877604\t mu=5.612546\t sigma=1.6804264\n",
      "Iteration=1125\t Loss=3.0871727\t mu=5.6163335\t sigma=1.6798462\n",
      "Iteration=1126\t Loss=3.086585\t mu=5.620122\t sigma=1.6792656\n",
      "Iteration=1127\t Loss=3.0859973\t mu=5.6239114\t sigma=1.6786847\n",
      "Iteration=1128\t Loss=3.085409\t mu=5.627702\t sigma=1.6781034\n",
      "Iteration=1129\t Loss=3.08482\t mu=5.631494\t sigma=1.6775218\n",
      "Iteration=1130\t Loss=3.084231\t mu=5.635287\t sigma=1.6769398\n",
      "Iteration=1131\t Loss=3.0836413\t mu=5.639081\t sigma=1.6763575\n",
      "Iteration=1132\t Loss=3.0830514\t mu=5.642876\t sigma=1.6757748\n",
      "Iteration=1133\t Loss=3.0824614\t mu=5.6466722\t sigma=1.6751918\n",
      "Iteration=1134\t Loss=3.0818708\t mu=5.65047\t sigma=1.6746083\n",
      "Iteration=1135\t Loss=3.0812805\t mu=5.6542683\t sigma=1.6740246\n",
      "Iteration=1136\t Loss=3.0806892\t mu=5.6580677\t sigma=1.6734405\n",
      "Iteration=1137\t Loss=3.0800974\t mu=5.661868\t sigma=1.672856\n",
      "Iteration=1138\t Loss=3.0795057\t mu=5.66567\t sigma=1.6722711\n",
      "Iteration=1139\t Loss=3.0789132\t mu=5.6694727\t sigma=1.6716859\n",
      "Iteration=1140\t Loss=3.078321\t mu=5.6732764\t sigma=1.6711004\n",
      "Iteration=1141\t Loss=3.077728\t mu=5.6770816\t sigma=1.6705145\n",
      "Iteration=1142\t Loss=3.0771346\t mu=5.6808877\t sigma=1.6699282\n",
      "Iteration=1143\t Loss=3.076541\t mu=5.684695\t sigma=1.6693416\n",
      "Iteration=1144\t Loss=3.075947\t mu=5.688503\t sigma=1.6687546\n",
      "Iteration=1145\t Loss=3.0753524\t mu=5.6923122\t sigma=1.6681672\n",
      "Iteration=1146\t Loss=3.0747576\t mu=5.6961226\t sigma=1.6675795\n",
      "Iteration=1147\t Loss=3.0741632\t mu=5.699934\t sigma=1.6669915\n",
      "Iteration=1148\t Loss=3.0735674\t mu=5.703747\t sigma=1.6664032\n",
      "Iteration=1149\t Loss=3.0729718\t mu=5.7075605\t sigma=1.6658145\n",
      "Iteration=1150\t Loss=3.0723758\t mu=5.711375\t sigma=1.6652255\n",
      "Iteration=1151\t Loss=3.0717793\t mu=5.715191\t sigma=1.6646361\n",
      "Iteration=1152\t Loss=3.0711827\t mu=5.719008\t sigma=1.6640464\n",
      "Iteration=1153\t Loss=3.070586\t mu=5.722826\t sigma=1.6634563\n",
      "Iteration=1154\t Loss=3.0699878\t mu=5.726645\t sigma=1.6628659\n",
      "Iteration=1155\t Loss=3.0693903\t mu=5.7304654\t sigma=1.6622751\n",
      "Iteration=1156\t Loss=3.068792\t mu=5.734287\t sigma=1.6616839\n",
      "Iteration=1157\t Loss=3.0681934\t mu=5.738109\t sigma=1.6610924\n",
      "Iteration=1158\t Loss=3.0675948\t mu=5.7419324\t sigma=1.6605005\n",
      "Iteration=1159\t Loss=3.0669956\t mu=5.745757\t sigma=1.6599083\n",
      "Iteration=1160\t Loss=3.066396\t mu=5.749583\t sigma=1.6593157\n",
      "Iteration=1161\t Loss=3.065796\t mu=5.7534094\t sigma=1.6587228\n",
      "Iteration=1162\t Loss=3.0651958\t mu=5.757237\t sigma=1.6581295\n",
      "Iteration=1163\t Loss=3.0645952\t mu=5.761066\t sigma=1.6575358\n",
      "Iteration=1164\t Loss=3.0639944\t mu=5.764896\t sigma=1.6569419\n",
      "Iteration=1165\t Loss=3.063393\t mu=5.768727\t sigma=1.6563476\n",
      "Iteration=1166\t Loss=3.0627918\t mu=5.7725587\t sigma=1.655753\n",
      "Iteration=1167\t Loss=3.0621896\t mu=5.776392\t sigma=1.655158\n",
      "Iteration=1168\t Loss=3.0615876\t mu=5.780226\t sigma=1.6545627\n",
      "Iteration=1169\t Loss=3.0609846\t mu=5.7840614\t sigma=1.653967\n",
      "Iteration=1170\t Loss=3.060382\t mu=5.7878976\t sigma=1.653371\n",
      "Iteration=1171\t Loss=3.0597785\t mu=5.7917347\t sigma=1.6527746\n",
      "Iteration=1172\t Loss=3.059175\t mu=5.795573\t sigma=1.6521778\n",
      "Iteration=1173\t Loss=3.0585706\t mu=5.7994127\t sigma=1.6515807\n",
      "Iteration=1174\t Loss=3.0579665\t mu=5.803253\t sigma=1.6509832\n",
      "Iteration=1175\t Loss=3.0573618\t mu=5.8070946\t sigma=1.6503855\n",
      "Iteration=1176\t Loss=3.0567567\t mu=5.8109374\t sigma=1.6497874\n",
      "Iteration=1177\t Loss=3.0561512\t mu=5.814781\t sigma=1.649189\n",
      "Iteration=1178\t Loss=3.0555456\t mu=5.818626\t sigma=1.6485902\n",
      "Iteration=1179\t Loss=3.0549395\t mu=5.8224716\t sigma=1.6479911\n",
      "Iteration=1180\t Loss=3.0543332\t mu=5.8263183\t sigma=1.6473916\n",
      "Iteration=1181\t Loss=3.0537267\t mu=5.8301663\t sigma=1.6467917\n",
      "Iteration=1182\t Loss=3.0531192\t mu=5.8340154\t sigma=1.6461915\n",
      "Iteration=1183\t Loss=3.0525115\t mu=5.8378654\t sigma=1.6455909\n",
      "Iteration=1184\t Loss=3.051904\t mu=5.8417163\t sigma=1.64499\n",
      "Iteration=1185\t Loss=3.051296\t mu=5.845568\t sigma=1.6443888\n",
      "Iteration=1186\t Loss=3.0506876\t mu=5.8494215\t sigma=1.6437873\n",
      "Iteration=1187\t Loss=3.0500786\t mu=5.853276\t sigma=1.6431854\n",
      "Iteration=1188\t Loss=3.04947\t mu=5.857131\t sigma=1.6425831\n",
      "Iteration=1189\t Loss=3.0488605\t mu=5.860987\t sigma=1.6419805\n",
      "Iteration=1190\t Loss=3.0482507\t mu=5.8648443\t sigma=1.6413776\n",
      "Iteration=1191\t Loss=3.0476406\t mu=5.8687024\t sigma=1.6407743\n",
      "Iteration=1192\t Loss=3.04703\t mu=5.872562\t sigma=1.6401706\n",
      "Iteration=1193\t Loss=3.0464194\t mu=5.8764224\t sigma=1.6395667\n",
      "Iteration=1194\t Loss=3.045808\t mu=5.880284\t sigma=1.6389624\n",
      "Iteration=1195\t Loss=3.0451968\t mu=5.884146\t sigma=1.6383578\n",
      "Iteration=1196\t Loss=3.044585\t mu=5.8880095\t sigma=1.6377528\n",
      "Iteration=1197\t Loss=3.043973\t mu=5.891874\t sigma=1.6371474\n",
      "Iteration=1198\t Loss=3.0433602\t mu=5.8957396\t sigma=1.6365417\n",
      "Iteration=1199\t Loss=3.0427477\t mu=5.899606\t sigma=1.6359358\n",
      "Iteration=1200\t Loss=3.0421345\t mu=5.903474\t sigma=1.6353295\n",
      "Iteration=1201\t Loss=3.0415208\t mu=5.9073424\t sigma=1.6347228\n",
      "Iteration=1202\t Loss=3.0409071\t mu=5.911212\t sigma=1.6341158\n",
      "Iteration=1203\t Loss=3.0402935\t mu=5.9150825\t sigma=1.6335084\n",
      "Iteration=1204\t Loss=3.0396788\t mu=5.918954\t sigma=1.6329007\n",
      "Iteration=1205\t Loss=3.0390642\t mu=5.922827\t sigma=1.6322927\n",
      "Iteration=1206\t Loss=3.0384488\t mu=5.9267006\t sigma=1.6316844\n",
      "Iteration=1207\t Loss=3.0378332\t mu=5.9305754\t sigma=1.6310757\n",
      "Iteration=1208\t Loss=3.0372176\t mu=5.934451\t sigma=1.6304667\n",
      "Iteration=1209\t Loss=3.0366018\t mu=5.938328\t sigma=1.6298573\n",
      "Iteration=1210\t Loss=3.0359855\t mu=5.9422054\t sigma=1.6292475\n",
      "Iteration=1211\t Loss=3.0353684\t mu=5.946084\t sigma=1.6286376\n",
      "Iteration=1212\t Loss=3.0347517\t mu=5.9499636\t sigma=1.6280272\n",
      "Iteration=1213\t Loss=3.0341341\t mu=5.953844\t sigma=1.6274165\n",
      "Iteration=1214\t Loss=3.0335164\t mu=5.957726\t sigma=1.6268054\n",
      "Iteration=1215\t Loss=3.0328982\t mu=5.961609\t sigma=1.626194\n",
      "Iteration=1216\t Loss=3.03228\t mu=5.9654927\t sigma=1.6255823\n",
      "Iteration=1217\t Loss=3.031661\t mu=5.9693775\t sigma=1.6249703\n",
      "Iteration=1218\t Loss=3.031042\t mu=5.9732633\t sigma=1.6243579\n",
      "Iteration=1219\t Loss=3.0304232\t mu=5.97715\t sigma=1.6237452\n",
      "Iteration=1220\t Loss=3.029803\t mu=5.9810376\t sigma=1.6231321\n",
      "Iteration=1221\t Loss=3.0291834\t mu=5.984926\t sigma=1.6225188\n",
      "Iteration=1222\t Loss=3.0285628\t mu=5.988816\t sigma=1.6219051\n",
      "Iteration=1223\t Loss=3.0279422\t mu=5.9927063\t sigma=1.621291\n",
      "Iteration=1224\t Loss=3.027321\t mu=5.996598\t sigma=1.6206766\n",
      "Iteration=1225\t Loss=3.0267\t mu=6.00049\t sigma=1.620062\n",
      "Iteration=1226\t Loss=3.0260785\t mu=6.0043836\t sigma=1.619447\n",
      "Iteration=1227\t Loss=3.0254567\t mu=6.008278\t sigma=1.6188316\n",
      "Iteration=1228\t Loss=3.0248344\t mu=6.012173\t sigma=1.6182159\n",
      "Iteration=1229\t Loss=3.0242114\t mu=6.01607\t sigma=1.6176\n",
      "Iteration=1230\t Loss=3.023589\t mu=6.0199676\t sigma=1.6169837\n",
      "Iteration=1231\t Loss=3.0229657\t mu=6.023866\t sigma=1.616367\n",
      "Iteration=1232\t Loss=3.022342\t mu=6.0277658\t sigma=1.61575\n",
      "Iteration=1233\t Loss=3.0217183\t mu=6.0316663\t sigma=1.6151326\n",
      "Iteration=1234\t Loss=3.0210938\t mu=6.0355678\t sigma=1.614515\n",
      "Iteration=1235\t Loss=3.0204694\t mu=6.03947\t sigma=1.613897\n",
      "Iteration=1236\t Loss=3.0198448\t mu=6.0433736\t sigma=1.6132786\n",
      "Iteration=1237\t Loss=3.0192196\t mu=6.047278\t sigma=1.61266\n",
      "Iteration=1238\t Loss=3.0185943\t mu=6.051183\t sigma=1.6120411\n",
      "Iteration=1239\t Loss=3.0179687\t mu=6.0550895\t sigma=1.6114218\n",
      "Iteration=1240\t Loss=3.0173428\t mu=6.0589967\t sigma=1.6108022\n",
      "Iteration=1241\t Loss=3.016716\t mu=6.062905\t sigma=1.6101823\n",
      "Iteration=1242\t Loss=3.016089\t mu=6.066814\t sigma=1.609562\n",
      "Iteration=1243\t Loss=3.0154622\t mu=6.070724\t sigma=1.6089414\n",
      "Iteration=1244\t Loss=3.014835\t mu=6.074635\t sigma=1.6083206\n",
      "Iteration=1245\t Loss=3.0142074\t mu=6.078547\t sigma=1.6076994\n",
      "Iteration=1246\t Loss=3.0135796\t mu=6.08246\t sigma=1.6070778\n",
      "Iteration=1247\t Loss=3.012951\t mu=6.0863733\t sigma=1.606456\n",
      "Iteration=1248\t Loss=3.012323\t mu=6.0902877\t sigma=1.6058339\n",
      "Iteration=1249\t Loss=3.011694\t mu=6.094203\t sigma=1.6052114\n",
      "Iteration=1250\t Loss=3.0110648\t mu=6.0981193\t sigma=1.6045886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=1251\t Loss=3.0104353\t mu=6.1020365\t sigma=1.6039655\n",
      "Iteration=1252\t Loss=3.009806\t mu=6.1059546\t sigma=1.603342\n",
      "Iteration=1253\t Loss=3.0091753\t mu=6.109874\t sigma=1.6027184\n",
      "Iteration=1254\t Loss=3.0085454\t mu=6.113794\t sigma=1.6020943\n",
      "Iteration=1255\t Loss=3.0079145\t mu=6.117715\t sigma=1.6014699\n",
      "Iteration=1256\t Loss=3.0072837\t mu=6.121637\t sigma=1.6008452\n",
      "Iteration=1257\t Loss=3.006652\t mu=6.12556\t sigma=1.6002202\n",
      "Iteration=1258\t Loss=3.006021\t mu=6.1294837\t sigma=1.5995948\n",
      "Iteration=1259\t Loss=3.0053887\t mu=6.1334085\t sigma=1.5989692\n",
      "Iteration=1260\t Loss=3.004757\t mu=6.1373343\t sigma=1.5983433\n",
      "Iteration=1261\t Loss=3.0041242\t mu=6.1412606\t sigma=1.597717\n",
      "Iteration=1262\t Loss=3.0034916\t mu=6.145188\t sigma=1.5970905\n",
      "Iteration=1263\t Loss=3.0028586\t mu=6.149116\t sigma=1.5964636\n",
      "Iteration=1264\t Loss=3.002225\t mu=6.153045\t sigma=1.5958364\n",
      "Iteration=1265\t Loss=3.0015917\t mu=6.1569753\t sigma=1.5952089\n",
      "Iteration=1266\t Loss=3.0009577\t mu=6.1609063\t sigma=1.5945811\n",
      "Iteration=1267\t Loss=3.0003233\t mu=6.1648383\t sigma=1.593953\n",
      "Iteration=1268\t Loss=2.9996889\t mu=6.1687713\t sigma=1.5933245\n",
      "Iteration=1269\t Loss=2.9990542\t mu=6.1727047\t sigma=1.5926958\n",
      "Iteration=1270\t Loss=2.998419\t mu=6.176639\t sigma=1.5920668\n",
      "Iteration=1271\t Loss=2.9977837\t mu=6.1805744\t sigma=1.5914375\n",
      "Iteration=1272\t Loss=2.9971478\t mu=6.1845107\t sigma=1.5908078\n",
      "Iteration=1273\t Loss=2.996512\t mu=6.188448\t sigma=1.5901779\n",
      "Iteration=1274\t Loss=2.995876\t mu=6.192386\t sigma=1.5895476\n",
      "Iteration=1275\t Loss=2.995239\t mu=6.196325\t sigma=1.5889171\n",
      "Iteration=1276\t Loss=2.9946022\t mu=6.2002645\t sigma=1.5882863\n",
      "Iteration=1277\t Loss=2.9939651\t mu=6.204205\t sigma=1.5876552\n",
      "Iteration=1278\t Loss=2.9933276\t mu=6.2081466\t sigma=1.5870237\n",
      "Iteration=1279\t Loss=2.99269\t mu=6.212089\t sigma=1.586392\n",
      "Iteration=1280\t Loss=2.992052\t mu=6.216032\t sigma=1.58576\n",
      "Iteration=1281\t Loss=2.9914136\t mu=6.219976\t sigma=1.5851277\n",
      "Iteration=1282\t Loss=2.9907753\t mu=6.223921\t sigma=1.5844951\n",
      "Iteration=1283\t Loss=2.9901361\t mu=6.2278666\t sigma=1.5838622\n",
      "Iteration=1284\t Loss=2.9894972\t mu=6.2318134\t sigma=1.583229\n",
      "Iteration=1285\t Loss=2.9888575\t mu=6.2357607\t sigma=1.5825955\n",
      "Iteration=1286\t Loss=2.988218\t mu=6.239709\t sigma=1.5819616\n",
      "Iteration=1287\t Loss=2.987578\t mu=6.243658\t sigma=1.5813276\n",
      "Iteration=1288\t Loss=2.9869378\t mu=6.247608\t sigma=1.5806931\n",
      "Iteration=1289\t Loss=2.9862974\t mu=6.251559\t sigma=1.5800585\n",
      "Iteration=1290\t Loss=2.9856563\t mu=6.2555103\t sigma=1.5794234\n",
      "Iteration=1291\t Loss=2.9850156\t mu=6.259463\t sigma=1.5787882\n",
      "Iteration=1292\t Loss=2.9843738\t mu=6.2634163\t sigma=1.5781525\n",
      "Iteration=1293\t Loss=2.9837322\t mu=6.26737\t sigma=1.5775167\n",
      "Iteration=1294\t Loss=2.9830904\t mu=6.271325\t sigma=1.5768806\n",
      "Iteration=1295\t Loss=2.9824483\t mu=6.275281\t sigma=1.5762441\n",
      "Iteration=1296\t Loss=2.9818058\t mu=6.2792373\t sigma=1.5756074\n",
      "Iteration=1297\t Loss=2.9811633\t mu=6.2831945\t sigma=1.5749704\n",
      "Iteration=1298\t Loss=2.98052\t mu=6.287153\t sigma=1.5743331\n",
      "Iteration=1299\t Loss=2.979877\t mu=6.2911115\t sigma=1.5736955\n",
      "Iteration=1300\t Loss=2.9792335\t mu=6.295071\t sigma=1.5730577\n",
      "Iteration=1301\t Loss=2.9785895\t mu=6.2990317\t sigma=1.5724195\n",
      "Iteration=1302\t Loss=2.9779458\t mu=6.302993\t sigma=1.571781\n",
      "Iteration=1303\t Loss=2.9773016\t mu=6.306955\t sigma=1.5711423\n",
      "Iteration=1304\t Loss=2.9766567\t mu=6.310918\t sigma=1.5705034\n",
      "Iteration=1305\t Loss=2.976012\t mu=6.3148813\t sigma=1.569864\n",
      "Iteration=1306\t Loss=2.9753666\t mu=6.3188457\t sigma=1.5692245\n",
      "Iteration=1307\t Loss=2.9747212\t mu=6.322811\t sigma=1.5685847\n",
      "Iteration=1308\t Loss=2.9740758\t mu=6.326777\t sigma=1.5679445\n",
      "Iteration=1309\t Loss=2.9734297\t mu=6.330744\t sigma=1.5673041\n",
      "Iteration=1310\t Loss=2.9727838\t mu=6.3347116\t sigma=1.5666635\n",
      "Iteration=1311\t Loss=2.9721372\t mu=6.33868\t sigma=1.5660226\n",
      "Iteration=1312\t Loss=2.9714909\t mu=6.342649\t sigma=1.5653814\n",
      "Iteration=1313\t Loss=2.9708436\t mu=6.3466187\t sigma=1.56474\n",
      "Iteration=1314\t Loss=2.9701962\t mu=6.3505893\t sigma=1.5640982\n",
      "Iteration=1315\t Loss=2.9695492\t mu=6.354561\t sigma=1.5634562\n",
      "Iteration=1316\t Loss=2.9689016\t mu=6.358533\t sigma=1.5628139\n",
      "Iteration=1317\t Loss=2.9682531\t mu=6.362506\t sigma=1.5621713\n",
      "Iteration=1318\t Loss=2.9676054\t mu=6.3664794\t sigma=1.5615286\n",
      "Iteration=1319\t Loss=2.9669569\t mu=6.370454\t sigma=1.5608854\n",
      "Iteration=1320\t Loss=2.9663084\t mu=6.3744287\t sigma=1.560242\n",
      "Iteration=1321\t Loss=2.9656594\t mu=6.3784046\t sigma=1.5595984\n",
      "Iteration=1322\t Loss=2.96501\t mu=6.382381\t sigma=1.5589546\n",
      "Iteration=1323\t Loss=2.9643612\t mu=6.3863583\t sigma=1.5583104\n",
      "Iteration=1324\t Loss=2.9637113\t mu=6.390336\t sigma=1.557666\n",
      "Iteration=1325\t Loss=2.9630616\t mu=6.394315\t sigma=1.5570213\n",
      "Iteration=1326\t Loss=2.9624112\t mu=6.398294\t sigma=1.5563763\n",
      "Iteration=1327\t Loss=2.961761\t mu=6.402274\t sigma=1.5557312\n",
      "Iteration=1328\t Loss=2.9611104\t mu=6.406255\t sigma=1.5550858\n",
      "Iteration=1329\t Loss=2.9604595\t mu=6.4102364\t sigma=1.55444\n",
      "Iteration=1330\t Loss=2.9598083\t mu=6.4142184\t sigma=1.553794\n",
      "Iteration=1331\t Loss=2.959157\t mu=6.4182014\t sigma=1.5531478\n",
      "Iteration=1332\t Loss=2.9585054\t mu=6.422185\t sigma=1.5525013\n",
      "Iteration=1333\t Loss=2.9578538\t mu=6.4261694\t sigma=1.5518546\n",
      "Iteration=1334\t Loss=2.9572015\t mu=6.4301543\t sigma=1.5512077\n",
      "Iteration=1335\t Loss=2.9565496\t mu=6.43414\t sigma=1.5505605\n",
      "Iteration=1336\t Loss=2.955897\t mu=6.4381266\t sigma=1.549913\n",
      "Iteration=1337\t Loss=2.9552445\t mu=6.4421134\t sigma=1.5492653\n",
      "Iteration=1338\t Loss=2.9545915\t mu=6.446101\t sigma=1.5486172\n",
      "Iteration=1339\t Loss=2.9539382\t mu=6.4500895\t sigma=1.547969\n",
      "Iteration=1340\t Loss=2.953285\t mu=6.4540787\t sigma=1.5473205\n",
      "Iteration=1341\t Loss=2.9526315\t mu=6.4580684\t sigma=1.5466717\n",
      "Iteration=1342\t Loss=2.9519775\t mu=6.4620585\t sigma=1.5460228\n",
      "Iteration=1343\t Loss=2.9513235\t mu=6.4660497\t sigma=1.5453736\n",
      "Iteration=1344\t Loss=2.950669\t mu=6.4700413\t sigma=1.5447241\n",
      "Iteration=1345\t Loss=2.9500146\t mu=6.4740334\t sigma=1.5440744\n",
      "Iteration=1346\t Loss=2.9493597\t mu=6.4780264\t sigma=1.5434245\n",
      "Iteration=1347\t Loss=2.9487052\t mu=6.48202\t sigma=1.5427743\n",
      "Iteration=1348\t Loss=2.94805\t mu=6.486014\t sigma=1.5421239\n",
      "Iteration=1349\t Loss=2.9473946\t mu=6.490009\t sigma=1.5414733\n",
      "Iteration=1350\t Loss=2.946739\t mu=6.4940042\t sigma=1.5408224\n",
      "Iteration=1351\t Loss=2.9460833\t mu=6.498\t sigma=1.5401713\n",
      "Iteration=1352\t Loss=2.9454274\t mu=6.501997\t sigma=1.5395199\n",
      "Iteration=1353\t Loss=2.9447715\t mu=6.5059943\t sigma=1.5388683\n",
      "Iteration=1354\t Loss=2.944115\t mu=6.509992\t sigma=1.5382165\n",
      "Iteration=1355\t Loss=2.9434586\t mu=6.513991\t sigma=1.5375645\n",
      "Iteration=1356\t Loss=2.9428015\t mu=6.51799\t sigma=1.5369123\n",
      "Iteration=1357\t Loss=2.9421446\t mu=6.52199\t sigma=1.5362599\n",
      "Iteration=1358\t Loss=2.9414873\t mu=6.52599\t sigma=1.5356072\n",
      "Iteration=1359\t Loss=2.94083\t mu=6.529991\t sigma=1.5349543\n",
      "Iteration=1360\t Loss=2.9401724\t mu=6.533993\t sigma=1.5343012\n",
      "Iteration=1361\t Loss=2.9395144\t mu=6.537995\t sigma=1.5336478\n",
      "Iteration=1362\t Loss=2.9388564\t mu=6.5419974\t sigma=1.5329942\n",
      "Iteration=1363\t Loss=2.9381986\t mu=6.5460005\t sigma=1.5323403\n",
      "Iteration=1364\t Loss=2.9375398\t mu=6.5500045\t sigma=1.5316863\n",
      "Iteration=1365\t Loss=2.9368815\t mu=6.554009\t sigma=1.5310321\n",
      "Iteration=1366\t Loss=2.9362226\t mu=6.558014\t sigma=1.5303776\n",
      "Iteration=1367\t Loss=2.9355638\t mu=6.5620193\t sigma=1.5297229\n",
      "Iteration=1368\t Loss=2.9349046\t mu=6.5660253\t sigma=1.529068\n",
      "Iteration=1369\t Loss=2.9342453\t mu=6.5700316\t sigma=1.5284129\n",
      "Iteration=1370\t Loss=2.933586\t mu=6.574039\t sigma=1.5277576\n",
      "Iteration=1371\t Loss=2.932926\t mu=6.578047\t sigma=1.5271021\n",
      "Iteration=1372\t Loss=2.9322662\t mu=6.582055\t sigma=1.5264463\n",
      "Iteration=1373\t Loss=2.9316063\t mu=6.586064\t sigma=1.5257905\n",
      "Iteration=1374\t Loss=2.9309459\t mu=6.590073\t sigma=1.5251343\n",
      "Iteration=1375\t Loss=2.9302855\t mu=6.594083\t sigma=1.524478\n",
      "Iteration=1376\t Loss=2.9296248\t mu=6.598093\t sigma=1.5238214\n",
      "Iteration=1377\t Loss=2.9289641\t mu=6.6021037\t sigma=1.5231646\n",
      "Iteration=1378\t Loss=2.9283032\t mu=6.606115\t sigma=1.5225077\n",
      "Iteration=1379\t Loss=2.927642\t mu=6.6101265\t sigma=1.5218505\n",
      "Iteration=1380\t Loss=2.9269812\t mu=6.6141386\t sigma=1.5211931\n",
      "Iteration=1381\t Loss=2.9263198\t mu=6.618151\t sigma=1.5205356\n",
      "Iteration=1382\t Loss=2.9256582\t mu=6.6221642\t sigma=1.5198779\n",
      "Iteration=1383\t Loss=2.924996\t mu=6.626178\t sigma=1.51922\n",
      "Iteration=1384\t Loss=2.9243345\t mu=6.630192\t sigma=1.5185618\n",
      "Iteration=1385\t Loss=2.9236722\t mu=6.6342063\t sigma=1.5179036\n",
      "Iteration=1386\t Loss=2.9230106\t mu=6.6382213\t sigma=1.517245\n",
      "Iteration=1387\t Loss=2.9223478\t mu=6.6422367\t sigma=1.5165864\n",
      "Iteration=1388\t Loss=2.9216852\t mu=6.6462526\t sigma=1.5159276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=1389\t Loss=2.9210227\t mu=6.650269\t sigma=1.5152686\n",
      "Iteration=1390\t Loss=2.9203598\t mu=6.654286\t sigma=1.5146093\n",
      "Iteration=1391\t Loss=2.9196968\t mu=6.6583033\t sigma=1.5139499\n",
      "Iteration=1392\t Loss=2.9190338\t mu=6.662321\t sigma=1.5132903\n",
      "Iteration=1393\t Loss=2.9183702\t mu=6.6663394\t sigma=1.5126305\n",
      "Iteration=1394\t Loss=2.9177067\t mu=6.670358\t sigma=1.5119705\n",
      "Iteration=1395\t Loss=2.9170432\t mu=6.6743774\t sigma=1.5113105\n",
      "Iteration=1396\t Loss=2.9163795\t mu=6.678397\t sigma=1.5106502\n",
      "Iteration=1397\t Loss=2.9157157\t mu=6.6824174\t sigma=1.5099897\n",
      "Iteration=1398\t Loss=2.9150515\t mu=6.6864376\t sigma=1.5093291\n",
      "Iteration=1399\t Loss=2.9143872\t mu=6.6904583\t sigma=1.5086683\n",
      "Iteration=1400\t Loss=2.913723\t mu=6.6944795\t sigma=1.5080073\n",
      "Iteration=1401\t Loss=2.9130585\t mu=6.698501\t sigma=1.5073462\n",
      "Iteration=1402\t Loss=2.912394\t mu=6.702523\t sigma=1.5066849\n",
      "Iteration=1403\t Loss=2.9117296\t mu=6.7065454\t sigma=1.5060234\n",
      "Iteration=1404\t Loss=2.9110644\t mu=6.710568\t sigma=1.5053618\n",
      "Iteration=1405\t Loss=2.9104\t mu=6.714591\t sigma=1.5047\n",
      "Iteration=1406\t Loss=2.9097342\t mu=6.7186146\t sigma=1.504038\n",
      "Iteration=1407\t Loss=2.909069\t mu=6.7226386\t sigma=1.5033759\n",
      "Iteration=1408\t Loss=2.9084036\t mu=6.7266626\t sigma=1.5027136\n",
      "Iteration=1409\t Loss=2.9077382\t mu=6.730687\t sigma=1.5020511\n",
      "Iteration=1410\t Loss=2.9070728\t mu=6.734712\t sigma=1.5013885\n",
      "Iteration=1411\t Loss=2.9064069\t mu=6.7387376\t sigma=1.5007259\n",
      "Iteration=1412\t Loss=2.9057412\t mu=6.742763\t sigma=1.500063\n",
      "Iteration=1413\t Loss=2.9050753\t mu=6.746789\t sigma=1.4993999\n",
      "Iteration=1414\t Loss=2.904409\t mu=6.7508154\t sigma=1.4987367\n",
      "Iteration=1415\t Loss=2.9037428\t mu=6.754842\t sigma=1.4980735\n",
      "Iteration=1416\t Loss=2.9030766\t mu=6.7588687\t sigma=1.49741\n",
      "Iteration=1417\t Loss=2.9024103\t mu=6.762896\t sigma=1.4967464\n",
      "Iteration=1418\t Loss=2.9017441\t mu=6.7669234\t sigma=1.4960827\n",
      "Iteration=1419\t Loss=2.9010773\t mu=6.7709513\t sigma=1.4954188\n",
      "Iteration=1420\t Loss=2.900411\t mu=6.774979\t sigma=1.4947548\n",
      "Iteration=1421\t Loss=2.899744\t mu=6.7790074\t sigma=1.4940907\n",
      "Iteration=1422\t Loss=2.8990772\t mu=6.783036\t sigma=1.4934264\n",
      "Iteration=1423\t Loss=2.89841\t mu=6.787065\t sigma=1.4927621\n",
      "Iteration=1424\t Loss=2.897743\t mu=6.7910943\t sigma=1.4920976\n",
      "Iteration=1425\t Loss=2.8970761\t mu=6.7951236\t sigma=1.4914329\n",
      "Iteration=1426\t Loss=2.896409\t mu=6.7991533\t sigma=1.4907681\n",
      "Iteration=1427\t Loss=2.8957415\t mu=6.803183\t sigma=1.4901031\n",
      "Iteration=1428\t Loss=2.8950741\t mu=6.8072133\t sigma=1.489438\n",
      "Iteration=1429\t Loss=2.8944066\t mu=6.8112435\t sigma=1.4887729\n",
      "Iteration=1430\t Loss=2.893739\t mu=6.8152742\t sigma=1.4881077\n",
      "Iteration=1431\t Loss=2.8930714\t mu=6.819305\t sigma=1.4874423\n",
      "Iteration=1432\t Loss=2.8924036\t mu=6.823336\t sigma=1.4867768\n",
      "Iteration=1433\t Loss=2.8917358\t mu=6.8273673\t sigma=1.4861113\n",
      "Iteration=1434\t Loss=2.891068\t mu=6.831399\t sigma=1.4854456\n",
      "Iteration=1435\t Loss=2.8903997\t mu=6.8354306\t sigma=1.4847798\n",
      "Iteration=1436\t Loss=2.8897321\t mu=6.8394628\t sigma=1.4841139\n",
      "Iteration=1437\t Loss=2.8890638\t mu=6.843495\t sigma=1.4834479\n",
      "Iteration=1438\t Loss=2.8883958\t mu=6.847527\t sigma=1.4827818\n",
      "Iteration=1439\t Loss=2.8877275\t mu=6.8515596\t sigma=1.4821155\n",
      "Iteration=1440\t Loss=2.8870595\t mu=6.8555923\t sigma=1.4814491\n",
      "Iteration=1441\t Loss=2.886391\t mu=6.8596253\t sigma=1.4807827\n",
      "Iteration=1442\t Loss=2.8857224\t mu=6.8636584\t sigma=1.4801162\n",
      "Iteration=1443\t Loss=2.8850543\t mu=6.8676915\t sigma=1.4794496\n",
      "Iteration=1444\t Loss=2.8843858\t mu=6.8717246\t sigma=1.4787829\n",
      "Iteration=1445\t Loss=2.883717\t mu=6.875758\t sigma=1.478116\n",
      "Iteration=1446\t Loss=2.8830485\t mu=6.8797917\t sigma=1.4774492\n",
      "Iteration=1447\t Loss=2.8823798\t mu=6.8838253\t sigma=1.4767822\n",
      "Iteration=1448\t Loss=2.8817112\t mu=6.8878593\t sigma=1.4761151\n",
      "Iteration=1449\t Loss=2.8810422\t mu=6.8918934\t sigma=1.475448\n",
      "Iteration=1450\t Loss=2.8803735\t mu=6.8959274\t sigma=1.4747808\n",
      "Iteration=1451\t Loss=2.8797045\t mu=6.8999615\t sigma=1.4741135\n",
      "Iteration=1452\t Loss=2.879036\t mu=6.903996\t sigma=1.4734461\n",
      "Iteration=1453\t Loss=2.878367\t mu=6.9080305\t sigma=1.4727787\n",
      "Iteration=1454\t Loss=2.877698\t mu=6.912065\t sigma=1.4721111\n",
      "Iteration=1455\t Loss=2.8770292\t mu=6.9160995\t sigma=1.4714435\n",
      "Iteration=1456\t Loss=2.8763597\t mu=6.920134\t sigma=1.4707758\n",
      "Iteration=1457\t Loss=2.875691\t mu=6.9241686\t sigma=1.4701082\n",
      "Iteration=1458\t Loss=2.8750222\t mu=6.9282036\t sigma=1.4694403\n",
      "Iteration=1459\t Loss=2.8743532\t mu=6.9322386\t sigma=1.4687725\n",
      "Iteration=1460\t Loss=2.8736844\t mu=6.9362736\t sigma=1.4681046\n",
      "Iteration=1461\t Loss=2.873015\t mu=6.9403086\t sigma=1.4674367\n",
      "Iteration=1462\t Loss=2.872346\t mu=6.9443436\t sigma=1.4667686\n",
      "Iteration=1463\t Loss=2.8716762\t mu=6.9483786\t sigma=1.4661006\n",
      "Iteration=1464\t Loss=2.871008\t mu=6.9524136\t sigma=1.4654324\n",
      "Iteration=1465\t Loss=2.8703382\t mu=6.9564486\t sigma=1.4647642\n",
      "Iteration=1466\t Loss=2.8696694\t mu=6.9604836\t sigma=1.4640961\n",
      "Iteration=1467\t Loss=2.8690002\t mu=6.9645185\t sigma=1.4634278\n",
      "Iteration=1468\t Loss=2.8683312\t mu=6.9685535\t sigma=1.4627595\n",
      "Iteration=1469\t Loss=2.867662\t mu=6.9725885\t sigma=1.4620912\n",
      "Iteration=1470\t Loss=2.866993\t mu=6.9766235\t sigma=1.4614228\n",
      "Iteration=1471\t Loss=2.8663237\t mu=6.9806585\t sigma=1.4607544\n",
      "Iteration=1472\t Loss=2.8656547\t mu=6.9846935\t sigma=1.460086\n",
      "Iteration=1473\t Loss=2.8649857\t mu=6.9887285\t sigma=1.4594175\n",
      "Iteration=1474\t Loss=2.8643167\t mu=6.9927635\t sigma=1.4587489\n",
      "Iteration=1475\t Loss=2.8636477\t mu=6.996798\t sigma=1.4580804\n",
      "Iteration=1476\t Loss=2.8629782\t mu=7.0008326\t sigma=1.4574119\n",
      "Iteration=1477\t Loss=2.8623095\t mu=7.004867\t sigma=1.4567432\n",
      "Iteration=1478\t Loss=2.8616407\t mu=7.0089016\t sigma=1.4560746\n",
      "Iteration=1479\t Loss=2.8609717\t mu=7.012936\t sigma=1.455406\n",
      "Iteration=1480\t Loss=2.8603027\t mu=7.0169706\t sigma=1.4547373\n",
      "Iteration=1481\t Loss=2.8596342\t mu=7.0210047\t sigma=1.4540687\n",
      "Iteration=1482\t Loss=2.858965\t mu=7.0250387\t sigma=1.4534\n",
      "Iteration=1483\t Loss=2.8582964\t mu=7.0290728\t sigma=1.4527314\n",
      "Iteration=1484\t Loss=2.8576274\t mu=7.033107\t sigma=1.4520627\n",
      "Iteration=1485\t Loss=2.8569589\t mu=7.0371404\t sigma=1.4513941\n",
      "Iteration=1486\t Loss=2.85629\t mu=7.041174\t sigma=1.4507254\n",
      "Iteration=1487\t Loss=2.8556213\t mu=7.0452075\t sigma=1.4500568\n",
      "Iteration=1488\t Loss=2.8549528\t mu=7.049241\t sigma=1.4493881\n",
      "Iteration=1489\t Loss=2.8542843\t mu=7.053274\t sigma=1.4487195\n",
      "Iteration=1490\t Loss=2.8536158\t mu=7.0573072\t sigma=1.4480509\n",
      "Iteration=1491\t Loss=2.8529472\t mu=7.0613403\t sigma=1.4473822\n",
      "Iteration=1492\t Loss=2.852279\t mu=7.065373\t sigma=1.4467136\n",
      "Iteration=1493\t Loss=2.8516107\t mu=7.0694056\t sigma=1.4460449\n",
      "Iteration=1494\t Loss=2.8509421\t mu=7.0734377\t sigma=1.4453763\n",
      "Iteration=1495\t Loss=2.850274\t mu=7.07747\t sigma=1.4447076\n",
      "Iteration=1496\t Loss=2.8496058\t mu=7.081502\t sigma=1.444039\n",
      "Iteration=1497\t Loss=2.8489382\t mu=7.0855336\t sigma=1.4433705\n",
      "Iteration=1498\t Loss=2.8482702\t mu=7.0895653\t sigma=1.4427019\n",
      "Iteration=1499\t Loss=2.8476021\t mu=7.0935965\t sigma=1.4420334\n",
      "Iteration=1500\t Loss=2.846934\t mu=7.0976276\t sigma=1.4413649\n",
      "Iteration=1501\t Loss=2.8462665\t mu=7.1016583\t sigma=1.4406965\n",
      "Iteration=1502\t Loss=2.8455987\t mu=7.105689\t sigma=1.4400281\n",
      "Iteration=1503\t Loss=2.8449314\t mu=7.1097193\t sigma=1.4393597\n",
      "Iteration=1504\t Loss=2.844264\t mu=7.113749\t sigma=1.4386913\n",
      "Iteration=1505\t Loss=2.8435962\t mu=7.117779\t sigma=1.438023\n",
      "Iteration=1506\t Loss=2.8429294\t mu=7.121808\t sigma=1.4373547\n",
      "Iteration=1507\t Loss=2.842262\t mu=7.1258373\t sigma=1.4366865\n",
      "Iteration=1508\t Loss=2.8415954\t mu=7.129866\t sigma=1.4360183\n",
      "Iteration=1509\t Loss=2.840928\t mu=7.1338944\t sigma=1.4353503\n",
      "Iteration=1510\t Loss=2.8402612\t mu=7.137923\t sigma=1.4346823\n",
      "Iteration=1511\t Loss=2.8395946\t mu=7.1419506\t sigma=1.4340143\n",
      "Iteration=1512\t Loss=2.8389277\t mu=7.145978\t sigma=1.4333464\n",
      "Iteration=1513\t Loss=2.8382614\t mu=7.1500053\t sigma=1.4326786\n",
      "Iteration=1514\t Loss=2.8375945\t mu=7.154032\t sigma=1.4320108\n",
      "Iteration=1515\t Loss=2.8369284\t mu=7.1580586\t sigma=1.4313431\n",
      "Iteration=1516\t Loss=2.8362622\t mu=7.1620846\t sigma=1.4306754\n",
      "Iteration=1517\t Loss=2.8355963\t mu=7.16611\t sigma=1.4300078\n",
      "Iteration=1518\t Loss=2.8349304\t mu=7.1701355\t sigma=1.4293404\n",
      "Iteration=1519\t Loss=2.8342648\t mu=7.1741605\t sigma=1.4286729\n",
      "Iteration=1520\t Loss=2.8335993\t mu=7.178185\t sigma=1.4280056\n",
      "Iteration=1521\t Loss=2.8329337\t mu=7.182209\t sigma=1.4273384\n",
      "Iteration=1522\t Loss=2.832268\t mu=7.1862326\t sigma=1.4266711\n",
      "Iteration=1523\t Loss=2.8316028\t mu=7.1902556\t sigma=1.426004\n",
      "Iteration=1524\t Loss=2.8309379\t mu=7.1942782\t sigma=1.4253371\n",
      "Iteration=1525\t Loss=2.8302732\t mu=7.198301\t sigma=1.4246702\n",
      "Iteration=1526\t Loss=2.829608\t mu=7.202323\t sigma=1.4240035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=1527\t Loss=2.8289437\t mu=7.2063446\t sigma=1.4233367\n",
      "Iteration=1528\t Loss=2.828279\t mu=7.210366\t sigma=1.4226701\n",
      "Iteration=1529\t Loss=2.8276145\t mu=7.2143865\t sigma=1.4220036\n",
      "Iteration=1530\t Loss=2.8269503\t mu=7.2184067\t sigma=1.4213372\n",
      "Iteration=1531\t Loss=2.8262868\t mu=7.2224264\t sigma=1.420671\n",
      "Iteration=1532\t Loss=2.8256223\t mu=7.226445\t sigma=1.4200048\n",
      "Iteration=1533\t Loss=2.824959\t mu=7.2304635\t sigma=1.4193388\n",
      "Iteration=1534\t Loss=2.8242958\t mu=7.2344813\t sigma=1.4186729\n",
      "Iteration=1535\t Loss=2.8236325\t mu=7.2384987\t sigma=1.4180071\n",
      "Iteration=1536\t Loss=2.8229694\t mu=7.2425156\t sigma=1.4173415\n",
      "Iteration=1537\t Loss=2.8223062\t mu=7.246532\t sigma=1.4166759\n",
      "Iteration=1538\t Loss=2.8216436\t mu=7.250548\t sigma=1.4160105\n",
      "Iteration=1539\t Loss=2.8209813\t mu=7.2545633\t sigma=1.4153452\n",
      "Iteration=1540\t Loss=2.8203187\t mu=7.258578\t sigma=1.41468\n",
      "Iteration=1541\t Loss=2.819657\t mu=7.262592\t sigma=1.414015\n",
      "Iteration=1542\t Loss=2.8189945\t mu=7.2666054\t sigma=1.4133502\n",
      "Iteration=1543\t Loss=2.8183324\t mu=7.2706184\t sigma=1.4126855\n",
      "Iteration=1544\t Loss=2.8176715\t mu=7.2746305\t sigma=1.4120209\n",
      "Iteration=1545\t Loss=2.81701\t mu=7.278642\t sigma=1.4113564\n",
      "Iteration=1546\t Loss=2.8163486\t mu=7.2826533\t sigma=1.4106922\n",
      "Iteration=1547\t Loss=2.815688\t mu=7.2866635\t sigma=1.4100281\n",
      "Iteration=1548\t Loss=2.8150272\t mu=7.2906733\t sigma=1.4093641\n",
      "Iteration=1549\t Loss=2.8143666\t mu=7.2946825\t sigma=1.4087003\n",
      "Iteration=1550\t Loss=2.8137064\t mu=7.298691\t sigma=1.4080367\n",
      "Iteration=1551\t Loss=2.8130462\t mu=7.3026986\t sigma=1.4073733\n",
      "Iteration=1552\t Loss=2.8123868\t mu=7.3067055\t sigma=1.40671\n",
      "Iteration=1553\t Loss=2.811727\t mu=7.310712\t sigma=1.4060469\n",
      "Iteration=1554\t Loss=2.8110676\t mu=7.314718\t sigma=1.405384\n",
      "Iteration=1555\t Loss=2.8104084\t mu=7.3187227\t sigma=1.4047211\n",
      "Iteration=1556\t Loss=2.8097496\t mu=7.322727\t sigma=1.4040586\n",
      "Iteration=1557\t Loss=2.8090909\t mu=7.3267307\t sigma=1.4033962\n",
      "Iteration=1558\t Loss=2.8084328\t mu=7.3307333\t sigma=1.402734\n",
      "Iteration=1559\t Loss=2.8077745\t mu=7.3347354\t sigma=1.4020721\n",
      "Iteration=1560\t Loss=2.8071167\t mu=7.3387365\t sigma=1.4014102\n",
      "Iteration=1561\t Loss=2.8064592\t mu=7.342737\t sigma=1.4007486\n",
      "Iteration=1562\t Loss=2.8058019\t mu=7.346737\t sigma=1.4000872\n",
      "Iteration=1563\t Loss=2.8051445\t mu=7.3507357\t sigma=1.399426\n",
      "Iteration=1564\t Loss=2.8044875\t mu=7.354734\t sigma=1.398765\n",
      "Iteration=1565\t Loss=2.803831\t mu=7.3587313\t sigma=1.3981042\n",
      "Iteration=1566\t Loss=2.803175\t mu=7.3627276\t sigma=1.3974437\n",
      "Iteration=1567\t Loss=2.802519\t mu=7.3667235\t sigma=1.3967834\n",
      "Iteration=1568\t Loss=2.8018632\t mu=7.3707185\t sigma=1.3961232\n",
      "Iteration=1569\t Loss=2.8012078\t mu=7.3747125\t sigma=1.3954632\n",
      "Iteration=1570\t Loss=2.8005526\t mu=7.3787055\t sigma=1.3948035\n",
      "Iteration=1571\t Loss=2.799898\t mu=7.382698\t sigma=1.394144\n",
      "Iteration=1572\t Loss=2.799243\t mu=7.3866897\t sigma=1.3934848\n",
      "Iteration=1573\t Loss=2.7985888\t mu=7.3906803\t sigma=1.3928258\n",
      "Iteration=1574\t Loss=2.797935\t mu=7.39467\t sigma=1.3921671\n",
      "Iteration=1575\t Loss=2.797281\t mu=7.3986588\t sigma=1.3915086\n",
      "Iteration=1576\t Loss=2.796628\t mu=7.4026465\t sigma=1.3908503\n",
      "Iteration=1577\t Loss=2.7959745\t mu=7.4066334\t sigma=1.3901923\n",
      "Iteration=1578\t Loss=2.7953222\t mu=7.4106193\t sigma=1.3895345\n",
      "Iteration=1579\t Loss=2.7946699\t mu=7.414604\t sigma=1.3888769\n",
      "Iteration=1580\t Loss=2.7940176\t mu=7.418588\t sigma=1.3882196\n",
      "Iteration=1581\t Loss=2.7933657\t mu=7.422571\t sigma=1.3875625\n",
      "Iteration=1582\t Loss=2.7927144\t mu=7.4265532\t sigma=1.3869058\n",
      "Iteration=1583\t Loss=2.792063\t mu=7.4305344\t sigma=1.3862493\n",
      "Iteration=1584\t Loss=2.7914124\t mu=7.4345145\t sigma=1.385593\n",
      "Iteration=1585\t Loss=2.7907617\t mu=7.4384937\t sigma=1.384937\n",
      "Iteration=1586\t Loss=2.7901115\t mu=7.442472\t sigma=1.3842814\n",
      "Iteration=1587\t Loss=2.7894616\t mu=7.4464493\t sigma=1.383626\n",
      "Iteration=1588\t Loss=2.7888122\t mu=7.4504256\t sigma=1.3829708\n",
      "Iteration=1589\t Loss=2.788163\t mu=7.4544005\t sigma=1.382316\n",
      "Iteration=1590\t Loss=2.7875144\t mu=7.4583745\t sigma=1.3816614\n",
      "Iteration=1591\t Loss=2.7868657\t mu=7.4623475\t sigma=1.3810071\n",
      "Iteration=1592\t Loss=2.786218\t mu=7.4663196\t sigma=1.3803531\n",
      "Iteration=1593\t Loss=2.78557\t mu=7.4702907\t sigma=1.3796993\n",
      "Iteration=1594\t Loss=2.7849228\t mu=7.4742603\t sigma=1.379046\n",
      "Iteration=1595\t Loss=2.7842758\t mu=7.478229\t sigma=1.3783928\n",
      "Iteration=1596\t Loss=2.7836292\t mu=7.482197\t sigma=1.37774\n",
      "Iteration=1597\t Loss=2.7829828\t mu=7.486163\t sigma=1.3770876\n",
      "Iteration=1598\t Loss=2.7823367\t mu=7.4901285\t sigma=1.3764354\n",
      "Iteration=1599\t Loss=2.7816916\t mu=7.4940925\t sigma=1.3757836\n",
      "Iteration=1600\t Loss=2.7810462\t mu=7.4980555\t sigma=1.3751321\n",
      "Iteration=1601\t Loss=2.7804015\t mu=7.5020175\t sigma=1.3744808\n",
      "Iteration=1602\t Loss=2.7797575\t mu=7.505978\t sigma=1.37383\n",
      "Iteration=1603\t Loss=2.7791133\t mu=7.509938\t sigma=1.3731794\n",
      "Iteration=1604\t Loss=2.7784698\t mu=7.513896\t sigma=1.3725291\n",
      "Iteration=1605\t Loss=2.7778268\t mu=7.5178533\t sigma=1.3718792\n",
      "Iteration=1606\t Loss=2.777184\t mu=7.521809\t sigma=1.3712296\n",
      "Iteration=1607\t Loss=2.7765417\t mu=7.525764\t sigma=1.3705804\n",
      "Iteration=1608\t Loss=2.7758996\t mu=7.5297174\t sigma=1.3699316\n",
      "Iteration=1609\t Loss=2.7752583\t mu=7.5336695\t sigma=1.3692831\n",
      "Iteration=1610\t Loss=2.7746172\t mu=7.5376205\t sigma=1.3686349\n",
      "Iteration=1611\t Loss=2.7739763\t mu=7.54157\t sigma=1.3679872\n",
      "Iteration=1612\t Loss=2.7733364\t mu=7.5455184\t sigma=1.3673397\n",
      "Iteration=1613\t Loss=2.7726965\t mu=7.5494657\t sigma=1.3666927\n",
      "Iteration=1614\t Loss=2.7720573\t mu=7.5534115\t sigma=1.366046\n",
      "Iteration=1615\t Loss=2.7714183\t mu=7.557356\t sigma=1.3653996\n",
      "Iteration=1616\t Loss=2.7707794\t mu=7.561299\t sigma=1.3647536\n",
      "Iteration=1617\t Loss=2.7701414\t mu=7.565241\t sigma=1.364108\n",
      "Iteration=1618\t Loss=2.7695038\t mu=7.5691814\t sigma=1.3634627\n",
      "Iteration=1619\t Loss=2.7688665\t mu=7.5731206\t sigma=1.3628178\n",
      "Iteration=1620\t Loss=2.76823\t mu=7.5770583\t sigma=1.3621733\n",
      "Iteration=1621\t Loss=2.7675936\t mu=7.5809946\t sigma=1.3615292\n",
      "Iteration=1622\t Loss=2.7669578\t mu=7.5849295\t sigma=1.3608855\n",
      "Iteration=1623\t Loss=2.7663229\t mu=7.588863\t sigma=1.3602421\n",
      "Iteration=1624\t Loss=2.7656877\t mu=7.592795\t sigma=1.3595992\n",
      "Iteration=1625\t Loss=2.765053\t mu=7.5967255\t sigma=1.3589567\n",
      "Iteration=1626\t Loss=2.764419\t mu=7.6006546\t sigma=1.3583146\n",
      "Iteration=1627\t Loss=2.763786\t mu=7.6045823\t sigma=1.3576729\n",
      "Iteration=1628\t Loss=2.763153\t mu=7.6085086\t sigma=1.3570317\n",
      "Iteration=1629\t Loss=2.7625206\t mu=7.6124334\t sigma=1.3563908\n",
      "Iteration=1630\t Loss=2.7618883\t mu=7.616357\t sigma=1.3557503\n",
      "Iteration=1631\t Loss=2.761257\t mu=7.620279\t sigma=1.3551103\n",
      "Iteration=1632\t Loss=2.7606258\t mu=7.6241994\t sigma=1.3544707\n",
      "Iteration=1633\t Loss=2.7599952\t mu=7.6281185\t sigma=1.3538315\n",
      "Iteration=1634\t Loss=2.7593653\t mu=7.6320357\t sigma=1.3531928\n",
      "Iteration=1635\t Loss=2.758736\t mu=7.6359515\t sigma=1.3525544\n",
      "Iteration=1636\t Loss=2.758107\t mu=7.639866\t sigma=1.3519166\n",
      "Iteration=1637\t Loss=2.757478\t mu=7.643779\t sigma=1.3512791\n",
      "Iteration=1638\t Loss=2.7568502\t mu=7.64769\t sigma=1.3506422\n",
      "Iteration=1639\t Loss=2.7562225\t mu=7.6515994\t sigma=1.3500056\n",
      "Iteration=1640\t Loss=2.755596\t mu=7.6555076\t sigma=1.3493695\n",
      "Iteration=1641\t Loss=2.7549694\t mu=7.659414\t sigma=1.3487339\n",
      "Iteration=1642\t Loss=2.7543435\t mu=7.6633186\t sigma=1.3480988\n",
      "Iteration=1643\t Loss=2.753718\t mu=7.667222\t sigma=1.3474641\n",
      "Iteration=1644\t Loss=2.753093\t mu=7.6711235\t sigma=1.3468299\n",
      "Iteration=1645\t Loss=2.7524686\t mu=7.6750236\t sigma=1.3461962\n",
      "Iteration=1646\t Loss=2.7518451\t mu=7.6789217\t sigma=1.3455628\n",
      "Iteration=1647\t Loss=2.751222\t mu=7.6828184\t sigma=1.3449299\n",
      "Iteration=1648\t Loss=2.750599\t mu=7.686713\t sigma=1.3442976\n",
      "Iteration=1649\t Loss=2.749977\t mu=7.6906066\t sigma=1.3436658\n",
      "Iteration=1650\t Loss=2.7493556\t mu=7.694498\t sigma=1.3430345\n",
      "Iteration=1651\t Loss=2.7487342\t mu=7.698388\t sigma=1.3424037\n",
      "Iteration=1652\t Loss=2.7481139\t mu=7.702276\t sigma=1.3417733\n",
      "Iteration=1653\t Loss=2.7474942\t mu=7.7061625\t sigma=1.3411434\n",
      "Iteration=1654\t Loss=2.7468746\t mu=7.7100472\t sigma=1.340514\n",
      "Iteration=1655\t Loss=2.746256\t mu=7.71393\t sigma=1.339885\n",
      "Iteration=1656\t Loss=2.7456374\t mu=7.717811\t sigma=1.3392566\n",
      "Iteration=1657\t Loss=2.7450202\t mu=7.7216907\t sigma=1.3386288\n",
      "Iteration=1658\t Loss=2.7444034\t mu=7.7255683\t sigma=1.3380014\n",
      "Iteration=1659\t Loss=2.7437868\t mu=7.729444\t sigma=1.3373746\n",
      "Iteration=1660\t Loss=2.743171\t mu=7.733318\t sigma=1.3367482\n",
      "Iteration=1661\t Loss=2.7425556\t mu=7.73719\t sigma=1.3361224\n",
      "Iteration=1662\t Loss=2.741941\t mu=7.7410603\t sigma=1.3354971\n",
      "Iteration=1663\t Loss=2.741327\t mu=7.744929\t sigma=1.3348724\n",
      "Iteration=1664\t Loss=2.7407134\t mu=7.7487955\t sigma=1.3342482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=1665\t Loss=2.7401009\t mu=7.7526603\t sigma=1.3336245\n",
      "Iteration=1666\t Loss=2.7394886\t mu=7.756523\t sigma=1.3330014\n",
      "Iteration=1667\t Loss=2.7388766\t mu=7.760384\t sigma=1.3323787\n",
      "Iteration=1668\t Loss=2.7382658\t mu=7.764243\t sigma=1.3317567\n",
      "Iteration=1669\t Loss=2.7376554\t mu=7.7681003\t sigma=1.3311353\n",
      "Iteration=1670\t Loss=2.7370458\t mu=7.7719555\t sigma=1.3305143\n",
      "Iteration=1671\t Loss=2.7364364\t mu=7.775809\t sigma=1.329894\n",
      "Iteration=1672\t Loss=2.7358282\t mu=7.77966\t sigma=1.3292742\n",
      "Iteration=1673\t Loss=2.73522\t mu=7.7835093\t sigma=1.3286549\n",
      "Iteration=1674\t Loss=2.734613\t mu=7.7873564\t sigma=1.3280362\n",
      "Iteration=1675\t Loss=2.7340062\t mu=7.7912016\t sigma=1.3274181\n",
      "Iteration=1676\t Loss=2.7334003\t mu=7.795045\t sigma=1.3268006\n",
      "Iteration=1677\t Loss=2.7327952\t mu=7.7988863\t sigma=1.3261837\n",
      "Iteration=1678\t Loss=2.7321901\t mu=7.8027253\t sigma=1.3255674\n",
      "Iteration=1679\t Loss=2.7315865\t mu=7.8065624\t sigma=1.3249516\n",
      "Iteration=1680\t Loss=2.7309835\t mu=7.8103976\t sigma=1.3243364\n",
      "Iteration=1681\t Loss=2.7303805\t mu=7.814231\t sigma=1.3237218\n",
      "Iteration=1682\t Loss=2.7297788\t mu=7.818062\t sigma=1.3231078\n",
      "Iteration=1683\t Loss=2.7291772\t mu=7.821891\t sigma=1.3224945\n",
      "Iteration=1684\t Loss=2.7285767\t mu=7.8257174\t sigma=1.3218818\n",
      "Iteration=1685\t Loss=2.727977\t mu=7.829542\t sigma=1.3212696\n",
      "Iteration=1686\t Loss=2.7273777\t mu=7.833365\t sigma=1.3206581\n",
      "Iteration=1687\t Loss=2.726779\t mu=7.8371854\t sigma=1.3200471\n",
      "Iteration=1688\t Loss=2.7261808\t mu=7.841004\t sigma=1.3194368\n",
      "Iteration=1689\t Loss=2.7255838\t mu=7.84482\t sigma=1.318827\n",
      "Iteration=1690\t Loss=2.724987\t mu=7.8486342\t sigma=1.318218\n",
      "Iteration=1691\t Loss=2.7243915\t mu=7.852446\t sigma=1.3176095\n",
      "Iteration=1692\t Loss=2.7237961\t mu=7.8562555\t sigma=1.3170017\n",
      "Iteration=1693\t Loss=2.7232018\t mu=7.860063\t sigma=1.3163944\n",
      "Iteration=1694\t Loss=2.722608\t mu=7.863868\t sigma=1.3157879\n",
      "Iteration=1695\t Loss=2.722015\t mu=7.867671\t sigma=1.315182\n",
      "Iteration=1696\t Loss=2.7214227\t mu=7.871472\t sigma=1.3145767\n",
      "Iteration=1697\t Loss=2.7208312\t mu=7.8752704\t sigma=1.3139721\n",
      "Iteration=1698\t Loss=2.7202404\t mu=7.8790665\t sigma=1.3133681\n",
      "Iteration=1699\t Loss=2.7196503\t mu=7.8828607\t sigma=1.3127648\n",
      "Iteration=1700\t Loss=2.7190607\t mu=7.8866525\t sigma=1.3121622\n",
      "Iteration=1701\t Loss=2.718472\t mu=7.890442\t sigma=1.3115602\n",
      "Iteration=1702\t Loss=2.717884\t mu=7.894229\t sigma=1.3109589\n",
      "Iteration=1703\t Loss=2.7172966\t mu=7.8980136\t sigma=1.3103582\n",
      "Iteration=1704\t Loss=2.7167103\t mu=7.901796\t sigma=1.3097582\n",
      "Iteration=1705\t Loss=2.7161245\t mu=7.9055758\t sigma=1.3091589\n",
      "Iteration=1706\t Loss=2.71554\t mu=7.9093533\t sigma=1.3085603\n",
      "Iteration=1707\t Loss=2.7149556\t mu=7.9131284\t sigma=1.3079623\n",
      "Iteration=1708\t Loss=2.7143722\t mu=7.916901\t sigma=1.3073651\n",
      "Iteration=1709\t Loss=2.7137895\t mu=7.9206715\t sigma=1.3067685\n",
      "Iteration=1710\t Loss=2.7132077\t mu=7.9244394\t sigma=1.3061726\n",
      "Iteration=1711\t Loss=2.7126262\t mu=7.928205\t sigma=1.3055774\n",
      "Iteration=1712\t Loss=2.712046\t mu=7.931968\t sigma=1.3049829\n",
      "Iteration=1713\t Loss=2.711466\t mu=7.935729\t sigma=1.3043891\n",
      "Iteration=1714\t Loss=2.7108872\t mu=7.9394875\t sigma=1.303796\n",
      "Iteration=1715\t Loss=2.710309\t mu=7.9432435\t sigma=1.3032037\n",
      "Iteration=1716\t Loss=2.709732\t mu=7.946997\t sigma=1.3026121\n",
      "Iteration=1717\t Loss=2.709155\t mu=7.950748\t sigma=1.3020211\n",
      "Iteration=1718\t Loss=2.7085798\t mu=7.9544964\t sigma=1.301431\n",
      "Iteration=1719\t Loss=2.7080042\t mu=7.9582424\t sigma=1.3008415\n",
      "Iteration=1720\t Loss=2.7074301\t mu=7.961986\t sigma=1.3002527\n",
      "Iteration=1721\t Loss=2.7068567\t mu=7.965727\t sigma=1.2996646\n",
      "Iteration=1722\t Loss=2.7062843\t mu=7.9694653\t sigma=1.2990773\n",
      "Iteration=1723\t Loss=2.7057123\t mu=7.9732013\t sigma=1.2984906\n",
      "Iteration=1724\t Loss=2.7051413\t mu=7.9769344\t sigma=1.2979048\n",
      "Iteration=1725\t Loss=2.704571\t mu=7.980665\t sigma=1.2973198\n",
      "Iteration=1726\t Loss=2.7040017\t mu=7.984393\t sigma=1.2967354\n",
      "Iteration=1727\t Loss=2.7034333\t mu=7.9881186\t sigma=1.2961518\n",
      "Iteration=1728\t Loss=2.7028656\t mu=7.9918413\t sigma=1.295569\n",
      "Iteration=1729\t Loss=2.7022984\t mu=7.9955616\t sigma=1.2949868\n",
      "Iteration=1730\t Loss=2.7017324\t mu=7.999279\t sigma=1.2944055\n",
      "Iteration=1731\t Loss=2.7011673\t mu=8.002994\t sigma=1.2938249\n",
      "Iteration=1732\t Loss=2.7006028\t mu=8.006706\t sigma=1.2932451\n",
      "Iteration=1733\t Loss=2.7000391\t mu=8.010416\t sigma=1.2926661\n",
      "Iteration=1734\t Loss=2.6994762\t mu=8.014123\t sigma=1.2920878\n",
      "Iteration=1735\t Loss=2.698914\t mu=8.017827\t sigma=1.2915102\n",
      "Iteration=1736\t Loss=2.6983528\t mu=8.021528\t sigma=1.2909335\n",
      "Iteration=1737\t Loss=2.697793\t mu=8.025227\t sigma=1.2903576\n",
      "Iteration=1738\t Loss=2.6972337\t mu=8.028922\t sigma=1.2897824\n",
      "Iteration=1739\t Loss=2.696675\t mu=8.032616\t sigma=1.289208\n",
      "Iteration=1740\t Loss=2.6961167\t mu=8.036306\t sigma=1.2886344\n",
      "Iteration=1741\t Loss=2.6955605\t mu=8.039994\t sigma=1.2880616\n",
      "Iteration=1742\t Loss=2.6950042\t mu=8.043679\t sigma=1.2874897\n",
      "Iteration=1743\t Loss=2.694449\t mu=8.047361\t sigma=1.2869184\n",
      "Iteration=1744\t Loss=2.6938946\t mu=8.051041\t sigma=1.286348\n",
      "Iteration=1745\t Loss=2.6933415\t mu=8.054717\t sigma=1.2857784\n",
      "Iteration=1746\t Loss=2.6927888\t mu=8.058391\t sigma=1.2852097\n",
      "Iteration=1747\t Loss=2.6922374\t mu=8.062061\t sigma=1.2846416\n",
      "Iteration=1748\t Loss=2.6916864\t mu=8.065729\t sigma=1.2840744\n",
      "Iteration=1749\t Loss=2.6911364\t mu=8.069394\t sigma=1.2835081\n",
      "Iteration=1750\t Loss=2.6905875\t mu=8.073056\t sigma=1.2829425\n",
      "Iteration=1751\t Loss=2.6900392\t mu=8.076715\t sigma=1.2823778\n",
      "Iteration=1752\t Loss=2.689492\t mu=8.080372\t sigma=1.281814\n",
      "Iteration=1753\t Loss=2.688946\t mu=8.084025\t sigma=1.281251\n",
      "Iteration=1754\t Loss=2.6884\t mu=8.087676\t sigma=1.2806888\n",
      "Iteration=1755\t Loss=2.6878557\t mu=8.091324\t sigma=1.2801274\n",
      "Iteration=1756\t Loss=2.6873114\t mu=8.094969\t sigma=1.2795669\n",
      "Iteration=1757\t Loss=2.6867692\t mu=8.098611\t sigma=1.2790072\n",
      "Iteration=1758\t Loss=2.6862276\t mu=8.102249\t sigma=1.2784483\n",
      "Iteration=1759\t Loss=2.685686\t mu=8.105885\t sigma=1.2778903\n",
      "Iteration=1760\t Loss=2.6851463\t mu=8.109517\t sigma=1.2773331\n",
      "Iteration=1761\t Loss=2.684607\t mu=8.113147\t sigma=1.2767769\n",
      "Iteration=1762\t Loss=2.6840687\t mu=8.116774\t sigma=1.2762215\n",
      "Iteration=1763\t Loss=2.6835313\t mu=8.120398\t sigma=1.275667\n",
      "Iteration=1764\t Loss=2.6829948\t mu=8.124019\t sigma=1.2751132\n",
      "Iteration=1765\t Loss=2.6824596\t mu=8.127636\t sigma=1.2745603\n",
      "Iteration=1766\t Loss=2.681925\t mu=8.13125\t sigma=1.2740084\n",
      "Iteration=1767\t Loss=2.6813915\t mu=8.134862\t sigma=1.2734573\n",
      "Iteration=1768\t Loss=2.6808586\t mu=8.138471\t sigma=1.272907\n",
      "Iteration=1769\t Loss=2.6803272\t mu=8.142076\t sigma=1.2723577\n",
      "Iteration=1770\t Loss=2.679796\t mu=8.145678\t sigma=1.2718092\n",
      "Iteration=1771\t Loss=2.6792665\t mu=8.149277\t sigma=1.2712617\n",
      "Iteration=1772\t Loss=2.6787374\t mu=8.152873\t sigma=1.270715\n",
      "Iteration=1773\t Loss=2.6782093\t mu=8.156466\t sigma=1.2701691\n",
      "Iteration=1774\t Loss=2.6776822\t mu=8.160055\t sigma=1.2696242\n",
      "Iteration=1775\t Loss=2.6771564\t mu=8.163642\t sigma=1.2690802\n",
      "Iteration=1776\t Loss=2.6766315\t mu=8.167225\t sigma=1.268537\n",
      "Iteration=1777\t Loss=2.676107\t mu=8.170805\t sigma=1.2679948\n",
      "Iteration=1778\t Loss=2.6755836\t mu=8.174382\t sigma=1.2674534\n",
      "Iteration=1779\t Loss=2.6750612\t mu=8.177956\t sigma=1.266913\n",
      "Iteration=1780\t Loss=2.67454\t mu=8.181526\t sigma=1.2663735\n",
      "Iteration=1781\t Loss=2.6740198\t mu=8.185093\t sigma=1.2658349\n",
      "Iteration=1782\t Loss=2.6735003\t mu=8.188657\t sigma=1.2652973\n",
      "Iteration=1783\t Loss=2.6729822\t mu=8.192218\t sigma=1.2647605\n",
      "Iteration=1784\t Loss=2.6724646\t mu=8.195775\t sigma=1.2642246\n",
      "Iteration=1785\t Loss=2.671948\t mu=8.199329\t sigma=1.2636898\n",
      "Iteration=1786\t Loss=2.6714327\t mu=8.20288\t sigma=1.2631557\n",
      "Iteration=1787\t Loss=2.6709185\t mu=8.206428\t sigma=1.2626226\n",
      "Iteration=1788\t Loss=2.6704044\t mu=8.209971\t sigma=1.2620904\n",
      "Iteration=1789\t Loss=2.669892\t mu=8.213512\t sigma=1.2615592\n",
      "Iteration=1790\t Loss=2.6693804\t mu=8.21705\t sigma=1.261029\n",
      "Iteration=1791\t Loss=2.66887\t mu=8.220584\t sigma=1.2604996\n",
      "Iteration=1792\t Loss=2.6683602\t mu=8.224114\t sigma=1.2599711\n",
      "Iteration=1793\t Loss=2.6678514\t mu=8.227642\t sigma=1.2594436\n",
      "Iteration=1794\t Loss=2.667344\t mu=8.231166\t sigma=1.2589171\n",
      "Iteration=1795\t Loss=2.6668372\t mu=8.234687\t sigma=1.2583915\n",
      "Iteration=1796\t Loss=2.6663318\t mu=8.238204\t sigma=1.2578669\n",
      "Iteration=1797\t Loss=2.6658273\t mu=8.241718\t sigma=1.2573432\n",
      "Iteration=1798\t Loss=2.6653237\t mu=8.245229\t sigma=1.2568204\n",
      "Iteration=1799\t Loss=2.664821\t mu=8.248735\t sigma=1.2562987\n",
      "Iteration=1800\t Loss=2.6643198\t mu=8.252239\t sigma=1.2557778\n",
      "Iteration=1801\t Loss=2.6638188\t mu=8.255739\t sigma=1.255258\n",
      "Iteration=1802\t Loss=2.6633196\t mu=8.259235\t sigma=1.254739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=1803\t Loss=2.6628208\t mu=8.262729\t sigma=1.2542211\n",
      "Iteration=1804\t Loss=2.6623232\t mu=8.266218\t sigma=1.2537042\n",
      "Iteration=1805\t Loss=2.6618268\t mu=8.269705\t sigma=1.2531883\n",
      "Iteration=1806\t Loss=2.6613312\t mu=8.273188\t sigma=1.2526733\n",
      "Iteration=1807\t Loss=2.6608365\t mu=8.276667\t sigma=1.2521592\n",
      "Iteration=1808\t Loss=2.6603432\t mu=8.280142\t sigma=1.2516462\n",
      "Iteration=1809\t Loss=2.6598506\t mu=8.283614\t sigma=1.251134\n",
      "Iteration=1810\t Loss=2.659359\t mu=8.287083\t sigma=1.250623\n",
      "Iteration=1811\t Loss=2.658869\t mu=8.290547\t sigma=1.2501129\n",
      "Iteration=1812\t Loss=2.6583798\t mu=8.294009\t sigma=1.2496037\n",
      "Iteration=1813\t Loss=2.657891\t mu=8.297467\t sigma=1.2490956\n",
      "Iteration=1814\t Loss=2.6574035\t mu=8.300921\t sigma=1.2485884\n",
      "Iteration=1815\t Loss=2.6569173\t mu=8.304372\t sigma=1.2480823\n",
      "Iteration=1816\t Loss=2.6564326\t mu=8.307818\t sigma=1.2475771\n",
      "Iteration=1817\t Loss=2.6559482\t mu=8.311262\t sigma=1.2470729\n",
      "Iteration=1818\t Loss=2.6554651\t mu=8.314702\t sigma=1.2465698\n",
      "Iteration=1819\t Loss=2.654983\t mu=8.318138\t sigma=1.2460676\n",
      "Iteration=1820\t Loss=2.6545017\t mu=8.32157\t sigma=1.2455665\n",
      "Iteration=1821\t Loss=2.654022\t mu=8.324999\t sigma=1.2450663\n",
      "Iteration=1822\t Loss=2.653543\t mu=8.3284235\t sigma=1.2445672\n",
      "Iteration=1823\t Loss=2.653065\t mu=8.331845\t sigma=1.244069\n",
      "Iteration=1824\t Loss=2.6525886\t mu=8.335263\t sigma=1.2435719\n",
      "Iteration=1825\t Loss=2.6521125\t mu=8.338677\t sigma=1.2430757\n",
      "Iteration=1826\t Loss=2.6516378\t mu=8.342088\t sigma=1.2425807\n",
      "Iteration=1827\t Loss=2.651164\t mu=8.345494\t sigma=1.2420865\n",
      "Iteration=1828\t Loss=2.6506915\t mu=8.348897\t sigma=1.2415935\n",
      "Iteration=1829\t Loss=2.65022\t mu=8.352296\t sigma=1.2411014\n",
      "Iteration=1830\t Loss=2.6497493\t mu=8.355691\t sigma=1.2406104\n",
      "Iteration=1831\t Loss=2.64928\t mu=8.359082\t sigma=1.2401204\n",
      "Iteration=1832\t Loss=2.6488113\t mu=8.36247\t sigma=1.2396314\n",
      "Iteration=1833\t Loss=2.648344\t mu=8.365853\t sigma=1.2391435\n",
      "Iteration=1834\t Loss=2.6478784\t mu=8.369233\t sigma=1.2386566\n",
      "Iteration=1835\t Loss=2.6474128\t mu=8.372609\t sigma=1.2381707\n",
      "Iteration=1836\t Loss=2.646949\t mu=8.375981\t sigma=1.2376859\n",
      "Iteration=1837\t Loss=2.646486\t mu=8.37935\t sigma=1.2372022\n",
      "Iteration=1838\t Loss=2.6460238\t mu=8.382714\t sigma=1.2367194\n",
      "Iteration=1839\t Loss=2.6455634\t mu=8.386075\t sigma=1.2362376\n",
      "Iteration=1840\t Loss=2.6451032\t mu=8.389432\t sigma=1.235757\n",
      "Iteration=1841\t Loss=2.6446447\t mu=8.392785\t sigma=1.2352774\n",
      "Iteration=1842\t Loss=2.6441872\t mu=8.396134\t sigma=1.2347988\n",
      "Iteration=1843\t Loss=2.6437304\t mu=8.39948\t sigma=1.2343212\n",
      "Iteration=1844\t Loss=2.6432753\t mu=8.402822\t sigma=1.2338448\n",
      "Iteration=1845\t Loss=2.6428206\t mu=8.406159\t sigma=1.2333694\n",
      "Iteration=1846\t Loss=2.642367\t mu=8.409493\t sigma=1.232895\n",
      "Iteration=1847\t Loss=2.641915\t mu=8.412824\t sigma=1.2324216\n",
      "Iteration=1848\t Loss=2.6414638\t mu=8.41615\t sigma=1.2319493\n",
      "Iteration=1849\t Loss=2.6410134\t mu=8.419473\t sigma=1.2314781\n",
      "Iteration=1850\t Loss=2.6405642\t mu=8.422791\t sigma=1.2310079\n",
      "Iteration=1851\t Loss=2.6401165\t mu=8.426105\t sigma=1.2305388\n",
      "Iteration=1852\t Loss=2.6396697\t mu=8.429415\t sigma=1.2300708\n",
      "Iteration=1853\t Loss=2.6392238\t mu=8.432721\t sigma=1.2296039\n",
      "Iteration=1854\t Loss=2.6387794\t mu=8.436024\t sigma=1.229138\n",
      "Iteration=1855\t Loss=2.6383357\t mu=8.439322\t sigma=1.2286732\n",
      "Iteration=1856\t Loss=2.6378934\t mu=8.442616\t sigma=1.2282094\n",
      "Iteration=1857\t Loss=2.637452\t mu=8.445907\t sigma=1.2277466\n",
      "Iteration=1858\t Loss=2.637012\t mu=8.449193\t sigma=1.2272849\n",
      "Iteration=1859\t Loss=2.6365728\t mu=8.452476\t sigma=1.2268243\n",
      "Iteration=1860\t Loss=2.6361349\t mu=8.455754\t sigma=1.2263647\n",
      "Iteration=1861\t Loss=2.6356976\t mu=8.459028\t sigma=1.2259063\n",
      "Iteration=1862\t Loss=2.635262\t mu=8.462298\t sigma=1.2254488\n",
      "Iteration=1863\t Loss=2.6348267\t mu=8.465565\t sigma=1.2249925\n",
      "Iteration=1864\t Loss=2.634393\t mu=8.468827\t sigma=1.2245373\n",
      "Iteration=1865\t Loss=2.6339607\t mu=8.472085\t sigma=1.2240831\n",
      "Iteration=1866\t Loss=2.6335292\t mu=8.475339\t sigma=1.2236301\n",
      "Iteration=1867\t Loss=2.6330986\t mu=8.478589\t sigma=1.2231781\n",
      "Iteration=1868\t Loss=2.6326697\t mu=8.481834\t sigma=1.2227273\n",
      "Iteration=1869\t Loss=2.6322415\t mu=8.485076\t sigma=1.2222775\n",
      "Iteration=1870\t Loss=2.6318145\t mu=8.488314\t sigma=1.2218288\n",
      "Iteration=1871\t Loss=2.6313884\t mu=8.491548\t sigma=1.2213812\n",
      "Iteration=1872\t Loss=2.6309636\t mu=8.494777\t sigma=1.2209346\n",
      "Iteration=1873\t Loss=2.63054\t mu=8.498002\t sigma=1.2204891\n",
      "Iteration=1874\t Loss=2.630117\t mu=8.501224\t sigma=1.2200447\n",
      "Iteration=1875\t Loss=2.6296954\t mu=8.50444\t sigma=1.2196014\n",
      "Iteration=1876\t Loss=2.629275\t mu=8.507653\t sigma=1.2191591\n",
      "Iteration=1877\t Loss=2.6288562\t mu=8.510861\t sigma=1.218718\n",
      "Iteration=1878\t Loss=2.628438\t mu=8.514066\t sigma=1.218278\n",
      "Iteration=1879\t Loss=2.6280205\t mu=8.517266\t sigma=1.2178391\n",
      "Iteration=1880\t Loss=2.6276047\t mu=8.520462\t sigma=1.2174013\n",
      "Iteration=1881\t Loss=2.6271896\t mu=8.523654\t sigma=1.2169645\n",
      "Iteration=1882\t Loss=2.6267762\t mu=8.526841\t sigma=1.2165288\n",
      "Iteration=1883\t Loss=2.6263635\t mu=8.530025\t sigma=1.2160943\n",
      "Iteration=1884\t Loss=2.625952\t mu=8.533204\t sigma=1.2156608\n",
      "Iteration=1885\t Loss=2.6255414\t mu=8.536379\t sigma=1.2152284\n",
      "Iteration=1886\t Loss=2.625132\t mu=8.53955\t sigma=1.2147971\n",
      "Iteration=1887\t Loss=2.624724\t mu=8.542716\t sigma=1.2143669\n",
      "Iteration=1888\t Loss=2.6243167\t mu=8.545878\t sigma=1.2139379\n",
      "Iteration=1889\t Loss=2.623911\t mu=8.549036\t sigma=1.2135099\n",
      "Iteration=1890\t Loss=2.623506\t mu=8.55219\t sigma=1.213083\n",
      "Iteration=1891\t Loss=2.6231024\t mu=8.555339\t sigma=1.2126572\n",
      "Iteration=1892\t Loss=2.6227002\t mu=8.558484\t sigma=1.2122326\n",
      "Iteration=1893\t Loss=2.6222982\t mu=8.561625\t sigma=1.211809\n",
      "Iteration=1894\t Loss=2.621898\t mu=8.564761\t sigma=1.2113866\n",
      "Iteration=1895\t Loss=2.6214986\t mu=8.567893\t sigma=1.2109652\n",
      "Iteration=1896\t Loss=2.6211007\t mu=8.571021\t sigma=1.210545\n",
      "Iteration=1897\t Loss=2.6207035\t mu=8.574144\t sigma=1.2101258\n",
      "Iteration=1898\t Loss=2.6203077\t mu=8.577264\t sigma=1.2097077\n",
      "Iteration=1899\t Loss=2.6199129\t mu=8.580379\t sigma=1.2092907\n",
      "Iteration=1900\t Loss=2.6195192\t mu=8.583489\t sigma=1.208875\n",
      "Iteration=1901\t Loss=2.6191266\t mu=8.586596\t sigma=1.2084602\n",
      "Iteration=1902\t Loss=2.618735\t mu=8.589698\t sigma=1.2080466\n",
      "Iteration=1903\t Loss=2.6183448\t mu=8.592795\t sigma=1.2076341\n",
      "Iteration=1904\t Loss=2.617956\t mu=8.595888\t sigma=1.2072227\n",
      "Iteration=1905\t Loss=2.6175678\t mu=8.598977\t sigma=1.2068124\n",
      "Iteration=1906\t Loss=2.6171806\t mu=8.602061\t sigma=1.2064033\n",
      "Iteration=1907\t Loss=2.6167948\t mu=8.605142\t sigma=1.2059952\n",
      "Iteration=1908\t Loss=2.6164103\t mu=8.608217\t sigma=1.2055882\n",
      "Iteration=1909\t Loss=2.6160266\t mu=8.611289\t sigma=1.2051824\n",
      "Iteration=1910\t Loss=2.6156437\t mu=8.614356\t sigma=1.2047777\n",
      "Iteration=1911\t Loss=2.6152625\t mu=8.617418\t sigma=1.2043741\n",
      "Iteration=1912\t Loss=2.6148822\t mu=8.620477\t sigma=1.2039716\n",
      "Iteration=1913\t Loss=2.6145031\t mu=8.62353\t sigma=1.2035702\n",
      "Iteration=1914\t Loss=2.614125\t mu=8.626579\t sigma=1.20317\n",
      "Iteration=1915\t Loss=2.613748\t mu=8.629624\t sigma=1.2027707\n",
      "Iteration=1916\t Loss=2.613372\t mu=8.632665\t sigma=1.2023727\n",
      "Iteration=1917\t Loss=2.6129978\t mu=8.6357\t sigma=1.2019757\n",
      "Iteration=1918\t Loss=2.612624\t mu=8.638732\t sigma=1.2015798\n",
      "Iteration=1919\t Loss=2.6122515\t mu=8.641759\t sigma=1.2011851\n",
      "Iteration=1920\t Loss=2.61188\t mu=8.644781\t sigma=1.2007915\n",
      "Iteration=1921\t Loss=2.61151\t mu=8.6477995\t sigma=1.200399\n",
      "Iteration=1922\t Loss=2.6111405\t mu=8.650813\t sigma=1.2000077\n",
      "Iteration=1923\t Loss=2.610773\t mu=8.653822\t sigma=1.1996174\n",
      "Iteration=1924\t Loss=2.610406\t mu=8.656827\t sigma=1.1992282\n",
      "Iteration=1925\t Loss=2.6100402\t mu=8.659827\t sigma=1.1988401\n",
      "Iteration=1926\t Loss=2.6096752\t mu=8.662823\t sigma=1.1984532\n",
      "Iteration=1927\t Loss=2.6093118\t mu=8.665814\t sigma=1.1980674\n",
      "Iteration=1928\t Loss=2.6089494\t mu=8.668801\t sigma=1.1976827\n",
      "Iteration=1929\t Loss=2.608588\t mu=8.671783\t sigma=1.1972991\n",
      "Iteration=1930\t Loss=2.6082277\t mu=8.674761\t sigma=1.1969166\n",
      "Iteration=1931\t Loss=2.6078687\t mu=8.677734\t sigma=1.1965352\n",
      "Iteration=1932\t Loss=2.6075108\t mu=8.680703\t sigma=1.196155\n",
      "Iteration=1933\t Loss=2.6071534\t mu=8.683667\t sigma=1.1957757\n",
      "Iteration=1934\t Loss=2.606798\t mu=8.686626\t sigma=1.1953977\n",
      "Iteration=1935\t Loss=2.6064427\t mu=8.689582\t sigma=1.1950208\n",
      "Iteration=1936\t Loss=2.6060894\t mu=8.692533\t sigma=1.1946449\n",
      "Iteration=1937\t Loss=2.605737\t mu=8.695478\t sigma=1.1942703\n",
      "Iteration=1938\t Loss=2.6053855\t mu=8.69842\t sigma=1.1938967\n",
      "Iteration=1939\t Loss=2.6050355\t mu=8.701357\t sigma=1.1935241\n",
      "Iteration=1940\t Loss=2.604686\t mu=8.704289\t sigma=1.1931528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=1941\t Loss=2.604338\t mu=8.707217\t sigma=1.1927825\n",
      "Iteration=1942\t Loss=2.6039908\t mu=8.71014\t sigma=1.1924133\n",
      "Iteration=1943\t Loss=2.6036453\t mu=8.713058\t sigma=1.1920453\n",
      "Iteration=1944\t Loss=2.6033\t mu=8.715973\t sigma=1.1916784\n",
      "Iteration=1945\t Loss=2.6029565\t mu=8.718883\t sigma=1.1913126\n",
      "Iteration=1946\t Loss=2.6026137\t mu=8.721787\t sigma=1.1909478\n",
      "Iteration=1947\t Loss=2.6022725\t mu=8.724688\t sigma=1.1905842\n",
      "Iteration=1948\t Loss=2.6019323\t mu=8.727583\t sigma=1.1902217\n",
      "Iteration=1949\t Loss=2.6015933\t mu=8.730474\t sigma=1.1898602\n",
      "Iteration=1950\t Loss=2.6012547\t mu=8.733361\t sigma=1.1895\n",
      "Iteration=1951\t Loss=2.6009176\t mu=8.736243\t sigma=1.1891408\n",
      "Iteration=1952\t Loss=2.6005814\t mu=8.7391205\t sigma=1.1887827\n",
      "Iteration=1953\t Loss=2.6002467\t mu=8.741993\t sigma=1.1884257\n",
      "Iteration=1954\t Loss=2.5999131\t mu=8.744861\t sigma=1.1880698\n",
      "Iteration=1955\t Loss=2.5995803\t mu=8.747725\t sigma=1.187715\n",
      "Iteration=1956\t Loss=2.5992482\t mu=8.750584\t sigma=1.1873614\n",
      "Iteration=1957\t Loss=2.5989182\t mu=8.753438\t sigma=1.1870087\n",
      "Iteration=1958\t Loss=2.5985882\t mu=8.756288\t sigma=1.1866573\n",
      "Iteration=1959\t Loss=2.5982602\t mu=8.759132\t sigma=1.186307\n",
      "Iteration=1960\t Loss=2.5979328\t mu=8.761972\t sigma=1.1859577\n",
      "Iteration=1961\t Loss=2.5976067\t mu=8.764808\t sigma=1.1856095\n",
      "Iteration=1962\t Loss=2.5972815\t mu=8.767639\t sigma=1.1852624\n",
      "Iteration=1963\t Loss=2.596957\t mu=8.770466\t sigma=1.1849165\n",
      "Iteration=1964\t Loss=2.5966341\t mu=8.773288\t sigma=1.1845716\n",
      "Iteration=1965\t Loss=2.596312\t mu=8.776105\t sigma=1.1842278\n",
      "Iteration=1966\t Loss=2.5959916\t mu=8.778917\t sigma=1.1838851\n",
      "Iteration=1967\t Loss=2.595672\t mu=8.781725\t sigma=1.1835434\n",
      "Iteration=1968\t Loss=2.5953534\t mu=8.784528\t sigma=1.183203\n",
      "Iteration=1969\t Loss=2.5950356\t mu=8.787326\t sigma=1.1828636\n",
      "Iteration=1970\t Loss=2.5947194\t mu=8.790119\t sigma=1.1825253\n",
      "Iteration=1971\t Loss=2.594404\t mu=8.792909\t sigma=1.182188\n",
      "Iteration=1972\t Loss=2.5940893\t mu=8.795693\t sigma=1.1818519\n",
      "Iteration=1973\t Loss=2.593776\t mu=8.798473\t sigma=1.1815168\n",
      "Iteration=1974\t Loss=2.5934641\t mu=8.801249\t sigma=1.1811827\n",
      "Iteration=1975\t Loss=2.5931528\t mu=8.804019\t sigma=1.1808499\n",
      "Iteration=1976\t Loss=2.5928426\t mu=8.806785\t sigma=1.1805182\n",
      "Iteration=1977\t Loss=2.5925336\t mu=8.8095455\t sigma=1.1801875\n",
      "Iteration=1978\t Loss=2.5922256\t mu=8.812302\t sigma=1.1798579\n",
      "Iteration=1979\t Loss=2.591919\t mu=8.815053\t sigma=1.1795293\n",
      "Iteration=1980\t Loss=2.591613\t mu=8.8178\t sigma=1.1792018\n",
      "Iteration=1981\t Loss=2.591308\t mu=8.820541\t sigma=1.1788754\n",
      "Iteration=1982\t Loss=2.5910044\t mu=8.823279\t sigma=1.1785501\n",
      "Iteration=1983\t Loss=2.5907016\t mu=8.826013\t sigma=1.1782259\n",
      "Iteration=1984\t Loss=2.5904\t mu=8.828741\t sigma=1.1779027\n",
      "Iteration=1985\t Loss=2.5900993\t mu=8.831465\t sigma=1.1775806\n",
      "Iteration=1986\t Loss=2.5898\t mu=8.834184\t sigma=1.1772596\n",
      "Iteration=1987\t Loss=2.5895011\t mu=8.836898\t sigma=1.1769396\n",
      "Iteration=1988\t Loss=2.5892038\t mu=8.839607\t sigma=1.1766207\n",
      "Iteration=1989\t Loss=2.5889075\t mu=8.842312\t sigma=1.1763029\n",
      "Iteration=1990\t Loss=2.5886123\t mu=8.845012\t sigma=1.1759862\n",
      "Iteration=1991\t Loss=2.5883179\t mu=8.847707\t sigma=1.1756705\n",
      "Iteration=1992\t Loss=2.5880249\t mu=8.850397\t sigma=1.1753559\n",
      "Iteration=1993\t Loss=2.5877323\t mu=8.853083\t sigma=1.1750424\n",
      "Iteration=1994\t Loss=2.5874414\t mu=8.855763\t sigma=1.17473\n",
      "Iteration=1995\t Loss=2.5871513\t mu=8.858439\t sigma=1.1744186\n",
      "Iteration=1996\t Loss=2.586862\t mu=8.861111\t sigma=1.1741083\n",
      "Iteration=1997\t Loss=2.5865743\t mu=8.863777\t sigma=1.173799\n",
      "Iteration=1998\t Loss=2.586287\t mu=8.866439\t sigma=1.1734909\n",
      "Iteration=1999\t Loss=2.5860012\t mu=8.869097\t sigma=1.1731838\n",
      "Iteration=2000\t Loss=2.5857162\t mu=8.87175\t sigma=1.1728778\n",
      "Iteration=2001\t Loss=2.585432\t mu=8.874398\t sigma=1.1725727\n",
      "Iteration=2002\t Loss=2.5851493\t mu=8.877042\t sigma=1.1722687\n",
      "Iteration=2003\t Loss=2.5848675\t mu=8.879681\t sigma=1.1719658\n",
      "Iteration=2004\t Loss=2.5845864\t mu=8.882315\t sigma=1.171664\n",
      "Iteration=2005\t Loss=2.5843065\t mu=8.884944\t sigma=1.1713632\n",
      "Iteration=2006\t Loss=2.5840278\t mu=8.887568\t sigma=1.1710634\n",
      "Iteration=2007\t Loss=2.58375\t mu=8.890188\t sigma=1.1707647\n",
      "Iteration=2008\t Loss=2.5834732\t mu=8.892803\t sigma=1.170467\n",
      "Iteration=2009\t Loss=2.5831974\t mu=8.895413\t sigma=1.1701704\n",
      "Iteration=2010\t Loss=2.5829227\t mu=8.898019\t sigma=1.1698748\n",
      "Iteration=2011\t Loss=2.5826488\t mu=8.9006195\t sigma=1.1695802\n",
      "Iteration=2012\t Loss=2.5823762\t mu=8.903215\t sigma=1.1692867\n",
      "Iteration=2013\t Loss=2.5821042\t mu=8.905807\t sigma=1.1689943\n",
      "Iteration=2014\t Loss=2.5818334\t mu=8.908393\t sigma=1.1687028\n",
      "Iteration=2015\t Loss=2.5815637\t mu=8.9109745\t sigma=1.1684124\n",
      "Iteration=2016\t Loss=2.581295\t mu=8.913551\t sigma=1.1681231\n",
      "Iteration=2017\t Loss=2.5810275\t mu=8.916123\t sigma=1.1678348\n",
      "Iteration=2018\t Loss=2.5807607\t mu=8.918691\t sigma=1.1675475\n",
      "Iteration=2019\t Loss=2.5804949\t mu=8.921253\t sigma=1.1672612\n",
      "Iteration=2020\t Loss=2.5802302\t mu=8.923811\t sigma=1.166976\n",
      "Iteration=2021\t Loss=2.5799665\t mu=8.926364\t sigma=1.1666918\n",
      "Iteration=2022\t Loss=2.579704\t mu=8.928912\t sigma=1.1664085\n",
      "Iteration=2023\t Loss=2.5794423\t mu=8.931456\t sigma=1.1661264\n",
      "Iteration=2024\t Loss=2.5791812\t mu=8.933994\t sigma=1.1658453\n",
      "Iteration=2025\t Loss=2.5789218\t mu=8.936528\t sigma=1.1655651\n",
      "Iteration=2026\t Loss=2.5786624\t mu=8.939057\t sigma=1.1652861\n",
      "Iteration=2027\t Loss=2.5784047\t mu=8.941583\t sigma=1.165008\n",
      "Iteration=2028\t Loss=2.5781476\t mu=8.944103\t sigma=1.1647309\n",
      "Iteration=2029\t Loss=2.577892\t mu=8.946619\t sigma=1.1644548\n",
      "Iteration=2030\t Loss=2.5776372\t mu=8.94913\t sigma=1.1641798\n",
      "Iteration=2031\t Loss=2.5773833\t mu=8.951636\t sigma=1.1639057\n",
      "Iteration=2032\t Loss=2.5771306\t mu=8.954138\t sigma=1.1636326\n",
      "Iteration=2033\t Loss=2.5768783\t mu=8.9566345\t sigma=1.1633606\n",
      "Iteration=2034\t Loss=2.5766273\t mu=8.959126\t sigma=1.1630895\n",
      "Iteration=2035\t Loss=2.576377\t mu=8.961614\t sigma=1.1628195\n",
      "Iteration=2036\t Loss=2.5761278\t mu=8.964096\t sigma=1.1625504\n",
      "Iteration=2037\t Loss=2.5758796\t mu=8.966574\t sigma=1.1622823\n",
      "Iteration=2038\t Loss=2.5756323\t mu=8.969047\t sigma=1.1620153\n",
      "Iteration=2039\t Loss=2.5753863\t mu=8.971515\t sigma=1.1617492\n",
      "Iteration=2040\t Loss=2.5751412\t mu=8.973978\t sigma=1.1614841\n",
      "Iteration=2041\t Loss=2.5748966\t mu=8.976437\t sigma=1.1612201\n",
      "Iteration=2042\t Loss=2.5746534\t mu=8.97889\t sigma=1.160957\n",
      "Iteration=2043\t Loss=2.574411\t mu=8.981339\t sigma=1.1606948\n",
      "Iteration=2044\t Loss=2.5741694\t mu=8.983784\t sigma=1.1604337\n",
      "Iteration=2045\t Loss=2.5739288\t mu=8.986223\t sigma=1.1601735\n",
      "Iteration=2046\t Loss=2.5736892\t mu=8.988658\t sigma=1.1599144\n",
      "Iteration=2047\t Loss=2.5734503\t mu=8.991088\t sigma=1.1596562\n",
      "Iteration=2048\t Loss=2.5732126\t mu=8.993513\t sigma=1.1593989\n",
      "Iteration=2049\t Loss=2.5729759\t mu=8.995934\t sigma=1.1591427\n",
      "Iteration=2050\t Loss=2.57274\t mu=8.998349\t sigma=1.1588875\n",
      "Iteration=2051\t Loss=2.572505\t mu=9.000761\t sigma=1.1586332\n",
      "Iteration=2052\t Loss=2.572271\t mu=9.003168\t sigma=1.1583799\n",
      "Iteration=2053\t Loss=2.5720382\t mu=9.00557\t sigma=1.1581275\n",
      "Iteration=2054\t Loss=2.5718057\t mu=9.007968\t sigma=1.1578761\n",
      "Iteration=2055\t Loss=2.5715747\t mu=9.010361\t sigma=1.1576257\n",
      "Iteration=2056\t Loss=2.5713444\t mu=9.012749\t sigma=1.1573762\n",
      "Iteration=2057\t Loss=2.5711148\t mu=9.015132\t sigma=1.1571276\n",
      "Iteration=2058\t Loss=2.5708864\t mu=9.01751\t sigma=1.15688\n",
      "Iteration=2059\t Loss=2.5706587\t mu=9.019884\t sigma=1.1566334\n",
      "Iteration=2060\t Loss=2.570432\t mu=9.022253\t sigma=1.1563877\n",
      "Iteration=2061\t Loss=2.5702062\t mu=9.024617\t sigma=1.156143\n",
      "Iteration=2062\t Loss=2.5699816\t mu=9.026977\t sigma=1.1558992\n",
      "Iteration=2063\t Loss=2.5697575\t mu=9.029331\t sigma=1.1556563\n",
      "Iteration=2064\t Loss=2.5695345\t mu=9.031681\t sigma=1.1554145\n",
      "Iteration=2065\t Loss=2.5693123\t mu=9.034026\t sigma=1.1551735\n",
      "Iteration=2066\t Loss=2.569091\t mu=9.036367\t sigma=1.1549336\n",
      "Iteration=2067\t Loss=2.5688708\t mu=9.038704\t sigma=1.1546946\n",
      "Iteration=2068\t Loss=2.568651\t mu=9.041036\t sigma=1.1544564\n",
      "Iteration=2069\t Loss=2.5684326\t mu=9.043363\t sigma=1.1542192\n",
      "Iteration=2070\t Loss=2.568215\t mu=9.045685\t sigma=1.1539829\n",
      "Iteration=2071\t Loss=2.567998\t mu=9.048002\t sigma=1.1537476\n",
      "Iteration=2072\t Loss=2.567782\t mu=9.050315\t sigma=1.1535132\n",
      "Iteration=2073\t Loss=2.5675669\t mu=9.052623\t sigma=1.1532797\n",
      "Iteration=2074\t Loss=2.5673528\t mu=9.054926\t sigma=1.1530471\n",
      "Iteration=2075\t Loss=2.5671396\t mu=9.057224\t sigma=1.1528155\n",
      "Iteration=2076\t Loss=2.566927\t mu=9.059519\t sigma=1.1525848\n",
      "Iteration=2077\t Loss=2.5667157\t mu=9.061809\t sigma=1.152355\n",
      "Iteration=2078\t Loss=2.566505\t mu=9.064094\t sigma=1.1521261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=2079\t Loss=2.5662951\t mu=9.066374\t sigma=1.151898\n",
      "Iteration=2080\t Loss=2.5660863\t mu=9.068649\t sigma=1.1516709\n",
      "Iteration=2081\t Loss=2.5658782\t mu=9.07092\t sigma=1.1514448\n",
      "Iteration=2082\t Loss=2.5656707\t mu=9.073186\t sigma=1.1512195\n",
      "Iteration=2083\t Loss=2.5654647\t mu=9.075447\t sigma=1.1509951\n",
      "Iteration=2084\t Loss=2.565259\t mu=9.077704\t sigma=1.1507716\n",
      "Iteration=2085\t Loss=2.5650542\t mu=9.079957\t sigma=1.150549\n",
      "Iteration=2086\t Loss=2.56485\t mu=9.082205\t sigma=1.1503273\n",
      "Iteration=2087\t Loss=2.5646474\t mu=9.084448\t sigma=1.1501065\n",
      "Iteration=2088\t Loss=2.5644453\t mu=9.086686\t sigma=1.1498866\n",
      "Iteration=2089\t Loss=2.564244\t mu=9.08892\t sigma=1.1496676\n",
      "Iteration=2090\t Loss=2.5640435\t mu=9.091148\t sigma=1.1494495\n",
      "Iteration=2091\t Loss=2.5638437\t mu=9.093373\t sigma=1.1492323\n",
      "Iteration=2092\t Loss=2.5636451\t mu=9.095593\t sigma=1.1490159\n",
      "Iteration=2093\t Loss=2.563447\t mu=9.097809\t sigma=1.1488004\n",
      "Iteration=2094\t Loss=2.56325\t mu=9.100019\t sigma=1.1485858\n",
      "Iteration=2095\t Loss=2.5630538\t mu=9.102225\t sigma=1.148372\n",
      "Iteration=2096\t Loss=2.562858\t mu=9.104426\t sigma=1.1481593\n",
      "Iteration=2097\t Loss=2.5626636\t mu=9.106624\t sigma=1.1479473\n",
      "Iteration=2098\t Loss=2.56247\t mu=9.108816\t sigma=1.1477362\n",
      "Iteration=2099\t Loss=2.5622766\t mu=9.111004\t sigma=1.1475259\n",
      "Iteration=2100\t Loss=2.5620842\t mu=9.113187\t sigma=1.1473166\n",
      "Iteration=2101\t Loss=2.5618935\t mu=9.115365\t sigma=1.1471081\n",
      "Iteration=2102\t Loss=2.561703\t mu=9.117538\t sigma=1.1469004\n",
      "Iteration=2103\t Loss=2.5615132\t mu=9.119708\t sigma=1.1466936\n",
      "Iteration=2104\t Loss=2.5613241\t mu=9.121873\t sigma=1.1464876\n",
      "Iteration=2105\t Loss=2.561136\t mu=9.124033\t sigma=1.1462824\n",
      "Iteration=2106\t Loss=2.5609488\t mu=9.126188\t sigma=1.1460782\n",
      "Iteration=2107\t Loss=2.5607622\t mu=9.128339\t sigma=1.1458749\n",
      "Iteration=2108\t Loss=2.5605767\t mu=9.130486\t sigma=1.1456723\n",
      "Iteration=2109\t Loss=2.5603914\t mu=9.1326275\t sigma=1.1454706\n",
      "Iteration=2110\t Loss=2.5602074\t mu=9.134765\t sigma=1.1452698\n",
      "Iteration=2111\t Loss=2.5600243\t mu=9.136897\t sigma=1.1450697\n",
      "Iteration=2112\t Loss=2.5598416\t mu=9.139026\t sigma=1.1448705\n",
      "Iteration=2113\t Loss=2.5596595\t mu=9.1411495\t sigma=1.1446722\n",
      "Iteration=2114\t Loss=2.559479\t mu=9.143269\t sigma=1.1444746\n",
      "Iteration=2115\t Loss=2.5592983\t mu=9.145383\t sigma=1.1442779\n",
      "Iteration=2116\t Loss=2.5591192\t mu=9.147493\t sigma=1.1440821\n",
      "Iteration=2117\t Loss=2.5589402\t mu=9.149599\t sigma=1.1438869\n",
      "Iteration=2118\t Loss=2.5587623\t mu=9.1517\t sigma=1.1436926\n",
      "Iteration=2119\t Loss=2.5585856\t mu=9.153796\t sigma=1.1434991\n",
      "Iteration=2120\t Loss=2.558409\t mu=9.155889\t sigma=1.1433065\n",
      "Iteration=2121\t Loss=2.5582335\t mu=9.157976\t sigma=1.1431147\n",
      "Iteration=2122\t Loss=2.5580585\t mu=9.160059\t sigma=1.1429237\n",
      "Iteration=2123\t Loss=2.5578847\t mu=9.162137\t sigma=1.1427336\n",
      "Iteration=2124\t Loss=2.5577114\t mu=9.164211\t sigma=1.1425442\n",
      "Iteration=2125\t Loss=2.5575387\t mu=9.166281\t sigma=1.1423556\n",
      "Iteration=2126\t Loss=2.557367\t mu=9.168345\t sigma=1.1421678\n",
      "Iteration=2127\t Loss=2.557196\t mu=9.170406\t sigma=1.1419808\n",
      "Iteration=2128\t Loss=2.5570257\t mu=9.172462\t sigma=1.1417946\n",
      "Iteration=2129\t Loss=2.5568562\t mu=9.174514\t sigma=1.1416092\n",
      "Iteration=2130\t Loss=2.556687\t mu=9.176561\t sigma=1.1414247\n",
      "Iteration=2131\t Loss=2.556519\t mu=9.178604\t sigma=1.1412408\n",
      "Iteration=2132\t Loss=2.5563517\t mu=9.180642\t sigma=1.1410578\n",
      "Iteration=2133\t Loss=2.5561852\t mu=9.182676\t sigma=1.1408756\n",
      "Iteration=2134\t Loss=2.5560195\t mu=9.184706\t sigma=1.1406941\n",
      "Iteration=2135\t Loss=2.5558538\t mu=9.18673\t sigma=1.1405134\n",
      "Iteration=2136\t Loss=2.5556898\t mu=9.188751\t sigma=1.1403335\n",
      "Iteration=2137\t Loss=2.5555263\t mu=9.190767\t sigma=1.1401544\n",
      "Iteration=2138\t Loss=2.5553632\t mu=9.192779\t sigma=1.139976\n",
      "Iteration=2139\t Loss=2.5552008\t mu=9.194786\t sigma=1.1397984\n",
      "Iteration=2140\t Loss=2.5550392\t mu=9.196789\t sigma=1.1396216\n",
      "Iteration=2141\t Loss=2.5548785\t mu=9.198787\t sigma=1.1394455\n",
      "Iteration=2142\t Loss=2.5547187\t mu=9.200781\t sigma=1.1392703\n",
      "Iteration=2143\t Loss=2.5545595\t mu=9.20277\t sigma=1.1390958\n",
      "Iteration=2144\t Loss=2.5544007\t mu=9.204756\t sigma=1.138922\n",
      "Iteration=2145\t Loss=2.5542424\t mu=9.206737\t sigma=1.138749\n",
      "Iteration=2146\t Loss=2.5540855\t mu=9.208713\t sigma=1.1385767\n",
      "Iteration=2147\t Loss=2.5539289\t mu=9.210685\t sigma=1.1384052\n",
      "Iteration=2148\t Loss=2.553773\t mu=9.212652\t sigma=1.1382345\n",
      "Iteration=2149\t Loss=2.5536175\t mu=9.214616\t sigma=1.1380645\n",
      "Iteration=2150\t Loss=2.553463\t mu=9.216575\t sigma=1.1378952\n",
      "Iteration=2151\t Loss=2.5533094\t mu=9.218529\t sigma=1.1377267\n",
      "Iteration=2152\t Loss=2.5531561\t mu=9.220479\t sigma=1.1375589\n",
      "Iteration=2153\t Loss=2.5530038\t mu=9.2224245\t sigma=1.1373919\n",
      "Iteration=2154\t Loss=2.5528522\t mu=9.224366\t sigma=1.1372256\n",
      "Iteration=2155\t Loss=2.5527015\t mu=9.226303\t sigma=1.13706\n",
      "Iteration=2156\t Loss=2.552551\t mu=9.228236\t sigma=1.1368952\n",
      "Iteration=2157\t Loss=2.5524013\t mu=9.230165\t sigma=1.136731\n",
      "Iteration=2158\t Loss=2.5522525\t mu=9.232088\t sigma=1.1365676\n",
      "Iteration=2159\t Loss=2.5521042\t mu=9.234008\t sigma=1.1364049\n",
      "Iteration=2160\t Loss=2.5519564\t mu=9.235923\t sigma=1.1362429\n",
      "Iteration=2161\t Loss=2.5518093\t mu=9.237834\t sigma=1.1360816\n",
      "Iteration=2162\t Loss=2.5516634\t mu=9.23974\t sigma=1.135921\n",
      "Iteration=2163\t Loss=2.5515175\t mu=9.241643\t sigma=1.1357611\n",
      "Iteration=2164\t Loss=2.5513728\t mu=9.243541\t sigma=1.135602\n",
      "Iteration=2165\t Loss=2.5512285\t mu=9.245435\t sigma=1.1354436\n",
      "Iteration=2166\t Loss=2.5510848\t mu=9.247324\t sigma=1.1352859\n",
      "Iteration=2167\t Loss=2.5509417\t mu=9.249209\t sigma=1.1351289\n",
      "Iteration=2168\t Loss=2.5507996\t mu=9.25109\t sigma=1.1349726\n",
      "Iteration=2169\t Loss=2.5506577\t mu=9.252967\t sigma=1.134817\n",
      "Iteration=2170\t Loss=2.550517\t mu=9.254839\t sigma=1.1346622\n",
      "Iteration=2171\t Loss=2.5503762\t mu=9.256707\t sigma=1.1345079\n",
      "Iteration=2172\t Loss=2.5502365\t mu=9.258571\t sigma=1.1343544\n",
      "Iteration=2173\t Loss=2.5500975\t mu=9.26043\t sigma=1.1342015\n",
      "Iteration=2174\t Loss=2.5499592\t mu=9.262286\t sigma=1.1340494\n",
      "Iteration=2175\t Loss=2.5498211\t mu=9.264137\t sigma=1.133898\n",
      "Iteration=2176\t Loss=2.5496838\t mu=9.265985\t sigma=1.1337472\n",
      "Iteration=2177\t Loss=2.5495477\t mu=9.267827\t sigma=1.1335971\n",
      "Iteration=2178\t Loss=2.549411\t mu=9.269666\t sigma=1.1334478\n",
      "Iteration=2179\t Loss=2.549276\t mu=9.2715\t sigma=1.133299\n",
      "Iteration=2180\t Loss=2.5491414\t mu=9.27333\t sigma=1.1331509\n",
      "Iteration=2181\t Loss=2.5490074\t mu=9.275156\t sigma=1.1330036\n",
      "Iteration=2182\t Loss=2.548874\t mu=9.276978\t sigma=1.1328568\n",
      "Iteration=2183\t Loss=2.548741\t mu=9.278795\t sigma=1.1327108\n",
      "Iteration=2184\t Loss=2.5486088\t mu=9.280608\t sigma=1.1325654\n",
      "Iteration=2185\t Loss=2.5484774\t mu=9.282417\t sigma=1.1324207\n",
      "Iteration=2186\t Loss=2.5483465\t mu=9.284223\t sigma=1.1322765\n",
      "Iteration=2187\t Loss=2.5482159\t mu=9.286023\t sigma=1.1321331\n",
      "Iteration=2188\t Loss=2.548086\t mu=9.28782\t sigma=1.1319903\n",
      "Iteration=2189\t Loss=2.547957\t mu=9.289613\t sigma=1.1318482\n",
      "Iteration=2190\t Loss=2.5478284\t mu=9.291401\t sigma=1.1317067\n",
      "Iteration=2191\t Loss=2.5477004\t mu=9.293185\t sigma=1.1315658\n",
      "Iteration=2192\t Loss=2.547573\t mu=9.294966\t sigma=1.1314256\n",
      "Iteration=2193\t Loss=2.547446\t mu=9.2967415\t sigma=1.131286\n",
      "Iteration=2194\t Loss=2.5473201\t mu=9.298513\t sigma=1.1311471\n",
      "Iteration=2195\t Loss=2.5471945\t mu=9.300282\t sigma=1.1310089\n",
      "Iteration=2196\t Loss=2.547069\t mu=9.302045\t sigma=1.1308712\n",
      "Iteration=2197\t Loss=2.5469449\t mu=9.303804\t sigma=1.1307342\n",
      "Iteration=2198\t Loss=2.5468214\t mu=9.30556\t sigma=1.1305978\n",
      "Iteration=2199\t Loss=2.5466976\t mu=9.307311\t sigma=1.130462\n",
      "Iteration=2200\t Loss=2.5465753\t mu=9.309058\t sigma=1.1303269\n",
      "Iteration=2201\t Loss=2.5464532\t mu=9.3108015\t sigma=1.1301924\n",
      "Iteration=2202\t Loss=2.5463314\t mu=9.31254\t sigma=1.1300585\n",
      "Iteration=2203\t Loss=2.5462108\t mu=9.314275\t sigma=1.1299253\n",
      "Iteration=2204\t Loss=2.5460901\t mu=9.316006\t sigma=1.1297926\n",
      "Iteration=2205\t Loss=2.5459702\t mu=9.317733\t sigma=1.1296605\n",
      "Iteration=2206\t Loss=2.545851\t mu=9.319455\t sigma=1.129529\n",
      "Iteration=2207\t Loss=2.5457323\t mu=9.321174\t sigma=1.1293982\n",
      "Iteration=2208\t Loss=2.545614\t mu=9.322888\t sigma=1.129268\n",
      "Iteration=2209\t Loss=2.5454965\t mu=9.324599\t sigma=1.1291385\n",
      "Iteration=2210\t Loss=2.5453794\t mu=9.326306\t sigma=1.1290095\n",
      "Iteration=2211\t Loss=2.545263\t mu=9.328009\t sigma=1.1288811\n",
      "Iteration=2212\t Loss=2.5451472\t mu=9.329707\t sigma=1.1287533\n",
      "Iteration=2213\t Loss=2.5450318\t mu=9.331402\t sigma=1.1286261\n",
      "Iteration=2214\t Loss=2.544917\t mu=9.333093\t sigma=1.1284995\n",
      "Iteration=2215\t Loss=2.5448024\t mu=9.33478\t sigma=1.1283735\n",
      "Iteration=2216\t Loss=2.544689\t mu=9.336462\t sigma=1.128248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=2217\t Loss=2.5445757\t mu=9.3381405\t sigma=1.128123\n",
      "Iteration=2218\t Loss=2.5444627\t mu=9.339815\t sigma=1.1279987\n",
      "Iteration=2219\t Loss=2.5443509\t mu=9.341486\t sigma=1.127875\n",
      "Iteration=2220\t Loss=2.5442393\t mu=9.343153\t sigma=1.1277518\n",
      "Iteration=2221\t Loss=2.5441284\t mu=9.344816\t sigma=1.1276293\n",
      "Iteration=2222\t Loss=2.5440176\t mu=9.346475\t sigma=1.1275073\n",
      "Iteration=2223\t Loss=2.5439079\t mu=9.348129\t sigma=1.1273859\n",
      "Iteration=2224\t Loss=2.5437982\t mu=9.34978\t sigma=1.127265\n",
      "Iteration=2225\t Loss=2.5436893\t mu=9.351427\t sigma=1.1271447\n",
      "Iteration=2226\t Loss=2.543581\t mu=9.35307\t sigma=1.127025\n",
      "Iteration=2227\t Loss=2.5434728\t mu=9.35471\t sigma=1.1269059\n",
      "Iteration=2228\t Loss=2.5433657\t mu=9.356345\t sigma=1.1267873\n",
      "Iteration=2229\t Loss=2.5432587\t mu=9.357977\t sigma=1.1266693\n",
      "Iteration=2230\t Loss=2.543152\t mu=9.359604\t sigma=1.1265519\n",
      "Iteration=2231\t Loss=2.5430465\t mu=9.361227\t sigma=1.1264349\n",
      "Iteration=2232\t Loss=2.542941\t mu=9.362846\t sigma=1.1263186\n",
      "Iteration=2233\t Loss=2.5428364\t mu=9.364462\t sigma=1.1262028\n",
      "Iteration=2234\t Loss=2.5427315\t mu=9.366074\t sigma=1.1260875\n",
      "Iteration=2235\t Loss=2.5426278\t mu=9.3676815\t sigma=1.1259729\n",
      "Iteration=2236\t Loss=2.542525\t mu=9.369286\t sigma=1.1258587\n",
      "Iteration=2237\t Loss=2.542422\t mu=9.370886\t sigma=1.125745\n",
      "Iteration=2238\t Loss=2.54232\t mu=9.372482\t sigma=1.1256319\n",
      "Iteration=2239\t Loss=2.5422175\t mu=9.374075\t sigma=1.1255194\n",
      "Iteration=2240\t Loss=2.5421164\t mu=9.375664\t sigma=1.1254073\n",
      "Iteration=2241\t Loss=2.5420158\t mu=9.377249\t sigma=1.1252959\n",
      "Iteration=2242\t Loss=2.541915\t mu=9.37883\t sigma=1.1251849\n",
      "Iteration=2243\t Loss=2.5418155\t mu=9.380407\t sigma=1.1250745\n",
      "Iteration=2244\t Loss=2.5417159\t mu=9.381981\t sigma=1.1249646\n",
      "Iteration=2245\t Loss=2.541617\t mu=9.383551\t sigma=1.1248553\n",
      "Iteration=2246\t Loss=2.5415187\t mu=9.385117\t sigma=1.1247464\n",
      "Iteration=2247\t Loss=2.5414207\t mu=9.386679\t sigma=1.1246381\n",
      "Iteration=2248\t Loss=2.5413234\t mu=9.388237\t sigma=1.1245303\n",
      "Iteration=2249\t Loss=2.5412261\t mu=9.3897915\t sigma=1.124423\n",
      "Iteration=2250\t Loss=2.5411296\t mu=9.391342\t sigma=1.1243162\n",
      "Iteration=2251\t Loss=2.5410335\t mu=9.392889\t sigma=1.12421\n",
      "Iteration=2252\t Loss=2.540938\t mu=9.394432\t sigma=1.1241043\n",
      "Iteration=2253\t Loss=2.5408428\t mu=9.395971\t sigma=1.123999\n",
      "Iteration=2254\t Loss=2.5407484\t mu=9.397507\t sigma=1.1238942\n",
      "Iteration=2255\t Loss=2.540654\t mu=9.399039\t sigma=1.12379\n",
      "Iteration=2256\t Loss=2.5405602\t mu=9.400568\t sigma=1.1236863\n",
      "Iteration=2257\t Loss=2.5404668\t mu=9.402093\t sigma=1.1235831\n",
      "Iteration=2258\t Loss=2.5403743\t mu=9.403614\t sigma=1.1234803\n",
      "Iteration=2259\t Loss=2.5402815\t mu=9.405131\t sigma=1.123378\n",
      "Iteration=2260\t Loss=2.5401897\t mu=9.406645\t sigma=1.1232762\n",
      "Iteration=2261\t Loss=2.540098\t mu=9.4081545\t sigma=1.123175\n",
      "Iteration=2262\t Loss=2.540007\t mu=9.40966\t sigma=1.1230743\n",
      "Iteration=2263\t Loss=2.5399168\t mu=9.411162\t sigma=1.122974\n",
      "Iteration=2264\t Loss=2.5398269\t mu=9.412662\t sigma=1.1228743\n",
      "Iteration=2265\t Loss=2.5397367\t mu=9.414157\t sigma=1.122775\n",
      "Iteration=2266\t Loss=2.5396476\t mu=9.415648\t sigma=1.1226761\n",
      "Iteration=2267\t Loss=2.5395586\t mu=9.417136\t sigma=1.1225778\n",
      "Iteration=2268\t Loss=2.5394704\t mu=9.41862\t sigma=1.1224799\n",
      "Iteration=2269\t Loss=2.5393822\t mu=9.4201\t sigma=1.1223825\n",
      "Iteration=2270\t Loss=2.5392952\t mu=9.421577\t sigma=1.1222856\n",
      "Iteration=2271\t Loss=2.5392077\t mu=9.423051\t sigma=1.1221892\n",
      "Iteration=2272\t Loss=2.5391212\t mu=9.4245205\t sigma=1.1220932\n",
      "Iteration=2273\t Loss=2.539035\t mu=9.425986\t sigma=1.1219977\n",
      "Iteration=2274\t Loss=2.538949\t mu=9.427448\t sigma=1.1219027\n",
      "Iteration=2275\t Loss=2.538864\t mu=9.428907\t sigma=1.121808\n",
      "Iteration=2276\t Loss=2.538779\t mu=9.430363\t sigma=1.1217139\n",
      "Iteration=2277\t Loss=2.538694\t mu=9.431814\t sigma=1.1216202\n",
      "Iteration=2278\t Loss=2.5386105\t mu=9.433262\t sigma=1.121527\n",
      "Iteration=2279\t Loss=2.5385268\t mu=9.434707\t sigma=1.1214342\n",
      "Iteration=2280\t Loss=2.5384429\t mu=9.436148\t sigma=1.121342\n",
      "Iteration=2281\t Loss=2.5383604\t mu=9.437585\t sigma=1.12125\n",
      "Iteration=2282\t Loss=2.5382779\t mu=9.439018\t sigma=1.1211586\n",
      "Iteration=2283\t Loss=2.5381956\t mu=9.440449\t sigma=1.1210676\n",
      "Iteration=2284\t Loss=2.5381143\t mu=9.441875\t sigma=1.1209772\n",
      "Iteration=2285\t Loss=2.538033\t mu=9.443298\t sigma=1.120887\n",
      "Iteration=2286\t Loss=2.537952\t mu=9.444718\t sigma=1.1207974\n",
      "Iteration=2287\t Loss=2.5378716\t mu=9.446135\t sigma=1.1207082\n",
      "Iteration=2288\t Loss=2.5377915\t mu=9.447547\t sigma=1.1206194\n",
      "Iteration=2289\t Loss=2.5377119\t mu=9.4489565\t sigma=1.1205311\n",
      "Iteration=2290\t Loss=2.5376325\t mu=9.450362\t sigma=1.1204432\n",
      "Iteration=2291\t Loss=2.5375538\t mu=9.451764\t sigma=1.1203557\n",
      "Iteration=2292\t Loss=2.537475\t mu=9.453163\t sigma=1.1202687\n",
      "Iteration=2293\t Loss=2.5373974\t mu=9.454558\t sigma=1.1201822\n",
      "Iteration=2294\t Loss=2.5373194\t mu=9.45595\t sigma=1.120096\n",
      "Iteration=2295\t Loss=2.5372422\t mu=9.457338\t sigma=1.1200103\n",
      "Iteration=2296\t Loss=2.5371654\t mu=9.458723\t sigma=1.1199249\n",
      "Iteration=2297\t Loss=2.5370886\t mu=9.460104\t sigma=1.11984\n",
      "Iteration=2298\t Loss=2.5370126\t mu=9.461482\t sigma=1.1197555\n",
      "Iteration=2299\t Loss=2.536937\t mu=9.462856\t sigma=1.1196715\n",
      "Iteration=2300\t Loss=2.5368614\t mu=9.464228\t sigma=1.1195878\n",
      "Iteration=2301\t Loss=2.5367866\t mu=9.465595\t sigma=1.1195046\n",
      "Iteration=2302\t Loss=2.536712\t mu=9.466959\t sigma=1.1194217\n",
      "Iteration=2303\t Loss=2.536638\t mu=9.46832\t sigma=1.1193393\n",
      "Iteration=2304\t Loss=2.5365639\t mu=9.469677\t sigma=1.1192573\n",
      "Iteration=2305\t Loss=2.5364904\t mu=9.471031\t sigma=1.1191757\n",
      "Iteration=2306\t Loss=2.5364172\t mu=9.472382\t sigma=1.1190945\n",
      "Iteration=2307\t Loss=2.5363445\t mu=9.473729\t sigma=1.1190137\n",
      "Iteration=2308\t Loss=2.536272\t mu=9.475073\t sigma=1.1189333\n",
      "Iteration=2309\t Loss=2.5362003\t mu=9.476414\t sigma=1.1188533\n",
      "Iteration=2310\t Loss=2.5361285\t mu=9.477751\t sigma=1.1187737\n",
      "Iteration=2311\t Loss=2.5360572\t mu=9.479085\t sigma=1.1186945\n",
      "Iteration=2312\t Loss=2.535986\t mu=9.480415\t sigma=1.1186157\n",
      "Iteration=2313\t Loss=2.5359151\t mu=9.481743\t sigma=1.1185373\n",
      "Iteration=2314\t Loss=2.5358453\t mu=9.483067\t sigma=1.1184592\n",
      "Iteration=2315\t Loss=2.5357754\t mu=9.484387\t sigma=1.1183816\n",
      "Iteration=2316\t Loss=2.5357056\t mu=9.485704\t sigma=1.1183044\n",
      "Iteration=2317\t Loss=2.5356367\t mu=9.487019\t sigma=1.1182275\n",
      "Iteration=2318\t Loss=2.5355675\t mu=9.488329\t sigma=1.118151\n",
      "Iteration=2319\t Loss=2.5354993\t mu=9.489636\t sigma=1.1180749\n",
      "Iteration=2320\t Loss=2.5354311\t mu=9.49094\t sigma=1.1179992\n",
      "Iteration=2321\t Loss=2.5353632\t mu=9.492241\t sigma=1.1179239\n",
      "Iteration=2322\t Loss=2.5352957\t mu=9.493538\t sigma=1.1178489\n",
      "Iteration=2323\t Loss=2.5352285\t mu=9.494832\t sigma=1.1177742\n",
      "Iteration=2324\t Loss=2.535162\t mu=9.496122\t sigma=1.1177\n",
      "Iteration=2325\t Loss=2.5350952\t mu=9.49741\t sigma=1.1176262\n",
      "Iteration=2326\t Loss=2.5350294\t mu=9.498694\t sigma=1.1175528\n",
      "Iteration=2327\t Loss=2.5349634\t mu=9.499975\t sigma=1.1174797\n",
      "Iteration=2328\t Loss=2.5348983\t mu=9.501253\t sigma=1.117407\n",
      "Iteration=2329\t Loss=2.5348332\t mu=9.502527\t sigma=1.1173346\n",
      "Iteration=2330\t Loss=2.5347679\t mu=9.5037985\t sigma=1.1172626\n",
      "Iteration=2331\t Loss=2.5347037\t mu=9.505067\t sigma=1.117191\n",
      "Iteration=2332\t Loss=2.5346396\t mu=9.506331\t sigma=1.1171197\n",
      "Iteration=2333\t Loss=2.534576\t mu=9.507593\t sigma=1.1170487\n",
      "Iteration=2334\t Loss=2.5345125\t mu=9.508852\t sigma=1.1169782\n",
      "Iteration=2335\t Loss=2.534449\t mu=9.510107\t sigma=1.116908\n",
      "Iteration=2336\t Loss=2.5343866\t mu=9.511359\t sigma=1.1168381\n",
      "Iteration=2337\t Loss=2.534324\t mu=9.512609\t sigma=1.1167686\n",
      "Iteration=2338\t Loss=2.5342617\t mu=9.513854\t sigma=1.1166995\n",
      "Iteration=2339\t Loss=2.5342\t mu=9.515097\t sigma=1.1166307\n",
      "Iteration=2340\t Loss=2.5341382\t mu=9.516336\t sigma=1.1165622\n",
      "Iteration=2341\t Loss=2.5340772\t mu=9.517572\t sigma=1.116494\n",
      "Iteration=2342\t Loss=2.5340161\t mu=9.5188055\t sigma=1.1164262\n",
      "Iteration=2343\t Loss=2.5339556\t mu=9.520036\t sigma=1.1163588\n",
      "Iteration=2344\t Loss=2.533895\t mu=9.521262\t sigma=1.1162916\n",
      "Iteration=2345\t Loss=2.5338352\t mu=9.522486\t sigma=1.1162249\n",
      "Iteration=2346\t Loss=2.5337753\t mu=9.523706\t sigma=1.1161585\n",
      "Iteration=2347\t Loss=2.5337162\t mu=9.524924\t sigma=1.1160924\n",
      "Iteration=2348\t Loss=2.533657\t mu=9.526138\t sigma=1.1160266\n",
      "Iteration=2349\t Loss=2.5335982\t mu=9.527349\t sigma=1.1159612\n",
      "Iteration=2350\t Loss=2.5335395\t mu=9.528558\t sigma=1.1158961\n",
      "Iteration=2351\t Loss=2.533482\t mu=9.529763\t sigma=1.1158314\n",
      "Iteration=2352\t Loss=2.5334234\t mu=9.530965\t sigma=1.115767\n",
      "Iteration=2353\t Loss=2.5333662\t mu=9.532164\t sigma=1.1157029\n",
      "Iteration=2354\t Loss=2.533309\t mu=9.53336\t sigma=1.1156391\n",
      "Iteration=2355\t Loss=2.5332518\t mu=9.534553\t sigma=1.1155757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=2356\t Loss=2.533195\t mu=9.535743\t sigma=1.1155125\n",
      "Iteration=2357\t Loss=2.5331388\t mu=9.536929\t sigma=1.1154497\n",
      "Iteration=2358\t Loss=2.5330825\t mu=9.538113\t sigma=1.1153872\n",
      "Iteration=2359\t Loss=2.533027\t mu=9.539293\t sigma=1.1153251\n",
      "Iteration=2360\t Loss=2.5329714\t mu=9.540471\t sigma=1.1152632\n",
      "Iteration=2361\t Loss=2.532916\t mu=9.541646\t sigma=1.1152017\n",
      "Iteration=2362\t Loss=2.5328608\t mu=9.542818\t sigma=1.1151404\n",
      "Iteration=2363\t Loss=2.5328062\t mu=9.543986\t sigma=1.1150795\n",
      "Iteration=2364\t Loss=2.5327518\t mu=9.545152\t sigma=1.115019\n",
      "Iteration=2365\t Loss=2.5326974\t mu=9.546314\t sigma=1.1149586\n",
      "Iteration=2366\t Loss=2.5326436\t mu=9.547474\t sigma=1.1148987\n",
      "Iteration=2367\t Loss=2.5325902\t mu=9.548631\t sigma=1.114839\n",
      "Iteration=2368\t Loss=2.532537\t mu=9.549785\t sigma=1.1147796\n",
      "Iteration=2369\t Loss=2.5324836\t mu=9.550936\t sigma=1.1147206\n",
      "Iteration=2370\t Loss=2.5324311\t mu=9.552084\t sigma=1.1146618\n",
      "Iteration=2371\t Loss=2.5323784\t mu=9.553228\t sigma=1.1146034\n",
      "Iteration=2372\t Loss=2.5323265\t mu=9.55437\t sigma=1.1145452\n",
      "Iteration=2373\t Loss=2.5322747\t mu=9.555509\t sigma=1.1144874\n",
      "Iteration=2374\t Loss=2.5322227\t mu=9.556644\t sigma=1.1144298\n",
      "Iteration=2375\t Loss=2.5321712\t mu=9.557777\t sigma=1.1143725\n",
      "Iteration=2376\t Loss=2.5321202\t mu=9.5589075\t sigma=1.1143155\n",
      "Iteration=2377\t Loss=2.532069\t mu=9.560035\t sigma=1.1142588\n",
      "Iteration=2378\t Loss=2.5320184\t mu=9.561159\t sigma=1.1142024\n",
      "Iteration=2379\t Loss=2.531968\t mu=9.562281\t sigma=1.1141462\n",
      "Iteration=2380\t Loss=2.531918\t mu=9.563399\t sigma=1.1140904\n",
      "Iteration=2381\t Loss=2.5318685\t mu=9.564515\t sigma=1.1140349\n",
      "Iteration=2382\t Loss=2.5318189\t mu=9.565628\t sigma=1.1139796\n",
      "Iteration=2383\t Loss=2.531769\t mu=9.566738\t sigma=1.1139246\n",
      "Iteration=2384\t Loss=2.5317204\t mu=9.567845\t sigma=1.1138699\n",
      "Iteration=2385\t Loss=2.5316715\t mu=9.56895\t sigma=1.1138155\n",
      "Iteration=2386\t Loss=2.5316231\t mu=9.570051\t sigma=1.1137614\n",
      "Iteration=2387\t Loss=2.5315745\t mu=9.57115\t sigma=1.1137075\n",
      "Iteration=2388\t Loss=2.5315263\t mu=9.572246\t sigma=1.113654\n",
      "Iteration=2389\t Loss=2.5314786\t mu=9.5733385\t sigma=1.1136007\n",
      "Iteration=2390\t Loss=2.5314312\t mu=9.574429\t sigma=1.1135477\n",
      "Iteration=2391\t Loss=2.5313835\t mu=9.575516\t sigma=1.1134949\n",
      "Iteration=2392\t Loss=2.5313368\t mu=9.5766\t sigma=1.1134424\n",
      "Iteration=2393\t Loss=2.5312898\t mu=9.577682\t sigma=1.1133902\n",
      "Iteration=2394\t Loss=2.531243\t mu=9.57876\t sigma=1.1133382\n",
      "Iteration=2395\t Loss=2.531197\t mu=9.579836\t sigma=1.1132865\n",
      "Iteration=2396\t Loss=2.5311506\t mu=9.580909\t sigma=1.1132351\n",
      "Iteration=2397\t Loss=2.531105\t mu=9.581979\t sigma=1.113184\n",
      "Iteration=2398\t Loss=2.5310593\t mu=9.583046\t sigma=1.1131331\n",
      "Iteration=2399\t Loss=2.531014\t mu=9.584111\t sigma=1.1130824\n",
      "Iteration=2400\t Loss=2.5309687\t mu=9.585174\t sigma=1.1130321\n",
      "Iteration=2401\t Loss=2.5309236\t mu=9.586233\t sigma=1.112982\n",
      "Iteration=2402\t Loss=2.530879\t mu=9.58729\t sigma=1.1129322\n",
      "Iteration=2403\t Loss=2.5308347\t mu=9.588344\t sigma=1.1128826\n",
      "Iteration=2404\t Loss=2.5307903\t mu=9.589395\t sigma=1.1128333\n",
      "Iteration=2405\t Loss=2.5307462\t mu=9.590443\t sigma=1.1127841\n",
      "Iteration=2406\t Loss=2.5307028\t mu=9.591488\t sigma=1.1127353\n",
      "Iteration=2407\t Loss=2.530659\t mu=9.59253\t sigma=1.1126868\n",
      "Iteration=2408\t Loss=2.5306158\t mu=9.593571\t sigma=1.1126385\n",
      "Iteration=2409\t Loss=2.5305727\t mu=9.594608\t sigma=1.1125904\n",
      "Iteration=2410\t Loss=2.53053\t mu=9.595643\t sigma=1.1125426\n",
      "Iteration=2411\t Loss=2.5304873\t mu=9.596675\t sigma=1.1124951\n",
      "Iteration=2412\t Loss=2.5304449\t mu=9.597704\t sigma=1.1124477\n",
      "Iteration=2413\t Loss=2.5304024\t mu=9.598731\t sigma=1.1124007\n",
      "Iteration=2414\t Loss=2.530361\t mu=9.599755\t sigma=1.1123538\n",
      "Iteration=2415\t Loss=2.5303187\t mu=9.600777\t sigma=1.1123072\n",
      "Iteration=2416\t Loss=2.5302773\t mu=9.601795\t sigma=1.1122608\n",
      "Iteration=2417\t Loss=2.5302362\t mu=9.602811\t sigma=1.1122147\n",
      "Iteration=2418\t Loss=2.5301948\t mu=9.603825\t sigma=1.1121688\n",
      "Iteration=2419\t Loss=2.530154\t mu=9.6048355\t sigma=1.1121231\n",
      "Iteration=2420\t Loss=2.5301135\t mu=9.605844\t sigma=1.1120777\n",
      "Iteration=2421\t Loss=2.5300727\t mu=9.606849\t sigma=1.1120325\n",
      "Iteration=2422\t Loss=2.5300329\t mu=9.607851\t sigma=1.1119876\n",
      "Iteration=2423\t Loss=2.5299926\t mu=9.608851\t sigma=1.1119429\n",
      "Iteration=2424\t Loss=2.529953\t mu=9.609849\t sigma=1.1118984\n",
      "Iteration=2425\t Loss=2.529913\t mu=9.610844\t sigma=1.1118542\n",
      "Iteration=2426\t Loss=2.5298738\t mu=9.611836\t sigma=1.1118102\n",
      "Iteration=2427\t Loss=2.5298343\t mu=9.612826\t sigma=1.1117665\n",
      "Iteration=2428\t Loss=2.5297956\t mu=9.613813\t sigma=1.111723\n",
      "Iteration=2429\t Loss=2.5297568\t mu=9.614798\t sigma=1.1116797\n",
      "Iteration=2430\t Loss=2.5297184\t mu=9.61578\t sigma=1.1116366\n",
      "Iteration=2431\t Loss=2.5296798\t mu=9.616759\t sigma=1.1115938\n",
      "Iteration=2432\t Loss=2.5296416\t mu=9.617736\t sigma=1.1115512\n",
      "Iteration=2433\t Loss=2.5296037\t mu=9.6187105\t sigma=1.1115087\n",
      "Iteration=2434\t Loss=2.5295656\t mu=9.619682\t sigma=1.1114665\n",
      "Iteration=2435\t Loss=2.5295281\t mu=9.620651\t sigma=1.1114246\n",
      "Iteration=2436\t Loss=2.529491\t mu=9.621618\t sigma=1.1113828\n",
      "Iteration=2437\t Loss=2.5294535\t mu=9.622582\t sigma=1.1113414\n",
      "Iteration=2438\t Loss=2.5294163\t mu=9.623544\t sigma=1.1113\n",
      "Iteration=2439\t Loss=2.5293798\t mu=9.624503\t sigma=1.1112589\n",
      "Iteration=2440\t Loss=2.5293431\t mu=9.62546\t sigma=1.111218\n",
      "Iteration=2441\t Loss=2.5293067\t mu=9.626413\t sigma=1.1111773\n",
      "Iteration=2442\t Loss=2.529271\t mu=9.627365\t sigma=1.1111369\n",
      "Iteration=2443\t Loss=2.5292346\t mu=9.628314\t sigma=1.1110966\n",
      "Iteration=2444\t Loss=2.5291986\t mu=9.62926\t sigma=1.1110566\n",
      "Iteration=2445\t Loss=2.529163\t mu=9.630204\t sigma=1.1110168\n",
      "Iteration=2446\t Loss=2.5291276\t mu=9.6311455\t sigma=1.1109772\n",
      "Iteration=2447\t Loss=2.529092\t mu=9.632085\t sigma=1.1109377\n",
      "Iteration=2448\t Loss=2.5290573\t mu=9.633021\t sigma=1.1108985\n",
      "Iteration=2449\t Loss=2.5290222\t mu=9.633955\t sigma=1.1108595\n",
      "Iteration=2450\t Loss=2.5289874\t mu=9.634887\t sigma=1.1108208\n",
      "Iteration=2451\t Loss=2.5289528\t mu=9.635816\t sigma=1.1107821\n",
      "Iteration=2452\t Loss=2.5289185\t mu=9.636743\t sigma=1.1107438\n",
      "Iteration=2453\t Loss=2.5288844\t mu=9.637667\t sigma=1.1107056\n",
      "Iteration=2454\t Loss=2.5288503\t mu=9.638589\t sigma=1.1106676\n",
      "Iteration=2455\t Loss=2.5288167\t mu=9.639508\t sigma=1.1106298\n",
      "Iteration=2456\t Loss=2.5287828\t mu=9.640426\t sigma=1.1105922\n",
      "Iteration=2457\t Loss=2.5287495\t mu=9.64134\t sigma=1.1105548\n",
      "Iteration=2458\t Loss=2.5287163\t mu=9.642252\t sigma=1.1105176\n",
      "Iteration=2459\t Loss=2.5286832\t mu=9.643162\t sigma=1.1104807\n",
      "Iteration=2460\t Loss=2.52865\t mu=9.644069\t sigma=1.1104438\n",
      "Iteration=2461\t Loss=2.5286171\t mu=9.644974\t sigma=1.1104072\n",
      "Iteration=2462\t Loss=2.5285847\t mu=9.645876\t sigma=1.1103708\n",
      "Iteration=2463\t Loss=2.5285523\t mu=9.646776\t sigma=1.1103345\n",
      "Iteration=2464\t Loss=2.5285203\t mu=9.647674\t sigma=1.1102985\n",
      "Iteration=2465\t Loss=2.528488\t mu=9.648569\t sigma=1.1102626\n",
      "Iteration=2466\t Loss=2.528456\t mu=9.649462\t sigma=1.110227\n",
      "Iteration=2467\t Loss=2.5284243\t mu=9.6503525\t sigma=1.1101915\n",
      "Iteration=2468\t Loss=2.5283928\t mu=9.651241\t sigma=1.1101562\n",
      "Iteration=2469\t Loss=2.5283608\t mu=9.652127\t sigma=1.1101211\n",
      "Iteration=2470\t Loss=2.5283298\t mu=9.653011\t sigma=1.1100862\n",
      "Iteration=2471\t Loss=2.5282989\t mu=9.6538925\t sigma=1.1100515\n",
      "Iteration=2472\t Loss=2.5282679\t mu=9.654772\t sigma=1.110017\n",
      "Iteration=2473\t Loss=2.528237\t mu=9.655648\t sigma=1.1099826\n",
      "Iteration=2474\t Loss=2.5282068\t mu=9.656523\t sigma=1.1099484\n",
      "Iteration=2475\t Loss=2.5281763\t mu=9.657394\t sigma=1.1099144\n",
      "Iteration=2476\t Loss=2.5281458\t mu=9.658264\t sigma=1.1098806\n",
      "Iteration=2477\t Loss=2.5281157\t mu=9.659132\t sigma=1.109847\n",
      "Iteration=2478\t Loss=2.528086\t mu=9.659997\t sigma=1.1098135\n",
      "Iteration=2479\t Loss=2.5280561\t mu=9.66086\t sigma=1.1097802\n",
      "Iteration=2480\t Loss=2.5280266\t mu=9.66172\t sigma=1.109747\n",
      "Iteration=2481\t Loss=2.5279968\t mu=9.662579\t sigma=1.1097142\n",
      "Iteration=2482\t Loss=2.5279677\t mu=9.663435\t sigma=1.1096814\n",
      "Iteration=2483\t Loss=2.5279388\t mu=9.6642885\t sigma=1.1096487\n",
      "Iteration=2484\t Loss=2.5279098\t mu=9.66514\t sigma=1.1096163\n",
      "Iteration=2485\t Loss=2.5278807\t mu=9.665989\t sigma=1.109584\n",
      "Iteration=2486\t Loss=2.527852\t mu=9.666836\t sigma=1.1095519\n",
      "Iteration=2487\t Loss=2.527824\t mu=9.667681\t sigma=1.10952\n",
      "Iteration=2488\t Loss=2.5277953\t mu=9.668523\t sigma=1.1094882\n",
      "Iteration=2489\t Loss=2.5277667\t mu=9.669363\t sigma=1.1094567\n",
      "Iteration=2490\t Loss=2.527739\t mu=9.670201\t sigma=1.1094252\n",
      "Iteration=2491\t Loss=2.5277107\t mu=9.671037\t sigma=1.109394\n",
      "Iteration=2492\t Loss=2.5276833\t mu=9.67187\t sigma=1.1093628\n",
      "Iteration=2493\t Loss=2.5276554\t mu=9.672702\t sigma=1.109332\n",
      "Iteration=2494\t Loss=2.5276277\t mu=9.673531\t sigma=1.1093012\n",
      "Iteration=2495\t Loss=2.5276003\t mu=9.674357\t sigma=1.1092706\n",
      "Iteration=2496\t Loss=2.5275733\t mu=9.675182\t sigma=1.1092402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=2497\t Loss=2.5275464\t mu=9.676005\t sigma=1.1092099\n",
      "Iteration=2498\t Loss=2.5275192\t mu=9.676826\t sigma=1.1091797\n",
      "Iteration=2499\t Loss=2.5274923\t mu=9.677644\t sigma=1.1091498\n",
      "Iteration=2500\t Loss=2.527466\t mu=9.67846\t sigma=1.10912\n",
      "Iteration=2501\t Loss=2.5274396\t mu=9.679274\t sigma=1.1090903\n",
      "Iteration=2502\t Loss=2.5274131\t mu=9.680085\t sigma=1.1090609\n",
      "Iteration=2503\t Loss=2.5273871\t mu=9.680895\t sigma=1.1090316\n",
      "Iteration=2504\t Loss=2.5273607\t mu=9.681703\t sigma=1.1090024\n",
      "Iteration=2505\t Loss=2.527335\t mu=9.6825075\t sigma=1.1089734\n",
      "Iteration=2506\t Loss=2.527309\t mu=9.6833105\t sigma=1.1089445\n",
      "Iteration=2507\t Loss=2.5272834\t mu=9.684112\t sigma=1.1089158\n",
      "Iteration=2508\t Loss=2.527258\t mu=9.684911\t sigma=1.1088873\n",
      "Iteration=2509\t Loss=2.5272326\t mu=9.685707\t sigma=1.108859\n",
      "Iteration=2510\t Loss=2.5272074\t mu=9.6865015\t sigma=1.1088307\n",
      "Iteration=2511\t Loss=2.5271823\t mu=9.687294\t sigma=1.1088026\n",
      "Iteration=2512\t Loss=2.5271573\t mu=9.688085\t sigma=1.1087747\n",
      "Iteration=2513\t Loss=2.5271325\t mu=9.688872\t sigma=1.1087469\n",
      "Iteration=2514\t Loss=2.5271077\t mu=9.689658\t sigma=1.1087192\n",
      "Iteration=2515\t Loss=2.5270832\t mu=9.690442\t sigma=1.1086917\n",
      "Iteration=2516\t Loss=2.5270588\t mu=9.691224\t sigma=1.1086643\n",
      "Iteration=2517\t Loss=2.5270343\t mu=9.692004\t sigma=1.1086371\n",
      "Iteration=2518\t Loss=2.5270102\t mu=9.692782\t sigma=1.10861\n",
      "Iteration=2519\t Loss=2.526986\t mu=9.693558\t sigma=1.1085831\n",
      "Iteration=2520\t Loss=2.526962\t mu=9.694331\t sigma=1.1085563\n",
      "Iteration=2521\t Loss=2.5269382\t mu=9.695103\t sigma=1.1085297\n",
      "Iteration=2522\t Loss=2.5269144\t mu=9.695872\t sigma=1.1085032\n",
      "Iteration=2523\t Loss=2.5268912\t mu=9.69664\t sigma=1.1084769\n",
      "Iteration=2524\t Loss=2.5268676\t mu=9.697406\t sigma=1.1084507\n",
      "Iteration=2525\t Loss=2.5268443\t mu=9.698169\t sigma=1.1084245\n",
      "Iteration=2526\t Loss=2.5268211\t mu=9.69893\t sigma=1.1083986\n",
      "Iteration=2527\t Loss=2.526798\t mu=9.699689\t sigma=1.1083728\n",
      "Iteration=2528\t Loss=2.5267751\t mu=9.700446\t sigma=1.1083472\n",
      "Iteration=2529\t Loss=2.5267522\t mu=9.701201\t sigma=1.1083217\n",
      "Iteration=2530\t Loss=2.5267296\t mu=9.701955\t sigma=1.1082963\n",
      "Iteration=2531\t Loss=2.526707\t mu=9.702706\t sigma=1.108271\n",
      "Iteration=2532\t Loss=2.5266848\t mu=9.703456\t sigma=1.1082458\n",
      "Iteration=2533\t Loss=2.5266626\t mu=9.704203\t sigma=1.1082208\n",
      "Iteration=2534\t Loss=2.52664\t mu=9.704947\t sigma=1.1081959\n",
      "Iteration=2535\t Loss=2.526618\t mu=9.70569\t sigma=1.1081712\n",
      "Iteration=2536\t Loss=2.526596\t mu=9.706431\t sigma=1.1081467\n",
      "Iteration=2537\t Loss=2.5265741\t mu=9.7071705\t sigma=1.1081222\n",
      "Iteration=2538\t Loss=2.5265524\t mu=9.707908\t sigma=1.1080979\n",
      "Iteration=2539\t Loss=2.5265307\t mu=9.708643\t sigma=1.1080737\n",
      "Iteration=2540\t Loss=2.526509\t mu=9.709376\t sigma=1.1080496\n",
      "Iteration=2541\t Loss=2.5264878\t mu=9.710108\t sigma=1.1080257\n",
      "Iteration=2542\t Loss=2.5264668\t mu=9.710837\t sigma=1.1080018\n",
      "Iteration=2543\t Loss=2.5264456\t mu=9.711565\t sigma=1.1079781\n",
      "Iteration=2544\t Loss=2.526425\t mu=9.712291\t sigma=1.1079545\n",
      "Iteration=2545\t Loss=2.5264034\t mu=9.713015\t sigma=1.107931\n",
      "Iteration=2546\t Loss=2.526383\t mu=9.713737\t sigma=1.1079077\n",
      "Iteration=2547\t Loss=2.526362\t mu=9.714457\t sigma=1.1078845\n",
      "Iteration=2548\t Loss=2.5263414\t mu=9.715175\t sigma=1.1078615\n",
      "Iteration=2549\t Loss=2.5263205\t mu=9.715891\t sigma=1.1078386\n",
      "Iteration=2550\t Loss=2.5263004\t mu=9.716605\t sigma=1.1078159\n",
      "Iteration=2551\t Loss=2.5262802\t mu=9.717318\t sigma=1.1077932\n",
      "Iteration=2552\t Loss=2.5262601\t mu=9.718028\t sigma=1.1077707\n",
      "Iteration=2553\t Loss=2.52624\t mu=9.718737\t sigma=1.1077483\n",
      "Iteration=2554\t Loss=2.5262198\t mu=9.719443\t sigma=1.107726\n",
      "Iteration=2555\t Loss=2.5262003\t mu=9.720148\t sigma=1.1077037\n",
      "Iteration=2556\t Loss=2.5261805\t mu=9.720851\t sigma=1.1076816\n",
      "Iteration=2557\t Loss=2.526161\t mu=9.721552\t sigma=1.1076597\n",
      "Iteration=2558\t Loss=2.5261414\t mu=9.722251\t sigma=1.1076379\n",
      "Iteration=2559\t Loss=2.5261214\t mu=9.722948\t sigma=1.1076161\n",
      "Iteration=2560\t Loss=2.5261023\t mu=9.723643\t sigma=1.1075944\n",
      "Iteration=2561\t Loss=2.5260837\t mu=9.724337\t sigma=1.1075728\n",
      "Iteration=2562\t Loss=2.5260644\t mu=9.725028\t sigma=1.1075513\n",
      "Iteration=2563\t Loss=2.5260453\t mu=9.725718\t sigma=1.10753\n",
      "Iteration=2564\t Loss=2.5260262\t mu=9.726405\t sigma=1.1075088\n",
      "Iteration=2565\t Loss=2.526008\t mu=9.727091\t sigma=1.1074877\n",
      "Iteration=2566\t Loss=2.5259888\t mu=9.727775\t sigma=1.1074667\n",
      "Iteration=2567\t Loss=2.5259702\t mu=9.7284565\t sigma=1.1074458\n",
      "Iteration=2568\t Loss=2.5259516\t mu=9.729136\t sigma=1.1074251\n",
      "Iteration=2569\t Loss=2.5259335\t mu=9.729815\t sigma=1.1074045\n",
      "Iteration=2570\t Loss=2.5259154\t mu=9.730491\t sigma=1.107384\n",
      "Iteration=2571\t Loss=2.5258968\t mu=9.731165\t sigma=1.1073636\n",
      "Iteration=2572\t Loss=2.5258787\t mu=9.731838\t sigma=1.1073433\n",
      "Iteration=2573\t Loss=2.5258608\t mu=9.73251\t sigma=1.1073232\n",
      "Iteration=2574\t Loss=2.525843\t mu=9.733179\t sigma=1.1073031\n",
      "Iteration=2575\t Loss=2.525825\t mu=9.733847\t sigma=1.1072832\n",
      "Iteration=2576\t Loss=2.5258071\t mu=9.734512\t sigma=1.1072634\n",
      "Iteration=2577\t Loss=2.5257895\t mu=9.735176\t sigma=1.1072437\n",
      "Iteration=2578\t Loss=2.5257723\t mu=9.735838\t sigma=1.107224\n",
      "Iteration=2579\t Loss=2.5257545\t mu=9.736498\t sigma=1.1072044\n",
      "Iteration=2580\t Loss=2.5257373\t mu=9.737156\t sigma=1.107185\n",
      "Iteration=2581\t Loss=2.5257204\t mu=9.737813\t sigma=1.1071657\n",
      "Iteration=2582\t Loss=2.5257032\t mu=9.738468\t sigma=1.1071465\n",
      "Iteration=2583\t Loss=2.525686\t mu=9.739121\t sigma=1.1071274\n",
      "Iteration=2584\t Loss=2.5256689\t mu=9.739773\t sigma=1.1071085\n",
      "Iteration=2585\t Loss=2.5256524\t mu=9.740422\t sigma=1.1070895\n",
      "Iteration=2586\t Loss=2.5256352\t mu=9.74107\t sigma=1.1070707\n",
      "Iteration=2587\t Loss=2.5256183\t mu=9.741716\t sigma=1.107052\n",
      "Iteration=2588\t Loss=2.525602\t mu=9.742361\t sigma=1.1070334\n",
      "Iteration=2589\t Loss=2.5255854\t mu=9.743004\t sigma=1.1070149\n",
      "Iteration=2590\t Loss=2.5255694\t mu=9.743645\t sigma=1.1069965\n",
      "Iteration=2591\t Loss=2.5255527\t mu=9.744284\t sigma=1.1069782\n",
      "Iteration=2592\t Loss=2.5255363\t mu=9.744921\t sigma=1.1069599\n",
      "Iteration=2593\t Loss=2.52552\t mu=9.745557\t sigma=1.1069418\n",
      "Iteration=2594\t Loss=2.5255046\t mu=9.746191\t sigma=1.1069238\n",
      "Iteration=2595\t Loss=2.5254884\t mu=9.746823\t sigma=1.1069059\n",
      "Iteration=2596\t Loss=2.5254722\t mu=9.747454\t sigma=1.1068882\n",
      "Iteration=2597\t Loss=2.5254567\t mu=9.748083\t sigma=1.1068704\n",
      "Iteration=2598\t Loss=2.525441\t mu=9.748711\t sigma=1.1068528\n",
      "Iteration=2599\t Loss=2.5254252\t mu=9.749336\t sigma=1.1068352\n",
      "Iteration=2600\t Loss=2.5254097\t mu=9.74996\t sigma=1.1068178\n",
      "Iteration=2601\t Loss=2.5253937\t mu=9.750582\t sigma=1.1068006\n",
      "Iteration=2602\t Loss=2.5253785\t mu=9.751203\t sigma=1.1067833\n",
      "Iteration=2603\t Loss=2.5253634\t mu=9.7518215\t sigma=1.1067661\n",
      "Iteration=2604\t Loss=2.5253482\t mu=9.752439\t sigma=1.106749\n",
      "Iteration=2605\t Loss=2.5253332\t mu=9.753054\t sigma=1.1067321\n",
      "Iteration=2606\t Loss=2.525318\t mu=9.753668\t sigma=1.1067152\n",
      "Iteration=2607\t Loss=2.5253026\t mu=9.75428\t sigma=1.1066984\n",
      "Iteration=2608\t Loss=2.5252879\t mu=9.75489\t sigma=1.1066817\n",
      "Iteration=2609\t Loss=2.525273\t mu=9.755499\t sigma=1.1066651\n",
      "Iteration=2610\t Loss=2.5252588\t mu=9.756106\t sigma=1.1066486\n",
      "Iteration=2611\t Loss=2.5252438\t mu=9.756712\t sigma=1.1066321\n",
      "Iteration=2612\t Loss=2.5252292\t mu=9.757316\t sigma=1.1066158\n",
      "Iteration=2613\t Loss=2.5252151\t mu=9.757918\t sigma=1.1065996\n",
      "Iteration=2614\t Loss=2.5252006\t mu=9.758519\t sigma=1.1065834\n",
      "Iteration=2615\t Loss=2.5251858\t mu=9.759118\t sigma=1.1065673\n",
      "Iteration=2616\t Loss=2.5251718\t mu=9.759716\t sigma=1.1065513\n",
      "Iteration=2617\t Loss=2.5251575\t mu=9.760312\t sigma=1.1065354\n",
      "Iteration=2618\t Loss=2.5251434\t mu=9.760906\t sigma=1.1065196\n",
      "Iteration=2619\t Loss=2.525129\t mu=9.761498\t sigma=1.1065038\n",
      "Iteration=2620\t Loss=2.5251153\t mu=9.76209\t sigma=1.1064882\n",
      "Iteration=2621\t Loss=2.5251014\t mu=9.762679\t sigma=1.1064726\n",
      "Iteration=2622\t Loss=2.5250876\t mu=9.763267\t sigma=1.1064571\n",
      "Iteration=2623\t Loss=2.525074\t mu=9.763853\t sigma=1.1064417\n",
      "Iteration=2624\t Loss=2.5250604\t mu=9.764438\t sigma=1.1064265\n",
      "Iteration=2625\t Loss=2.5250466\t mu=9.76502\t sigma=1.1064112\n",
      "Iteration=2626\t Loss=2.5250332\t mu=9.765602\t sigma=1.1063961\n",
      "Iteration=2627\t Loss=2.5250196\t mu=9.766182\t sigma=1.106381\n",
      "Iteration=2628\t Loss=2.5250065\t mu=9.76676\t sigma=1.106366\n",
      "Iteration=2629\t Loss=2.524993\t mu=9.767337\t sigma=1.1063511\n",
      "Iteration=2630\t Loss=2.52498\t mu=9.767912\t sigma=1.1063364\n",
      "Iteration=2631\t Loss=2.5249667\t mu=9.768486\t sigma=1.1063216\n",
      "Iteration=2632\t Loss=2.5249536\t mu=9.769058\t sigma=1.1063069\n",
      "Iteration=2633\t Loss=2.5249407\t mu=9.769629\t sigma=1.1062924\n",
      "Iteration=2634\t Loss=2.5249276\t mu=9.770198\t sigma=1.1062778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=2635\t Loss=2.524915\t mu=9.770765\t sigma=1.1062634\n",
      "Iteration=2636\t Loss=2.524902\t mu=9.771331\t sigma=1.1062491\n",
      "Iteration=2637\t Loss=2.524889\t mu=9.771895\t sigma=1.1062348\n",
      "Iteration=2638\t Loss=2.5248766\t mu=9.772458\t sigma=1.1062206\n",
      "Iteration=2639\t Loss=2.524864\t mu=9.77302\t sigma=1.1062064\n",
      "Iteration=2640\t Loss=2.5248518\t mu=9.77358\t sigma=1.1061924\n",
      "Iteration=2641\t Loss=2.5248392\t mu=9.774138\t sigma=1.1061784\n",
      "Iteration=2642\t Loss=2.5248265\t mu=9.774695\t sigma=1.1061645\n",
      "Iteration=2643\t Loss=2.5248144\t mu=9.77525\t sigma=1.1061506\n",
      "Iteration=2644\t Loss=2.5248022\t mu=9.7758045\t sigma=1.1061369\n",
      "Iteration=2645\t Loss=2.52479\t mu=9.776357\t sigma=1.1061232\n",
      "Iteration=2646\t Loss=2.5247777\t mu=9.776908\t sigma=1.1061096\n",
      "Iteration=2647\t Loss=2.5247657\t mu=9.777457\t sigma=1.106096\n",
      "Iteration=2648\t Loss=2.5247533\t mu=9.778005\t sigma=1.1060826\n",
      "Iteration=2649\t Loss=2.5247416\t mu=9.778551\t sigma=1.1060692\n",
      "Iteration=2650\t Loss=2.52473\t mu=9.779096\t sigma=1.1060559\n",
      "Iteration=2651\t Loss=2.524718\t mu=9.779639\t sigma=1.1060426\n",
      "Iteration=2652\t Loss=2.5247064\t mu=9.780181\t sigma=1.1060295\n",
      "Iteration=2653\t Loss=2.5246947\t mu=9.780722\t sigma=1.1060164\n",
      "Iteration=2654\t Loss=2.524683\t mu=9.7812605\t sigma=1.1060034\n",
      "Iteration=2655\t Loss=2.5246718\t mu=9.781798\t sigma=1.1059904\n",
      "Iteration=2656\t Loss=2.5246599\t mu=9.782334\t sigma=1.1059775\n",
      "Iteration=2657\t Loss=2.5246487\t mu=9.782869\t sigma=1.1059648\n",
      "Iteration=2658\t Loss=2.5246372\t mu=9.783402\t sigma=1.105952\n",
      "Iteration=2659\t Loss=2.5246263\t mu=9.783935\t sigma=1.1059394\n",
      "Iteration=2660\t Loss=2.5246143\t mu=9.784465\t sigma=1.1059268\n",
      "Iteration=2661\t Loss=2.5246036\t mu=9.784994\t sigma=1.1059142\n",
      "Iteration=2662\t Loss=2.524592\t mu=9.7855215\t sigma=1.1059017\n",
      "Iteration=2663\t Loss=2.5245812\t mu=9.786048\t sigma=1.1058893\n",
      "Iteration=2664\t Loss=2.5245702\t mu=9.786572\t sigma=1.105877\n",
      "Iteration=2665\t Loss=2.5245593\t mu=9.787096\t sigma=1.1058648\n",
      "Iteration=2666\t Loss=2.5245485\t mu=9.787618\t sigma=1.1058526\n",
      "Iteration=2667\t Loss=2.5245378\t mu=9.788138\t sigma=1.1058404\n",
      "Iteration=2668\t Loss=2.5245268\t mu=9.788657\t sigma=1.1058284\n",
      "Iteration=2669\t Loss=2.5245163\t mu=9.789175\t sigma=1.1058164\n",
      "Iteration=2670\t Loss=2.5245056\t mu=9.789691\t sigma=1.1058044\n",
      "Iteration=2671\t Loss=2.5244946\t mu=9.790206\t sigma=1.1057925\n",
      "Iteration=2672\t Loss=2.5244844\t mu=9.790719\t sigma=1.1057807\n",
      "Iteration=2673\t Loss=2.524474\t mu=9.791231\t sigma=1.1057689\n",
      "Iteration=2674\t Loss=2.5244632\t mu=9.791741\t sigma=1.1057572\n",
      "Iteration=2675\t Loss=2.524453\t mu=9.792251\t sigma=1.1057457\n",
      "Iteration=2676\t Loss=2.5244427\t mu=9.792758\t sigma=1.1057341\n",
      "Iteration=2677\t Loss=2.5244327\t mu=9.793264\t sigma=1.1057227\n",
      "Iteration=2678\t Loss=2.5244222\t mu=9.79377\t sigma=1.1057112\n",
      "Iteration=2679\t Loss=2.5244124\t mu=9.794273\t sigma=1.1056999\n",
      "Iteration=2680\t Loss=2.5244021\t mu=9.794776\t sigma=1.1056886\n",
      "Iteration=2681\t Loss=2.524392\t mu=9.795277\t sigma=1.1056774\n",
      "Iteration=2682\t Loss=2.5243824\t mu=9.795776\t sigma=1.1056662\n",
      "Iteration=2683\t Loss=2.5243723\t mu=9.796274\t sigma=1.1056551\n",
      "Iteration=2684\t Loss=2.5243626\t mu=9.796771\t sigma=1.105644\n",
      "Iteration=2685\t Loss=2.5243526\t mu=9.797267\t sigma=1.105633\n",
      "Iteration=2686\t Loss=2.5243425\t mu=9.797761\t sigma=1.105622\n",
      "Iteration=2687\t Loss=2.524333\t mu=9.798254\t sigma=1.1056112\n",
      "Iteration=2688\t Loss=2.5243237\t mu=9.798745\t sigma=1.1056004\n",
      "Iteration=2689\t Loss=2.524314\t mu=9.799235\t sigma=1.1055896\n",
      "Iteration=2690\t Loss=2.5243044\t mu=9.799725\t sigma=1.1055789\n",
      "Iteration=2691\t Loss=2.5242949\t mu=9.800212\t sigma=1.1055683\n",
      "Iteration=2692\t Loss=2.5242856\t mu=9.800698\t sigma=1.1055577\n",
      "Iteration=2693\t Loss=2.5242758\t mu=9.801183\t sigma=1.1055472\n",
      "Iteration=2694\t Loss=2.5242665\t mu=9.801666\t sigma=1.1055367\n",
      "Iteration=2695\t Loss=2.5242572\t mu=9.802149\t sigma=1.1055262\n",
      "Iteration=2696\t Loss=2.5242481\t mu=9.802629\t sigma=1.1055158\n",
      "Iteration=2697\t Loss=2.524239\t mu=9.803109\t sigma=1.1055055\n",
      "Iteration=2698\t Loss=2.5242298\t mu=9.803587\t sigma=1.1054952\n",
      "Iteration=2699\t Loss=2.5242207\t mu=9.804064\t sigma=1.105485\n",
      "Iteration=2700\t Loss=2.5242114\t mu=9.80454\t sigma=1.1054748\n",
      "Iteration=2701\t Loss=2.5242028\t mu=9.805014\t sigma=1.1054647\n",
      "Iteration=2702\t Loss=2.5241938\t mu=9.805487\t sigma=1.1054547\n",
      "Iteration=2703\t Loss=2.5241847\t mu=9.805959\t sigma=1.1054447\n",
      "Iteration=2704\t Loss=2.5241761\t mu=9.806429\t sigma=1.1054348\n",
      "Iteration=2705\t Loss=2.5241673\t mu=9.806898\t sigma=1.1054249\n",
      "Iteration=2706\t Loss=2.5241585\t mu=9.807366\t sigma=1.1054151\n",
      "Iteration=2707\t Loss=2.52415\t mu=9.807833\t sigma=1.1054053\n",
      "Iteration=2708\t Loss=2.5241408\t mu=9.808298\t sigma=1.1053957\n",
      "Iteration=2709\t Loss=2.5241325\t mu=9.808763\t sigma=1.105386\n",
      "Iteration=2710\t Loss=2.524124\t mu=9.809225\t sigma=1.1053764\n",
      "Iteration=2711\t Loss=2.5241153\t mu=9.809687\t sigma=1.1053668\n",
      "Iteration=2712\t Loss=2.5241067\t mu=9.810147\t sigma=1.1053573\n",
      "Iteration=2713\t Loss=2.5240986\t mu=9.810606\t sigma=1.1053479\n",
      "Iteration=2714\t Loss=2.52409\t mu=9.811064\t sigma=1.1053385\n",
      "Iteration=2715\t Loss=2.5240817\t mu=9.811521\t sigma=1.1053292\n",
      "Iteration=2716\t Loss=2.5240734\t mu=9.8119755\t sigma=1.1053199\n",
      "Iteration=2717\t Loss=2.5240655\t mu=9.812429\t sigma=1.1053106\n",
      "Iteration=2718\t Loss=2.5240571\t mu=9.812882\t sigma=1.1053014\n",
      "Iteration=2719\t Loss=2.5240488\t mu=9.813334\t sigma=1.1052922\n",
      "Iteration=2720\t Loss=2.5240407\t mu=9.813785\t sigma=1.1052831\n",
      "Iteration=2721\t Loss=2.5240328\t mu=9.814234\t sigma=1.1052741\n",
      "Iteration=2722\t Loss=2.5240247\t mu=9.814682\t sigma=1.1052651\n",
      "Iteration=2723\t Loss=2.5240169\t mu=9.815128\t sigma=1.1052562\n",
      "Iteration=2724\t Loss=2.5240088\t mu=9.815574\t sigma=1.1052473\n",
      "Iteration=2725\t Loss=2.524001\t mu=9.816018\t sigma=1.1052384\n",
      "Iteration=2726\t Loss=2.523993\t mu=9.816462\t sigma=1.1052296\n",
      "Iteration=2727\t Loss=2.5239851\t mu=9.816903\t sigma=1.1052209\n",
      "Iteration=2728\t Loss=2.5239778\t mu=9.817344\t sigma=1.1052122\n",
      "Iteration=2729\t Loss=2.5239697\t mu=9.817783\t sigma=1.1052035\n",
      "Iteration=2730\t Loss=2.523962\t mu=9.818222\t sigma=1.1051949\n",
      "Iteration=2731\t Loss=2.5239544\t mu=9.818659\t sigma=1.1051863\n",
      "Iteration=2732\t Loss=2.5239468\t mu=9.819095\t sigma=1.1051779\n",
      "Iteration=2733\t Loss=2.5239394\t mu=9.81953\t sigma=1.1051694\n",
      "Iteration=2734\t Loss=2.5239317\t mu=9.819963\t sigma=1.105161\n",
      "Iteration=2735\t Loss=2.5239246\t mu=9.820395\t sigma=1.1051526\n",
      "Iteration=2736\t Loss=2.5239167\t mu=9.820827\t sigma=1.1051443\n",
      "Iteration=2737\t Loss=2.5239093\t mu=9.821257\t sigma=1.1051359\n",
      "Iteration=2738\t Loss=2.5239022\t mu=9.821686\t sigma=1.1051277\n",
      "Iteration=2739\t Loss=2.523895\t mu=9.822113\t sigma=1.1051195\n",
      "Iteration=2740\t Loss=2.5238879\t mu=9.822539\t sigma=1.1051114\n",
      "Iteration=2741\t Loss=2.5238805\t mu=9.822965\t sigma=1.1051033\n",
      "Iteration=2742\t Loss=2.523873\t mu=9.823389\t sigma=1.1050951\n",
      "Iteration=2743\t Loss=2.523866\t mu=9.8238125\t sigma=1.1050872\n",
      "Iteration=2744\t Loss=2.5238593\t mu=9.824234\t sigma=1.1050792\n",
      "Iteration=2745\t Loss=2.5238519\t mu=9.824655\t sigma=1.1050712\n",
      "Iteration=2746\t Loss=2.5238447\t mu=9.825074\t sigma=1.1050633\n",
      "Iteration=2747\t Loss=2.5238378\t mu=9.825493\t sigma=1.1050555\n",
      "Iteration=2748\t Loss=2.523831\t mu=9.825911\t sigma=1.1050476\n",
      "Iteration=2749\t Loss=2.523824\t mu=9.826326\t sigma=1.1050398\n",
      "Iteration=2750\t Loss=2.5238173\t mu=9.826741\t sigma=1.1050321\n",
      "Iteration=2751\t Loss=2.5238106\t mu=9.827155\t sigma=1.1050245\n",
      "Iteration=2752\t Loss=2.5238035\t mu=9.827568\t sigma=1.1050168\n",
      "Iteration=2753\t Loss=2.5237968\t mu=9.82798\t sigma=1.1050092\n",
      "Iteration=2754\t Loss=2.5237894\t mu=9.82839\t sigma=1.1050017\n",
      "Iteration=2755\t Loss=2.5237832\t mu=9.828799\t sigma=1.1049942\n",
      "Iteration=2756\t Loss=2.5237768\t mu=9.829207\t sigma=1.1049867\n",
      "Iteration=2757\t Loss=2.5237703\t mu=9.829615\t sigma=1.1049793\n",
      "Iteration=2758\t Loss=2.5237632\t mu=9.830021\t sigma=1.1049719\n",
      "Iteration=2759\t Loss=2.523757\t mu=9.830426\t sigma=1.1049645\n",
      "Iteration=2760\t Loss=2.5237503\t mu=9.83083\t sigma=1.1049572\n",
      "Iteration=2761\t Loss=2.5237439\t mu=9.831232\t sigma=1.10495\n",
      "Iteration=2762\t Loss=2.5237372\t mu=9.831634\t sigma=1.1049427\n",
      "Iteration=2763\t Loss=2.5237308\t mu=9.832034\t sigma=1.1049355\n",
      "Iteration=2764\t Loss=2.5237248\t mu=9.832434\t sigma=1.1049284\n",
      "Iteration=2765\t Loss=2.523718\t mu=9.832832\t sigma=1.1049212\n",
      "Iteration=2766\t Loss=2.523712\t mu=9.83323\t sigma=1.1049142\n",
      "Iteration=2767\t Loss=2.5237057\t mu=9.833626\t sigma=1.1049072\n",
      "Iteration=2768\t Loss=2.5236993\t mu=9.834021\t sigma=1.1049001\n",
      "Iteration=2769\t Loss=2.5236933\t mu=9.8344145\t sigma=1.1048932\n",
      "Iteration=2770\t Loss=2.523687\t mu=9.834807\t sigma=1.1048863\n",
      "Iteration=2771\t Loss=2.5236812\t mu=9.835199\t sigma=1.1048794\n",
      "Iteration=2772\t Loss=2.5236747\t mu=9.83559\t sigma=1.1048725\n",
      "Iteration=2773\t Loss=2.5236685\t mu=9.83598\t sigma=1.1048657\n",
      "Iteration=2774\t Loss=2.5236628\t mu=9.8363695\t sigma=1.1048589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=2775\t Loss=2.5236566\t mu=9.836757\t sigma=1.1048521\n",
      "Iteration=2776\t Loss=2.5236506\t mu=9.837143\t sigma=1.1048454\n",
      "Iteration=2777\t Loss=2.5236444\t mu=9.837528\t sigma=1.1048387\n",
      "Iteration=2778\t Loss=2.523639\t mu=9.837913\t sigma=1.104832\n",
      "Iteration=2779\t Loss=2.523633\t mu=9.838296\t sigma=1.1048255\n",
      "Iteration=2780\t Loss=2.523627\t mu=9.838678\t sigma=1.1048189\n",
      "Iteration=2781\t Loss=2.5236213\t mu=9.83906\t sigma=1.1048124\n",
      "Iteration=2782\t Loss=2.5236154\t mu=9.83944\t sigma=1.104806\n",
      "Iteration=2783\t Loss=2.5236099\t mu=9.83982\t sigma=1.1047995\n",
      "Iteration=2784\t Loss=2.5236044\t mu=9.8401985\t sigma=1.1047931\n",
      "Iteration=2785\t Loss=2.5235984\t mu=9.840575\t sigma=1.1047866\n",
      "Iteration=2786\t Loss=2.5235927\t mu=9.840951\t sigma=1.1047803\n",
      "Iteration=2787\t Loss=2.5235872\t mu=9.841326\t sigma=1.104774\n",
      "Iteration=2788\t Loss=2.5235813\t mu=9.8417\t sigma=1.1047677\n",
      "Iteration=2789\t Loss=2.523576\t mu=9.8420725\t sigma=1.1047615\n",
      "Iteration=2790\t Loss=2.5235705\t mu=9.842444\t sigma=1.1047553\n",
      "Iteration=2791\t Loss=2.523565\t mu=9.842815\t sigma=1.1047491\n",
      "Iteration=2792\t Loss=2.5235593\t mu=9.843185\t sigma=1.104743\n",
      "Iteration=2793\t Loss=2.5235538\t mu=9.8435545\t sigma=1.1047369\n",
      "Iteration=2794\t Loss=2.5235486\t mu=9.843923\t sigma=1.1047308\n",
      "Iteration=2795\t Loss=2.5235431\t mu=9.84429\t sigma=1.1047248\n",
      "Iteration=2796\t Loss=2.523538\t mu=9.844656\t sigma=1.1047188\n",
      "Iteration=2797\t Loss=2.5235324\t mu=9.845021\t sigma=1.1047128\n",
      "Iteration=2798\t Loss=2.5235274\t mu=9.845386\t sigma=1.1047069\n",
      "Iteration=2799\t Loss=2.523522\t mu=9.845749\t sigma=1.1047009\n",
      "Iteration=2800\t Loss=2.5235167\t mu=9.846111\t sigma=1.1046951\n",
      "Iteration=2801\t Loss=2.5235114\t mu=9.846473\t sigma=1.1046892\n",
      "Iteration=2802\t Loss=2.5235062\t mu=9.846833\t sigma=1.1046834\n",
      "Iteration=2803\t Loss=2.5235014\t mu=9.847192\t sigma=1.1046777\n",
      "Iteration=2804\t Loss=2.5234962\t mu=9.847549\t sigma=1.104672\n",
      "Iteration=2805\t Loss=2.523491\t mu=9.847906\t sigma=1.1046662\n",
      "Iteration=2806\t Loss=2.5234861\t mu=9.848262\t sigma=1.1046605\n",
      "Iteration=2807\t Loss=2.523481\t mu=9.848617\t sigma=1.1046549\n",
      "Iteration=2808\t Loss=2.523476\t mu=9.84897\t sigma=1.1046493\n",
      "Iteration=2809\t Loss=2.5234709\t mu=9.849323\t sigma=1.1046437\n",
      "Iteration=2810\t Loss=2.5234656\t mu=9.849675\t sigma=1.1046381\n",
      "Iteration=2811\t Loss=2.523461\t mu=9.850026\t sigma=1.1046326\n",
      "Iteration=2812\t Loss=2.523456\t mu=9.850376\t sigma=1.1046271\n",
      "Iteration=2813\t Loss=2.5234513\t mu=9.850725\t sigma=1.1046216\n",
      "Iteration=2814\t Loss=2.5234466\t mu=9.851073\t sigma=1.1046162\n",
      "Iteration=2815\t Loss=2.5234413\t mu=9.85142\t sigma=1.1046108\n",
      "Iteration=2816\t Loss=2.523437\t mu=9.851767\t sigma=1.1046054\n",
      "Iteration=2817\t Loss=2.5234323\t mu=9.852112\t sigma=1.1046001\n",
      "Iteration=2818\t Loss=2.5234272\t mu=9.852456\t sigma=1.1045947\n",
      "Iteration=2819\t Loss=2.5234225\t mu=9.852799\t sigma=1.1045895\n",
      "Iteration=2820\t Loss=2.5234182\t mu=9.853142\t sigma=1.1045842\n",
      "Iteration=2821\t Loss=2.5234132\t mu=9.853483\t sigma=1.104579\n",
      "Iteration=2822\t Loss=2.5234084\t mu=9.853824\t sigma=1.1045737\n",
      "Iteration=2823\t Loss=2.5234044\t mu=9.854163\t sigma=1.1045686\n",
      "Iteration=2824\t Loss=2.5233994\t mu=9.854502\t sigma=1.1045635\n",
      "Iteration=2825\t Loss=2.5233948\t mu=9.854839\t sigma=1.1045583\n",
      "Iteration=2826\t Loss=2.5233903\t mu=9.855177\t sigma=1.1045532\n",
      "Iteration=2827\t Loss=2.5233858\t mu=9.855514\t sigma=1.1045481\n",
      "Iteration=2828\t Loss=2.523381\t mu=9.855849\t sigma=1.1045431\n",
      "Iteration=2829\t Loss=2.523377\t mu=9.856184\t sigma=1.1045381\n",
      "Iteration=2830\t Loss=2.5233722\t mu=9.856518\t sigma=1.1045331\n",
      "Iteration=2831\t Loss=2.523368\t mu=9.856851\t sigma=1.1045281\n",
      "Iteration=2832\t Loss=2.5233636\t mu=9.8571825\t sigma=1.1045232\n",
      "Iteration=2833\t Loss=2.5233593\t mu=9.857513\t sigma=1.1045183\n",
      "Iteration=2834\t Loss=2.5233548\t mu=9.857843\t sigma=1.1045134\n",
      "Iteration=2835\t Loss=2.5233505\t mu=9.858172\t sigma=1.1045085\n",
      "Iteration=2836\t Loss=2.5233462\t mu=9.8585005\t sigma=1.1045036\n",
      "Iteration=2837\t Loss=2.523342\t mu=9.858828\t sigma=1.1044989\n",
      "Iteration=2838\t Loss=2.5233376\t mu=9.859154\t sigma=1.1044941\n",
      "Iteration=2839\t Loss=2.5233335\t mu=9.859479\t sigma=1.1044893\n",
      "Iteration=2840\t Loss=2.5233293\t mu=9.859803\t sigma=1.1044846\n",
      "Iteration=2841\t Loss=2.523325\t mu=9.8601265\t sigma=1.1044799\n",
      "Iteration=2842\t Loss=2.5233212\t mu=9.860449\t sigma=1.1044753\n",
      "Iteration=2843\t Loss=2.5233164\t mu=9.86077\t sigma=1.1044706\n",
      "Iteration=2844\t Loss=2.5233128\t mu=9.861092\t sigma=1.104466\n",
      "Iteration=2845\t Loss=2.5233085\t mu=9.861412\t sigma=1.1044613\n",
      "Iteration=2846\t Loss=2.5233042\t mu=9.861732\t sigma=1.1044568\n",
      "Iteration=2847\t Loss=2.5233006\t mu=9.86205\t sigma=1.1044523\n",
      "Iteration=2848\t Loss=2.5232966\t mu=9.862368\t sigma=1.1044477\n",
      "Iteration=2849\t Loss=2.5232923\t mu=9.862684\t sigma=1.1044432\n",
      "Iteration=2850\t Loss=2.5232885\t mu=9.863\t sigma=1.1044387\n",
      "Iteration=2851\t Loss=2.5232847\t mu=9.863315\t sigma=1.1044343\n",
      "Iteration=2852\t Loss=2.5232804\t mu=9.863628\t sigma=1.1044298\n",
      "Iteration=2853\t Loss=2.5232766\t mu=9.863941\t sigma=1.1044254\n",
      "Iteration=2854\t Loss=2.5232728\t mu=9.864253\t sigma=1.104421\n",
      "Iteration=2855\t Loss=2.5232685\t mu=9.864565\t sigma=1.1044167\n",
      "Iteration=2856\t Loss=2.523265\t mu=9.864876\t sigma=1.1044124\n",
      "Iteration=2857\t Loss=2.5232613\t mu=9.865186\t sigma=1.1044081\n",
      "Iteration=2858\t Loss=2.5232575\t mu=9.865495\t sigma=1.1044039\n",
      "Iteration=2859\t Loss=2.5232534\t mu=9.865803\t sigma=1.1043996\n",
      "Iteration=2860\t Loss=2.5232496\t mu=9.86611\t sigma=1.1043953\n",
      "Iteration=2861\t Loss=2.523246\t mu=9.866416\t sigma=1.1043911\n",
      "Iteration=2862\t Loss=2.5232422\t mu=9.866721\t sigma=1.1043869\n",
      "Iteration=2863\t Loss=2.5232387\t mu=9.867025\t sigma=1.1043828\n",
      "Iteration=2864\t Loss=2.5232348\t mu=9.86733\t sigma=1.1043786\n",
      "Iteration=2865\t Loss=2.5232313\t mu=9.867633\t sigma=1.1043744\n",
      "Iteration=2866\t Loss=2.5232275\t mu=9.867935\t sigma=1.1043704\n",
      "Iteration=2867\t Loss=2.5232239\t mu=9.868237\t sigma=1.1043663\n",
      "Iteration=2868\t Loss=2.5232205\t mu=9.868537\t sigma=1.1043622\n",
      "Iteration=2869\t Loss=2.5232165\t mu=9.868836\t sigma=1.1043582\n",
      "Iteration=2870\t Loss=2.523213\t mu=9.869135\t sigma=1.1043541\n",
      "Iteration=2871\t Loss=2.5232096\t mu=9.869433\t sigma=1.1043502\n",
      "Iteration=2872\t Loss=2.523206\t mu=9.869731\t sigma=1.1043463\n",
      "Iteration=2873\t Loss=2.5232027\t mu=9.870028\t sigma=1.1043423\n",
      "Iteration=2874\t Loss=2.5231993\t mu=9.870323\t sigma=1.1043384\n",
      "Iteration=2875\t Loss=2.523196\t mu=9.870618\t sigma=1.1043345\n",
      "Iteration=2876\t Loss=2.5231924\t mu=9.870912\t sigma=1.1043307\n",
      "Iteration=2877\t Loss=2.5231888\t mu=9.871204\t sigma=1.1043268\n",
      "Iteration=2878\t Loss=2.5231853\t mu=9.871497\t sigma=1.104323\n",
      "Iteration=2879\t Loss=2.523182\t mu=9.871789\t sigma=1.1043192\n",
      "Iteration=2880\t Loss=2.5231783\t mu=9.87208\t sigma=1.1043154\n",
      "Iteration=2881\t Loss=2.523175\t mu=9.87237\t sigma=1.1043116\n",
      "Iteration=2882\t Loss=2.523172\t mu=9.872659\t sigma=1.1043079\n",
      "Iteration=2883\t Loss=2.5231686\t mu=9.872947\t sigma=1.1043042\n",
      "Iteration=2884\t Loss=2.5231655\t mu=9.873235\t sigma=1.1043005\n",
      "Iteration=2885\t Loss=2.523162\t mu=9.873522\t sigma=1.1042968\n",
      "Iteration=2886\t Loss=2.5231586\t mu=9.873808\t sigma=1.1042931\n",
      "Iteration=2887\t Loss=2.5231552\t mu=9.874093\t sigma=1.1042894\n",
      "Iteration=2888\t Loss=2.523152\t mu=9.874377\t sigma=1.1042858\n",
      "Iteration=2889\t Loss=2.5231488\t mu=9.8746605\t sigma=1.1042823\n",
      "Iteration=2890\t Loss=2.5231457\t mu=9.874944\t sigma=1.1042787\n",
      "Iteration=2891\t Loss=2.5231426\t mu=9.875226\t sigma=1.1042751\n",
      "Iteration=2892\t Loss=2.5231392\t mu=9.875507\t sigma=1.1042715\n",
      "Iteration=2893\t Loss=2.523136\t mu=9.875788\t sigma=1.104268\n",
      "Iteration=2894\t Loss=2.5231328\t mu=9.876067\t sigma=1.1042645\n",
      "Iteration=2895\t Loss=2.5231302\t mu=9.876347\t sigma=1.104261\n",
      "Iteration=2896\t Loss=2.5231268\t mu=9.876625\t sigma=1.1042576\n",
      "Iteration=2897\t Loss=2.5231237\t mu=9.876903\t sigma=1.1042541\n",
      "Iteration=2898\t Loss=2.523121\t mu=9.877179\t sigma=1.1042507\n",
      "Iteration=2899\t Loss=2.5231178\t mu=9.877455\t sigma=1.1042472\n",
      "Iteration=2900\t Loss=2.5231152\t mu=9.87773\t sigma=1.1042438\n",
      "Iteration=2901\t Loss=2.5231118\t mu=9.878005\t sigma=1.1042404\n",
      "Iteration=2902\t Loss=2.523109\t mu=9.878279\t sigma=1.1042371\n",
      "Iteration=2903\t Loss=2.5231059\t mu=9.8785515\t sigma=1.1042337\n",
      "Iteration=2904\t Loss=2.523103\t mu=9.878823\t sigma=1.1042304\n",
      "Iteration=2905\t Loss=2.5231\t mu=9.879095\t sigma=1.1042271\n",
      "Iteration=2906\t Loss=2.5230966\t mu=9.879366\t sigma=1.1042237\n",
      "Iteration=2907\t Loss=2.5230942\t mu=9.879636\t sigma=1.1042205\n",
      "Iteration=2908\t Loss=2.5230913\t mu=9.879905\t sigma=1.1042173\n",
      "Iteration=2909\t Loss=2.5230882\t mu=9.880174\t sigma=1.1042141\n",
      "Iteration=2910\t Loss=2.5230856\t mu=9.880442\t sigma=1.1042109\n",
      "Iteration=2911\t Loss=2.5230825\t mu=9.880709\t sigma=1.1042076\n",
      "Iteration=2912\t Loss=2.5230799\t mu=9.880975\t sigma=1.1042044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=2913\t Loss=2.523077\t mu=9.881241\t sigma=1.1042012\n",
      "Iteration=2914\t Loss=2.5230742\t mu=9.881506\t sigma=1.1041981\n",
      "Iteration=2915\t Loss=2.5230713\t mu=9.88177\t sigma=1.104195\n",
      "Iteration=2916\t Loss=2.5230687\t mu=9.882033\t sigma=1.1041919\n",
      "Iteration=2917\t Loss=2.5230658\t mu=9.882296\t sigma=1.1041888\n",
      "Iteration=2918\t Loss=2.523063\t mu=9.882558\t sigma=1.1041857\n",
      "Iteration=2919\t Loss=2.5230606\t mu=9.882819\t sigma=1.1041826\n",
      "Iteration=2920\t Loss=2.5230575\t mu=9.88308\t sigma=1.1041795\n",
      "Iteration=2921\t Loss=2.5230548\t mu=9.883339\t sigma=1.1041765\n",
      "Iteration=2922\t Loss=2.523052\t mu=9.883598\t sigma=1.1041735\n",
      "Iteration=2923\t Loss=2.5230498\t mu=9.883857\t sigma=1.1041706\n",
      "Iteration=2924\t Loss=2.523047\t mu=9.884114\t sigma=1.1041676\n",
      "Iteration=2925\t Loss=2.523044\t mu=9.884371\t sigma=1.1041646\n",
      "Iteration=2926\t Loss=2.5230417\t mu=9.884627\t sigma=1.1041616\n",
      "Iteration=2927\t Loss=2.5230386\t mu=9.884883\t sigma=1.1041586\n",
      "Iteration=2928\t Loss=2.5230365\t mu=9.885138\t sigma=1.1041558\n",
      "Iteration=2929\t Loss=2.523034\t mu=9.885392\t sigma=1.1041529\n",
      "Iteration=2930\t Loss=2.5230312\t mu=9.885646\t sigma=1.10415\n",
      "Iteration=2931\t Loss=2.5230286\t mu=9.885899\t sigma=1.1041472\n",
      "Iteration=2932\t Loss=2.5230262\t mu=9.88615\t sigma=1.1041443\n",
      "Iteration=2933\t Loss=2.5230238\t mu=9.886402\t sigma=1.1041415\n",
      "Iteration=2934\t Loss=2.5230212\t mu=9.886653\t sigma=1.1041386\n",
      "Iteration=2935\t Loss=2.5230186\t mu=9.886903\t sigma=1.1041358\n",
      "Iteration=2936\t Loss=2.5230162\t mu=9.887152\t sigma=1.104133\n",
      "Iteration=2937\t Loss=2.5230136\t mu=9.887401\t sigma=1.1041303\n",
      "Iteration=2938\t Loss=2.5230114\t mu=9.887649\t sigma=1.1041275\n",
      "Iteration=2939\t Loss=2.5230088\t mu=9.887896\t sigma=1.1041248\n",
      "Iteration=2940\t Loss=2.523006\t mu=9.888143\t sigma=1.104122\n",
      "Iteration=2941\t Loss=2.5230038\t mu=9.888389\t sigma=1.1041193\n",
      "Iteration=2942\t Loss=2.5230017\t mu=9.888634\t sigma=1.1041166\n",
      "Iteration=2943\t Loss=2.5229993\t mu=9.888878\t sigma=1.1041138\n",
      "Iteration=2944\t Loss=2.5229971\t mu=9.889122\t sigma=1.1041112\n",
      "Iteration=2945\t Loss=2.5229945\t mu=9.889365\t sigma=1.1041086\n",
      "Iteration=2946\t Loss=2.522992\t mu=9.889607\t sigma=1.104106\n",
      "Iteration=2947\t Loss=2.5229897\t mu=9.88985\t sigma=1.1041033\n",
      "Iteration=2948\t Loss=2.5229876\t mu=9.890091\t sigma=1.1041007\n",
      "Iteration=2949\t Loss=2.5229855\t mu=9.890331\t sigma=1.1040981\n",
      "Iteration=2950\t Loss=2.5229828\t mu=9.890572\t sigma=1.1040955\n",
      "Iteration=2951\t Loss=2.5229802\t mu=9.890811\t sigma=1.1040928\n",
      "Iteration=2952\t Loss=2.5229783\t mu=9.891049\t sigma=1.1040903\n",
      "Iteration=2953\t Loss=2.5229762\t mu=9.891288\t sigma=1.1040878\n",
      "Iteration=2954\t Loss=2.5229738\t mu=9.891525\t sigma=1.1040853\n",
      "Iteration=2955\t Loss=2.5229719\t mu=9.891762\t sigma=1.1040828\n",
      "Iteration=2956\t Loss=2.5229692\t mu=9.891997\t sigma=1.1040803\n",
      "Iteration=2957\t Loss=2.522967\t mu=9.892233\t sigma=1.1040778\n",
      "Iteration=2958\t Loss=2.5229647\t mu=9.8924675\t sigma=1.1040753\n",
      "Iteration=2959\t Loss=2.5229628\t mu=9.892701\t sigma=1.1040728\n",
      "Iteration=2960\t Loss=2.5229607\t mu=9.892935\t sigma=1.1040704\n",
      "Iteration=2961\t Loss=2.5229585\t mu=9.8931675\t sigma=1.104068\n",
      "Iteration=2962\t Loss=2.5229561\t mu=9.893399\t sigma=1.1040657\n",
      "Iteration=2963\t Loss=2.522954\t mu=9.893631\t sigma=1.1040633\n",
      "Iteration=2964\t Loss=2.5229518\t mu=9.893862\t sigma=1.1040609\n",
      "Iteration=2965\t Loss=2.5229495\t mu=9.894092\t sigma=1.1040585\n",
      "Iteration=2966\t Loss=2.5229475\t mu=9.894321\t sigma=1.1040561\n",
      "Iteration=2967\t Loss=2.5229454\t mu=9.89455\t sigma=1.1040537\n",
      "Iteration=2968\t Loss=2.5229435\t mu=9.894778\t sigma=1.1040514\n",
      "Iteration=2969\t Loss=2.5229416\t mu=9.895006\t sigma=1.104049\n",
      "Iteration=2970\t Loss=2.522939\t mu=9.895233\t sigma=1.1040467\n",
      "Iteration=2971\t Loss=2.5229373\t mu=9.89546\t sigma=1.1040444\n",
      "Iteration=2972\t Loss=2.5229352\t mu=9.895686\t sigma=1.1040422\n",
      "Iteration=2973\t Loss=2.5229332\t mu=9.895911\t sigma=1.1040399\n",
      "Iteration=2974\t Loss=2.5229313\t mu=9.896136\t sigma=1.1040376\n",
      "Iteration=2975\t Loss=2.5229292\t mu=9.89636\t sigma=1.1040354\n",
      "Iteration=2976\t Loss=2.5229273\t mu=9.896584\t sigma=1.1040331\n",
      "Iteration=2977\t Loss=2.5229254\t mu=9.896807\t sigma=1.1040308\n",
      "Iteration=2978\t Loss=2.5229235\t mu=9.897029\t sigma=1.1040286\n",
      "Iteration=2979\t Loss=2.5229213\t mu=9.89725\t sigma=1.1040264\n",
      "Iteration=2980\t Loss=2.5229194\t mu=9.897471\t sigma=1.1040243\n",
      "Iteration=2981\t Loss=2.5229173\t mu=9.897692\t sigma=1.1040221\n",
      "Iteration=2982\t Loss=2.5229151\t mu=9.897911\t sigma=1.10402\n",
      "Iteration=2983\t Loss=2.5229135\t mu=9.89813\t sigma=1.1040179\n",
      "Iteration=2984\t Loss=2.5229118\t mu=9.898349\t sigma=1.1040157\n",
      "Iteration=2985\t Loss=2.5229099\t mu=9.898567\t sigma=1.1040136\n",
      "Iteration=2986\t Loss=2.5229077\t mu=9.898785\t sigma=1.1040114\n",
      "Iteration=2987\t Loss=2.522906\t mu=9.899001\t sigma=1.1040093\n",
      "Iteration=2988\t Loss=2.5229042\t mu=9.899218\t sigma=1.1040071\n",
      "Iteration=2989\t Loss=2.522902\t mu=9.899433\t sigma=1.1040051\n",
      "Iteration=2990\t Loss=2.5229\t mu=9.899648\t sigma=1.1040031\n",
      "Iteration=2991\t Loss=2.5228982\t mu=9.899862\t sigma=1.104001\n",
      "Iteration=2992\t Loss=2.5228965\t mu=9.900076\t sigma=1.103999\n",
      "Iteration=2993\t Loss=2.5228953\t mu=9.90029\t sigma=1.103997\n",
      "Iteration=2994\t Loss=2.5228932\t mu=9.900502\t sigma=1.103995\n",
      "Iteration=2995\t Loss=2.5228913\t mu=9.900714\t sigma=1.1039929\n",
      "Iteration=2996\t Loss=2.5228896\t mu=9.900926\t sigma=1.1039909\n",
      "Iteration=2997\t Loss=2.522888\t mu=9.901136\t sigma=1.1039889\n",
      "Iteration=2998\t Loss=2.522886\t mu=9.901347\t sigma=1.1039869\n",
      "Iteration=2999\t Loss=2.5228841\t mu=9.901557\t sigma=1.1039848\n",
      "Iteration=3000\t Loss=2.5228827\t mu=9.901766\t sigma=1.1039829\n",
      "Iteration=3001\t Loss=2.5228806\t mu=9.901975\t sigma=1.103981\n",
      "Iteration=3002\t Loss=2.5228791\t mu=9.902183\t sigma=1.1039791\n",
      "Iteration=3003\t Loss=2.5228775\t mu=9.9023905\t sigma=1.1039772\n",
      "Iteration=3004\t Loss=2.5228758\t mu=9.902597\t sigma=1.1039753\n",
      "Iteration=3005\t Loss=2.5228739\t mu=9.902803\t sigma=1.1039734\n",
      "Iteration=3006\t Loss=2.5228722\t mu=9.903009\t sigma=1.1039715\n",
      "Iteration=3007\t Loss=2.5228705\t mu=9.903214\t sigma=1.1039696\n",
      "Iteration=3008\t Loss=2.5228689\t mu=9.9034195\t sigma=1.1039677\n",
      "Iteration=3009\t Loss=2.5228677\t mu=9.903624\t sigma=1.1039658\n",
      "Iteration=3010\t Loss=2.5228655\t mu=9.903827\t sigma=1.1039639\n",
      "Iteration=3011\t Loss=2.5228634\t mu=9.90403\t sigma=1.1039621\n",
      "Iteration=3012\t Loss=2.5228624\t mu=9.904232\t sigma=1.1039603\n",
      "Iteration=3013\t Loss=2.5228605\t mu=9.904434\t sigma=1.1039585\n",
      "Iteration=3014\t Loss=2.522859\t mu=9.904635\t sigma=1.1039567\n",
      "Iteration=3015\t Loss=2.5228574\t mu=9.904836\t sigma=1.1039549\n",
      "Iteration=3016\t Loss=2.5228558\t mu=9.905036\t sigma=1.1039531\n",
      "Iteration=3017\t Loss=2.5228543\t mu=9.905235\t sigma=1.1039513\n",
      "Iteration=3018\t Loss=2.5228527\t mu=9.905435\t sigma=1.1039495\n",
      "Iteration=3019\t Loss=2.522851\t mu=9.905633\t sigma=1.1039478\n",
      "Iteration=3020\t Loss=2.5228496\t mu=9.905831\t sigma=1.103946\n",
      "Iteration=3021\t Loss=2.5228477\t mu=9.906029\t sigma=1.1039442\n",
      "Iteration=3022\t Loss=2.5228465\t mu=9.906225\t sigma=1.1039424\n",
      "Iteration=3023\t Loss=2.5228448\t mu=9.906422\t sigma=1.1039407\n",
      "Iteration=3024\t Loss=2.5228434\t mu=9.906617\t sigma=1.103939\n",
      "Iteration=3025\t Loss=2.5228417\t mu=9.906813\t sigma=1.1039374\n",
      "Iteration=3026\t Loss=2.5228405\t mu=9.907007\t sigma=1.1039357\n",
      "Iteration=3027\t Loss=2.5228388\t mu=9.907202\t sigma=1.103934\n",
      "Iteration=3028\t Loss=2.5228374\t mu=9.907395\t sigma=1.1039324\n",
      "Iteration=3029\t Loss=2.522836\t mu=9.907589\t sigma=1.1039307\n",
      "Iteration=3030\t Loss=2.5228343\t mu=9.907782\t sigma=1.103929\n",
      "Iteration=3031\t Loss=2.5228326\t mu=9.907973\t sigma=1.1039274\n",
      "Iteration=3032\t Loss=2.5228317\t mu=9.908165\t sigma=1.1039257\n",
      "Iteration=3033\t Loss=2.52283\t mu=9.908356\t sigma=1.103924\n",
      "Iteration=3034\t Loss=2.5228286\t mu=9.908546\t sigma=1.1039224\n",
      "Iteration=3035\t Loss=2.522827\t mu=9.908736\t sigma=1.1039207\n",
      "Iteration=3036\t Loss=2.5228257\t mu=9.908926\t sigma=1.103919\n",
      "Iteration=3037\t Loss=2.5228245\t mu=9.909115\t sigma=1.1039175\n",
      "Iteration=3038\t Loss=2.5228226\t mu=9.909304\t sigma=1.1039159\n",
      "Iteration=3039\t Loss=2.5228217\t mu=9.909492\t sigma=1.1039144\n",
      "Iteration=3040\t Loss=2.52282\t mu=9.909678\t sigma=1.1039128\n",
      "Iteration=3041\t Loss=2.5228188\t mu=9.909865\t sigma=1.1039113\n",
      "Iteration=3042\t Loss=2.522817\t mu=9.910051\t sigma=1.1039097\n",
      "Iteration=3043\t Loss=2.5228157\t mu=9.910237\t sigma=1.1039082\n",
      "Iteration=3044\t Loss=2.5228145\t mu=9.910422\t sigma=1.1039066\n",
      "Iteration=3045\t Loss=2.5228128\t mu=9.910607\t sigma=1.1039051\n",
      "Iteration=3046\t Loss=2.5228117\t mu=9.910791\t sigma=1.1039035\n",
      "Iteration=3047\t Loss=2.5228105\t mu=9.910975\t sigma=1.103902\n",
      "Iteration=3048\t Loss=2.522809\t mu=9.911159\t sigma=1.1039004\n",
      "Iteration=3049\t Loss=2.5228074\t mu=9.911342\t sigma=1.1038989\n",
      "Iteration=3050\t Loss=2.5228062\t mu=9.911524\t sigma=1.1038973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=3051\t Loss=2.522805\t mu=9.911706\t sigma=1.1038959\n",
      "Iteration=3052\t Loss=2.522804\t mu=9.911887\t sigma=1.1038945\n",
      "Iteration=3053\t Loss=2.5228026\t mu=9.912068\t sigma=1.103893\n",
      "Iteration=3054\t Loss=2.5228007\t mu=9.912249\t sigma=1.1038916\n",
      "Iteration=3055\t Loss=2.5228\t mu=9.912429\t sigma=1.1038902\n",
      "Iteration=3056\t Loss=2.5227985\t mu=9.912608\t sigma=1.1038888\n",
      "Iteration=3057\t Loss=2.522797\t mu=9.912787\t sigma=1.1038873\n",
      "Iteration=3058\t Loss=2.5227957\t mu=9.912966\t sigma=1.1038859\n",
      "Iteration=3059\t Loss=2.522795\t mu=9.913143\t sigma=1.1038845\n",
      "Iteration=3060\t Loss=2.5227938\t mu=9.913321\t sigma=1.103883\n",
      "Iteration=3061\t Loss=2.522792\t mu=9.913497\t sigma=1.1038816\n",
      "Iteration=3062\t Loss=2.5227907\t mu=9.913673\t sigma=1.1038802\n",
      "Iteration=3063\t Loss=2.52279\t mu=9.913849\t sigma=1.1038787\n",
      "Iteration=3064\t Loss=2.5227888\t mu=9.914024\t sigma=1.1038773\n",
      "Iteration=3065\t Loss=2.5227876\t mu=9.914199\t sigma=1.103876\n",
      "Iteration=3066\t Loss=2.5227864\t mu=9.914373\t sigma=1.1038747\n",
      "Iteration=3067\t Loss=2.5227847\t mu=9.914547\t sigma=1.1038734\n",
      "Iteration=3068\t Loss=2.5227835\t mu=9.914721\t sigma=1.1038721\n",
      "Iteration=3069\t Loss=2.5227823\t mu=9.914893\t sigma=1.1038707\n",
      "Iteration=3070\t Loss=2.5227811\t mu=9.915066\t sigma=1.1038694\n",
      "Iteration=3071\t Loss=2.52278\t mu=9.915237\t sigma=1.1038681\n",
      "Iteration=3072\t Loss=2.5227787\t mu=9.915409\t sigma=1.1038668\n",
      "Iteration=3073\t Loss=2.5227778\t mu=9.91558\t sigma=1.1038655\n",
      "Iteration=3074\t Loss=2.5227768\t mu=9.9157505\t sigma=1.1038642\n",
      "Iteration=3075\t Loss=2.5227754\t mu=9.91592\t sigma=1.1038629\n",
      "Iteration=3076\t Loss=2.5227742\t mu=9.91609\t sigma=1.1038616\n",
      "Iteration=3077\t Loss=2.5227733\t mu=9.916259\t sigma=1.1038603\n",
      "Iteration=3078\t Loss=2.5227723\t mu=9.916428\t sigma=1.103859\n",
      "Iteration=3079\t Loss=2.5227706\t mu=9.916596\t sigma=1.1038576\n",
      "Iteration=3080\t Loss=2.5227697\t mu=9.916764\t sigma=1.1038563\n",
      "Iteration=3081\t Loss=2.5227685\t mu=9.916932\t sigma=1.103855\n",
      "Iteration=3082\t Loss=2.5227675\t mu=9.917099\t sigma=1.1038538\n",
      "Iteration=3083\t Loss=2.5227664\t mu=9.917266\t sigma=1.1038526\n",
      "Iteration=3084\t Loss=2.522765\t mu=9.917432\t sigma=1.1038514\n",
      "Iteration=3085\t Loss=2.522764\t mu=9.917598\t sigma=1.1038502\n",
      "Iteration=3086\t Loss=2.522763\t mu=9.917763\t sigma=1.103849\n",
      "Iteration=3087\t Loss=2.522762\t mu=9.917928\t sigma=1.1038479\n",
      "Iteration=3088\t Loss=2.522761\t mu=9.918092\t sigma=1.1038467\n",
      "Iteration=3089\t Loss=2.52276\t mu=9.918256\t sigma=1.1038455\n",
      "Iteration=3090\t Loss=2.5227587\t mu=9.918419\t sigma=1.1038443\n",
      "Iteration=3091\t Loss=2.5227575\t mu=9.918582\t sigma=1.1038431\n",
      "Iteration=3092\t Loss=2.5227566\t mu=9.918744\t sigma=1.1038419\n",
      "Iteration=3093\t Loss=2.5227554\t mu=9.918906\t sigma=1.1038407\n",
      "Iteration=3094\t Loss=2.5227547\t mu=9.919067\t sigma=1.1038395\n",
      "Iteration=3095\t Loss=2.5227535\t mu=9.919229\t sigma=1.1038383\n",
      "Iteration=3096\t Loss=2.5227528\t mu=9.919389\t sigma=1.1038371\n",
      "Iteration=3097\t Loss=2.5227513\t mu=9.919549\t sigma=1.1038359\n",
      "Iteration=3098\t Loss=2.5227504\t mu=9.919709\t sigma=1.1038347\n",
      "Iteration=3099\t Loss=2.5227494\t mu=9.919868\t sigma=1.1038336\n",
      "Iteration=3100\t Loss=2.5227485\t mu=9.920028\t sigma=1.1038324\n",
      "Iteration=3101\t Loss=2.5227478\t mu=9.920186\t sigma=1.1038313\n",
      "Iteration=3102\t Loss=2.5227466\t mu=9.920344\t sigma=1.1038302\n",
      "Iteration=3103\t Loss=2.5227454\t mu=9.920502\t sigma=1.1038291\n",
      "Iteration=3104\t Loss=2.5227444\t mu=9.920659\t sigma=1.1038281\n",
      "Iteration=3105\t Loss=2.5227435\t mu=9.920815\t sigma=1.103827\n",
      "Iteration=3106\t Loss=2.5227423\t mu=9.920972\t sigma=1.1038259\n",
      "Iteration=3107\t Loss=2.5227416\t mu=9.921127\t sigma=1.1038249\n",
      "Iteration=3108\t Loss=2.5227406\t mu=9.921283\t sigma=1.1038238\n",
      "Iteration=3109\t Loss=2.5227401\t mu=9.921438\t sigma=1.1038227\n",
      "Iteration=3110\t Loss=2.5227387\t mu=9.921593\t sigma=1.1038216\n",
      "Iteration=3111\t Loss=2.5227375\t mu=9.921747\t sigma=1.1038206\n",
      "Iteration=3112\t Loss=2.522737\t mu=9.921901\t sigma=1.1038195\n",
      "Iteration=3113\t Loss=2.5227358\t mu=9.922054\t sigma=1.1038184\n",
      "Iteration=3114\t Loss=2.5227349\t mu=9.922207\t sigma=1.1038173\n",
      "Iteration=3115\t Loss=2.5227342\t mu=9.922359\t sigma=1.1038163\n",
      "Iteration=3116\t Loss=2.5227327\t mu=9.922511\t sigma=1.1038152\n",
      "Iteration=3117\t Loss=2.5227325\t mu=9.922663\t sigma=1.1038141\n",
      "Iteration=3118\t Loss=2.5227315\t mu=9.922814\t sigma=1.103813\n",
      "Iteration=3119\t Loss=2.5227304\t mu=9.922965\t sigma=1.103812\n",
      "Iteration=3120\t Loss=2.5227294\t mu=9.923116\t sigma=1.1038109\n",
      "Iteration=3121\t Loss=2.5227284\t mu=9.923265\t sigma=1.10381\n",
      "Iteration=3122\t Loss=2.5227277\t mu=9.923415\t sigma=1.103809\n",
      "Iteration=3123\t Loss=2.5227265\t mu=9.923564\t sigma=1.103808\n",
      "Iteration=3124\t Loss=2.5227258\t mu=9.923713\t sigma=1.1038071\n",
      "Iteration=3125\t Loss=2.5227249\t mu=9.9238615\t sigma=1.1038061\n",
      "Iteration=3126\t Loss=2.522724\t mu=9.924009\t sigma=1.1038052\n",
      "Iteration=3127\t Loss=2.5227232\t mu=9.924157\t sigma=1.1038042\n",
      "Iteration=3128\t Loss=2.5227225\t mu=9.924304\t sigma=1.1038033\n",
      "Iteration=3129\t Loss=2.5227215\t mu=9.924451\t sigma=1.1038023\n",
      "Iteration=3130\t Loss=2.5227208\t mu=9.924597\t sigma=1.1038014\n",
      "Iteration=3131\t Loss=2.5227199\t mu=9.924743\t sigma=1.1038004\n",
      "Iteration=3132\t Loss=2.5227191\t mu=9.924889\t sigma=1.1037995\n",
      "Iteration=3133\t Loss=2.522718\t mu=9.925034\t sigma=1.1037985\n",
      "Iteration=3134\t Loss=2.522717\t mu=9.925179\t sigma=1.1037976\n",
      "Iteration=3135\t Loss=2.5227163\t mu=9.925323\t sigma=1.1037966\n",
      "Iteration=3136\t Loss=2.5227153\t mu=9.925467\t sigma=1.1037956\n",
      "Iteration=3137\t Loss=2.5227149\t mu=9.92561\t sigma=1.1037947\n",
      "Iteration=3138\t Loss=2.522714\t mu=9.925753\t sigma=1.1037937\n",
      "Iteration=3139\t Loss=2.5227132\t mu=9.925896\t sigma=1.1037928\n",
      "Iteration=3140\t Loss=2.5227122\t mu=9.926038\t sigma=1.1037918\n",
      "Iteration=3141\t Loss=2.5227115\t mu=9.92618\t sigma=1.1037909\n",
      "Iteration=3142\t Loss=2.5227108\t mu=9.926321\t sigma=1.1037899\n",
      "Iteration=3143\t Loss=2.52271\t mu=9.926462\t sigma=1.1037891\n",
      "Iteration=3144\t Loss=2.5227091\t mu=9.926603\t sigma=1.1037883\n",
      "Iteration=3145\t Loss=2.5227087\t mu=9.9267435\t sigma=1.1037874\n",
      "Iteration=3146\t Loss=2.5227077\t mu=9.926884\t sigma=1.1037866\n",
      "Iteration=3147\t Loss=2.522707\t mu=9.927023\t sigma=1.1037858\n",
      "Iteration=3148\t Loss=2.5227058\t mu=9.927162\t sigma=1.1037849\n",
      "Iteration=3149\t Loss=2.5227053\t mu=9.927301\t sigma=1.1037841\n",
      "Iteration=3150\t Loss=2.5227046\t mu=9.92744\t sigma=1.1037832\n",
      "Iteration=3151\t Loss=2.522704\t mu=9.927578\t sigma=1.1037824\n",
      "Iteration=3152\t Loss=2.5227027\t mu=9.927715\t sigma=1.1037816\n",
      "Iteration=3153\t Loss=2.522702\t mu=9.927853\t sigma=1.1037807\n",
      "Iteration=3154\t Loss=2.5227015\t mu=9.92799\t sigma=1.1037799\n",
      "Iteration=3155\t Loss=2.522701\t mu=9.928126\t sigma=1.1037791\n",
      "Iteration=3156\t Loss=2.5227\t mu=9.928263\t sigma=1.1037782\n",
      "Iteration=3157\t Loss=2.522699\t mu=9.928398\t sigma=1.1037774\n",
      "Iteration=3158\t Loss=2.5226989\t mu=9.928534\t sigma=1.1037766\n",
      "Iteration=3159\t Loss=2.5226977\t mu=9.928669\t sigma=1.1037757\n",
      "Iteration=3160\t Loss=2.5226972\t mu=9.928803\t sigma=1.1037749\n",
      "Iteration=3161\t Loss=2.5226965\t mu=9.928938\t sigma=1.1037741\n",
      "Iteration=3162\t Loss=2.5226958\t mu=9.929071\t sigma=1.1037732\n",
      "Iteration=3163\t Loss=2.522695\t mu=9.929205\t sigma=1.1037724\n",
      "Iteration=3164\t Loss=2.5226943\t mu=9.929338\t sigma=1.1037716\n",
      "Iteration=3165\t Loss=2.5226939\t mu=9.929471\t sigma=1.1037707\n",
      "Iteration=3166\t Loss=2.5226927\t mu=9.929604\t sigma=1.1037699\n",
      "Iteration=3167\t Loss=2.5226924\t mu=9.929736\t sigma=1.1037691\n",
      "Iteration=3168\t Loss=2.5226915\t mu=9.929868\t sigma=1.1037682\n",
      "Iteration=3169\t Loss=2.5226905\t mu=9.929999\t sigma=1.1037675\n",
      "Iteration=3170\t Loss=2.52269\t mu=9.93013\t sigma=1.1037668\n",
      "Iteration=3171\t Loss=2.5226893\t mu=9.930261\t sigma=1.1037661\n",
      "Iteration=3172\t Loss=2.5226884\t mu=9.930391\t sigma=1.1037654\n",
      "Iteration=3173\t Loss=2.522688\t mu=9.930521\t sigma=1.1037647\n",
      "Iteration=3174\t Loss=2.5226872\t mu=9.930651\t sigma=1.1037639\n",
      "Iteration=3175\t Loss=2.5226865\t mu=9.93078\t sigma=1.1037632\n",
      "Iteration=3176\t Loss=2.522686\t mu=9.930909\t sigma=1.1037625\n",
      "Iteration=3177\t Loss=2.522685\t mu=9.931038\t sigma=1.1037618\n",
      "Iteration=3178\t Loss=2.5226848\t mu=9.931166\t sigma=1.1037611\n",
      "Iteration=3179\t Loss=2.522684\t mu=9.9312935\t sigma=1.1037604\n",
      "Iteration=3180\t Loss=2.5226834\t mu=9.931421\t sigma=1.1037596\n",
      "Iteration=3181\t Loss=2.522683\t mu=9.931548\t sigma=1.1037589\n",
      "Iteration=3182\t Loss=2.5226822\t mu=9.931675\t sigma=1.1037582\n",
      "Iteration=3183\t Loss=2.5226815\t mu=9.931802\t sigma=1.1037575\n",
      "Iteration=3184\t Loss=2.5226808\t mu=9.931928\t sigma=1.1037568\n",
      "Iteration=3185\t Loss=2.5226803\t mu=9.932054\t sigma=1.1037561\n",
      "Iteration=3186\t Loss=2.5226796\t mu=9.9321785\t sigma=1.1037554\n",
      "Iteration=3187\t Loss=2.5226789\t mu=9.932303\t sigma=1.1037546\n",
      "Iteration=3188\t Loss=2.5226781\t mu=9.932428\t sigma=1.1037539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=3189\t Loss=2.5226777\t mu=9.932552\t sigma=1.1037532\n",
      "Iteration=3190\t Loss=2.5226774\t mu=9.932676\t sigma=1.1037525\n",
      "Iteration=3191\t Loss=2.5226765\t mu=9.9328\t sigma=1.1037518\n",
      "Iteration=3192\t Loss=2.5226758\t mu=9.932923\t sigma=1.1037511\n",
      "Iteration=3193\t Loss=2.5226753\t mu=9.933046\t sigma=1.1037503\n",
      "Iteration=3194\t Loss=2.5226746\t mu=9.933169\t sigma=1.1037496\n",
      "Iteration=3195\t Loss=2.522674\t mu=9.933291\t sigma=1.1037489\n",
      "Iteration=3196\t Loss=2.5226734\t mu=9.9334135\t sigma=1.1037482\n",
      "Iteration=3197\t Loss=2.522673\t mu=9.933536\t sigma=1.1037475\n",
      "Iteration=3198\t Loss=2.5226722\t mu=9.933657\t sigma=1.1037468\n",
      "Iteration=3199\t Loss=2.5226722\t mu=9.933778\t sigma=1.1037462\n",
      "Iteration=3200\t Loss=2.522671\t mu=9.933899\t sigma=1.1037456\n",
      "Iteration=3201\t Loss=2.5226705\t mu=9.934019\t sigma=1.103745\n",
      "Iteration=3202\t Loss=2.52267\t mu=9.934139\t sigma=1.1037444\n",
      "Iteration=3203\t Loss=2.5226696\t mu=9.934258\t sigma=1.1037438\n",
      "Iteration=3204\t Loss=2.5226688\t mu=9.934378\t sigma=1.1037432\n",
      "Iteration=3205\t Loss=2.5226684\t mu=9.934497\t sigma=1.1037426\n",
      "Iteration=3206\t Loss=2.522668\t mu=9.934615\t sigma=1.103742\n",
      "Iteration=3207\t Loss=2.5226672\t mu=9.934733\t sigma=1.1037414\n",
      "Iteration=3208\t Loss=2.5226667\t mu=9.934852\t sigma=1.1037408\n",
      "Iteration=3209\t Loss=2.5226662\t mu=9.934969\t sigma=1.1037402\n",
      "Iteration=3210\t Loss=2.5226657\t mu=9.935086\t sigma=1.1037396\n",
      "Iteration=3211\t Loss=2.522665\t mu=9.935204\t sigma=1.103739\n",
      "Iteration=3212\t Loss=2.5226643\t mu=9.93532\t sigma=1.1037384\n",
      "Iteration=3213\t Loss=2.5226638\t mu=9.935436\t sigma=1.1037378\n",
      "Iteration=3214\t Loss=2.5226636\t mu=9.935553\t sigma=1.1037372\n",
      "Iteration=3215\t Loss=2.5226629\t mu=9.935668\t sigma=1.1037366\n",
      "Iteration=3216\t Loss=2.5226624\t mu=9.935783\t sigma=1.103736\n",
      "Iteration=3217\t Loss=2.522662\t mu=9.935899\t sigma=1.1037354\n",
      "Iteration=3218\t Loss=2.5226612\t mu=9.936013\t sigma=1.1037349\n",
      "Iteration=3219\t Loss=2.5226603\t mu=9.936128\t sigma=1.1037343\n",
      "Iteration=3220\t Loss=2.5226603\t mu=9.936242\t sigma=1.1037337\n",
      "Iteration=3221\t Loss=2.5226598\t mu=9.936356\t sigma=1.1037331\n",
      "Iteration=3222\t Loss=2.522659\t mu=9.936469\t sigma=1.1037325\n",
      "Iteration=3223\t Loss=2.5226588\t mu=9.936583\t sigma=1.1037319\n",
      "Iteration=3224\t Loss=2.522658\t mu=9.936695\t sigma=1.1037313\n",
      "Iteration=3225\t Loss=2.5226579\t mu=9.936808\t sigma=1.1037307\n",
      "Iteration=3226\t Loss=2.522657\t mu=9.93692\t sigma=1.1037301\n",
      "Iteration=3227\t Loss=2.5226567\t mu=9.937032\t sigma=1.1037295\n",
      "Iteration=3228\t Loss=2.5226562\t mu=9.937143\t sigma=1.1037289\n",
      "Iteration=3229\t Loss=2.5226557\t mu=9.937255\t sigma=1.1037283\n",
      "Iteration=3230\t Loss=2.522655\t mu=9.9373665\t sigma=1.1037277\n",
      "Iteration=3231\t Loss=2.5226548\t mu=9.937477\t sigma=1.1037271\n",
      "Iteration=3232\t Loss=2.5226538\t mu=9.937588\t sigma=1.1037265\n",
      "Iteration=3233\t Loss=2.5226538\t mu=9.937698\t sigma=1.1037259\n",
      "Iteration=3234\t Loss=2.522653\t mu=9.937808\t sigma=1.1037253\n",
      "Iteration=3235\t Loss=2.5226526\t mu=9.937918\t sigma=1.1037247\n",
      "Iteration=3236\t Loss=2.5226524\t mu=9.938027\t sigma=1.1037242\n",
      "Iteration=3237\t Loss=2.5226517\t mu=9.938136\t sigma=1.1037238\n",
      "Iteration=3238\t Loss=2.5226512\t mu=9.938245\t sigma=1.1037232\n",
      "Iteration=3239\t Loss=2.5226507\t mu=9.938354\t sigma=1.1037227\n",
      "Iteration=3240\t Loss=2.5226502\t mu=9.938461\t sigma=1.1037222\n",
      "Iteration=3241\t Loss=2.5226498\t mu=9.938569\t sigma=1.1037217\n",
      "Iteration=3242\t Loss=2.5226495\t mu=9.938677\t sigma=1.1037213\n",
      "Iteration=3243\t Loss=2.5226488\t mu=9.938784\t sigma=1.1037208\n",
      "Iteration=3244\t Loss=2.5226483\t mu=9.93889\t sigma=1.1037203\n",
      "Iteration=3245\t Loss=2.522648\t mu=9.938997\t sigma=1.1037198\n",
      "Iteration=3246\t Loss=2.5226474\t mu=9.939103\t sigma=1.1037194\n",
      "Iteration=3247\t Loss=2.5226474\t mu=9.939209\t sigma=1.1037189\n",
      "Iteration=3248\t Loss=2.5226464\t mu=9.939315\t sigma=1.1037184\n",
      "Iteration=3249\t Loss=2.522646\t mu=9.939421\t sigma=1.1037179\n",
      "Iteration=3250\t Loss=2.5226457\t mu=9.939526\t sigma=1.1037174\n",
      "Iteration=3251\t Loss=2.5226452\t mu=9.9396305\t sigma=1.103717\n",
      "Iteration=3252\t Loss=2.522645\t mu=9.939735\t sigma=1.1037165\n",
      "Iteration=3253\t Loss=2.5226448\t mu=9.939839\t sigma=1.103716\n",
      "Iteration=3254\t Loss=2.522644\t mu=9.939943\t sigma=1.1037155\n",
      "Iteration=3255\t Loss=2.5226433\t mu=9.940047\t sigma=1.1037151\n",
      "Iteration=3256\t Loss=2.522643\t mu=9.94015\t sigma=1.1037146\n",
      "Iteration=3257\t Loss=2.5226426\t mu=9.940253\t sigma=1.1037141\n",
      "Iteration=3258\t Loss=2.5226421\t mu=9.940356\t sigma=1.1037136\n",
      "Iteration=3259\t Loss=2.522642\t mu=9.940459\t sigma=1.1037132\n",
      "Iteration=3260\t Loss=2.5226417\t mu=9.940561\t sigma=1.1037127\n",
      "Iteration=3261\t Loss=2.522641\t mu=9.940663\t sigma=1.1037122\n",
      "Iteration=3262\t Loss=2.5226405\t mu=9.940765\t sigma=1.1037117\n",
      "Iteration=3263\t Loss=2.52264\t mu=9.940866\t sigma=1.1037112\n",
      "Iteration=3264\t Loss=2.5226398\t mu=9.940968\t sigma=1.1037108\n",
      "Iteration=3265\t Loss=2.5226393\t mu=9.941069\t sigma=1.1037103\n",
      "Iteration=3266\t Loss=2.522639\t mu=9.94117\t sigma=1.1037098\n",
      "Iteration=3267\t Loss=2.5226386\t mu=9.94127\t sigma=1.1037093\n",
      "Iteration=3268\t Loss=2.5226383\t mu=9.94137\t sigma=1.1037089\n",
      "Iteration=3269\t Loss=2.5226376\t mu=9.94147\t sigma=1.1037084\n",
      "Iteration=3270\t Loss=2.5226374\t mu=9.941569\t sigma=1.1037079\n",
      "Iteration=3271\t Loss=2.5226371\t mu=9.9416685\t sigma=1.1037074\n",
      "Iteration=3272\t Loss=2.5226364\t mu=9.941768\t sigma=1.103707\n",
      "Iteration=3273\t Loss=2.5226364\t mu=9.941867\t sigma=1.1037065\n",
      "Iteration=3274\t Loss=2.522636\t mu=9.941965\t sigma=1.103706\n",
      "Iteration=3275\t Loss=2.5226355\t mu=9.942063\t sigma=1.1037055\n",
      "Iteration=3276\t Loss=2.5226352\t mu=9.942162\t sigma=1.103705\n",
      "Iteration=3277\t Loss=2.5226345\t mu=9.942259\t sigma=1.1037046\n",
      "Iteration=3278\t Loss=2.5226343\t mu=9.942356\t sigma=1.1037041\n",
      "Iteration=3279\t Loss=2.522634\t mu=9.942453\t sigma=1.1037036\n",
      "Iteration=3280\t Loss=2.5226336\t mu=9.942551\t sigma=1.1037033\n",
      "Iteration=3281\t Loss=2.5226333\t mu=9.942647\t sigma=1.1037029\n",
      "Iteration=3282\t Loss=2.522633\t mu=9.942743\t sigma=1.1037025\n",
      "Iteration=3283\t Loss=2.5226326\t mu=9.94284\t sigma=1.1037021\n",
      "Iteration=3284\t Loss=2.5226321\t mu=9.942935\t sigma=1.1037017\n",
      "Iteration=3285\t Loss=2.522632\t mu=9.94303\t sigma=1.1037014\n",
      "Iteration=3286\t Loss=2.5226314\t mu=9.943126\t sigma=1.103701\n",
      "Iteration=3287\t Loss=2.522631\t mu=9.943221\t sigma=1.1037006\n",
      "Iteration=3288\t Loss=2.5226307\t mu=9.9433155\t sigma=1.1037003\n",
      "Iteration=3289\t Loss=2.5226302\t mu=9.94341\t sigma=1.1036999\n",
      "Iteration=3290\t Loss=2.52263\t mu=9.943504\t sigma=1.1036996\n",
      "Iteration=3291\t Loss=2.5226295\t mu=9.943598\t sigma=1.1036992\n",
      "Iteration=3292\t Loss=2.522629\t mu=9.943691\t sigma=1.1036988\n",
      "Iteration=3293\t Loss=2.522629\t mu=9.943785\t sigma=1.1036985\n",
      "Iteration=3294\t Loss=2.5226288\t mu=9.943878\t sigma=1.1036981\n",
      "Iteration=3295\t Loss=2.5226285\t mu=9.943971\t sigma=1.1036978\n",
      "Iteration=3296\t Loss=2.5226278\t mu=9.944063\t sigma=1.1036974\n",
      "Iteration=3297\t Loss=2.5226276\t mu=9.944156\t sigma=1.1036971\n",
      "Iteration=3298\t Loss=2.5226274\t mu=9.944248\t sigma=1.1036967\n",
      "Iteration=3299\t Loss=2.5226269\t mu=9.94434\t sigma=1.1036963\n",
      "Iteration=3300\t Loss=2.5226266\t mu=9.944431\t sigma=1.103696\n",
      "Iteration=3301\t Loss=2.5226264\t mu=9.944523\t sigma=1.1036956\n",
      "Iteration=3302\t Loss=2.5226257\t mu=9.944614\t sigma=1.1036953\n",
      "Iteration=3303\t Loss=2.5226257\t mu=9.944705\t sigma=1.1036949\n",
      "Iteration=3304\t Loss=2.5226252\t mu=9.944796\t sigma=1.1036946\n",
      "Iteration=3305\t Loss=2.522625\t mu=9.944886\t sigma=1.1036942\n",
      "Iteration=3306\t Loss=2.5226245\t mu=9.944977\t sigma=1.1036938\n",
      "Iteration=3307\t Loss=2.5226245\t mu=9.945066\t sigma=1.1036935\n",
      "Iteration=3308\t Loss=2.5226238\t mu=9.945156\t sigma=1.1036931\n",
      "Iteration=3309\t Loss=2.5226235\t mu=9.945246\t sigma=1.1036928\n",
      "Iteration=3310\t Loss=2.5226235\t mu=9.945334\t sigma=1.1036924\n",
      "Iteration=3311\t Loss=2.5226228\t mu=9.945423\t sigma=1.103692\n",
      "Iteration=3312\t Loss=2.5226226\t mu=9.945512\t sigma=1.1036917\n",
      "Iteration=3313\t Loss=2.5226223\t mu=9.9456005\t sigma=1.1036913\n",
      "Iteration=3314\t Loss=2.5226223\t mu=9.945688\t sigma=1.103691\n",
      "Iteration=3315\t Loss=2.5226219\t mu=9.945776\t sigma=1.1036906\n",
      "Iteration=3316\t Loss=2.5226214\t mu=9.945864\t sigma=1.1036903\n",
      "Iteration=3317\t Loss=2.5226214\t mu=9.945951\t sigma=1.1036899\n",
      "Iteration=3318\t Loss=2.5226207\t mu=9.946038\t sigma=1.1036896\n",
      "Iteration=3319\t Loss=2.5226207\t mu=9.946125\t sigma=1.1036892\n",
      "Iteration=3320\t Loss=2.5226202\t mu=9.946212\t sigma=1.1036888\n",
      "Iteration=3321\t Loss=2.52262\t mu=9.946299\t sigma=1.1036885\n",
      "Iteration=3322\t Loss=2.5226195\t mu=9.946384\t sigma=1.1036881\n",
      "Iteration=3323\t Loss=2.5226192\t mu=9.94647\t sigma=1.1036878\n",
      "Iteration=3324\t Loss=2.522619\t mu=9.946556\t sigma=1.1036874\n",
      "Iteration=3325\t Loss=2.5226188\t mu=9.946642\t sigma=1.103687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=3326\t Loss=2.5226183\t mu=9.946727\t sigma=1.1036867\n",
      "Iteration=3327\t Loss=2.5226178\t mu=9.946812\t sigma=1.1036863\n",
      "Iteration=3328\t Loss=2.5226176\t mu=9.946897\t sigma=1.103686\n",
      "Iteration=3329\t Loss=2.5226176\t mu=9.946981\t sigma=1.1036856\n",
      "Iteration=3330\t Loss=2.522617\t mu=9.947065\t sigma=1.1036853\n",
      "Iteration=3331\t Loss=2.522617\t mu=9.947149\t sigma=1.1036849\n",
      "Iteration=3332\t Loss=2.5226166\t mu=9.947233\t sigma=1.1036845\n",
      "Iteration=3333\t Loss=2.5226164\t mu=9.947317\t sigma=1.1036842\n",
      "Iteration=3334\t Loss=2.5226161\t mu=9.947401\t sigma=1.1036838\n",
      "Iteration=3335\t Loss=2.522616\t mu=9.947484\t sigma=1.1036835\n",
      "Iteration=3336\t Loss=2.5226154\t mu=9.947567\t sigma=1.1036831\n",
      "Iteration=3337\t Loss=2.5226152\t mu=9.94765\t sigma=1.1036828\n",
      "Iteration=3338\t Loss=2.5226152\t mu=9.947733\t sigma=1.1036824\n",
      "Iteration=3339\t Loss=2.522615\t mu=9.947815\t sigma=1.1036822\n",
      "Iteration=3340\t Loss=2.5226142\t mu=9.947897\t sigma=1.1036818\n",
      "Iteration=3341\t Loss=2.5226142\t mu=9.947979\t sigma=1.1036816\n",
      "Iteration=3342\t Loss=2.522614\t mu=9.948061\t sigma=1.1036813\n",
      "Iteration=3343\t Loss=2.5226133\t mu=9.948142\t sigma=1.103681\n",
      "Iteration=3344\t Loss=2.5226135\t mu=9.948223\t sigma=1.1036807\n",
      "Iteration=3345\t Loss=2.5226128\t mu=9.948304\t sigma=1.1036805\n",
      "Iteration=3346\t Loss=2.5226128\t mu=9.948385\t sigma=1.1036803\n",
      "Iteration=3347\t Loss=2.5226126\t mu=9.948465\t sigma=1.1036799\n",
      "Iteration=3348\t Loss=2.5226128\t mu=9.948545\t sigma=1.1036797\n",
      "Iteration=3349\t Loss=2.5226123\t mu=9.948626\t sigma=1.1036794\n",
      "Iteration=3350\t Loss=2.5226119\t mu=9.948706\t sigma=1.1036792\n",
      "Iteration=3351\t Loss=2.5226116\t mu=9.948786\t sigma=1.1036788\n",
      "Iteration=3352\t Loss=2.5226111\t mu=9.948865\t sigma=1.1036786\n",
      "Iteration=3353\t Loss=2.5226114\t mu=9.948944\t sigma=1.1036783\n",
      "Iteration=3354\t Loss=2.5226107\t mu=9.949023\t sigma=1.1036781\n",
      "Iteration=3355\t Loss=2.5226107\t mu=9.949102\t sigma=1.1036779\n",
      "Iteration=3356\t Loss=2.5226107\t mu=9.949181\t sigma=1.1036776\n",
      "Iteration=3357\t Loss=2.5226102\t mu=9.949259\t sigma=1.1036774\n",
      "Iteration=3358\t Loss=2.52261\t mu=9.949337\t sigma=1.1036772\n",
      "Iteration=3359\t Loss=2.5226097\t mu=9.949415\t sigma=1.1036769\n",
      "Iteration=3360\t Loss=2.5226092\t mu=9.949492\t sigma=1.1036767\n",
      "Iteration=3361\t Loss=2.5226095\t mu=9.94957\t sigma=1.1036764\n",
      "Iteration=3362\t Loss=2.522609\t mu=9.949647\t sigma=1.1036762\n",
      "Iteration=3363\t Loss=2.522609\t mu=9.949724\t sigma=1.103676\n",
      "Iteration=3364\t Loss=2.5226083\t mu=9.949801\t sigma=1.1036757\n",
      "Iteration=3365\t Loss=2.5226083\t mu=9.949878\t sigma=1.1036755\n",
      "Iteration=3366\t Loss=2.522608\t mu=9.949954\t sigma=1.1036752\n",
      "Iteration=3367\t Loss=2.5226078\t mu=9.95003\t sigma=1.103675\n",
      "Iteration=3368\t Loss=2.5226076\t mu=9.950107\t sigma=1.1036748\n",
      "Iteration=3369\t Loss=2.5226073\t mu=9.950182\t sigma=1.1036745\n",
      "Iteration=3370\t Loss=2.522607\t mu=9.950257\t sigma=1.1036743\n",
      "Iteration=3371\t Loss=2.5226068\t mu=9.950333\t sigma=1.103674\n",
      "Iteration=3372\t Loss=2.5226064\t mu=9.950408\t sigma=1.1036738\n",
      "Iteration=3373\t Loss=2.5226064\t mu=9.950483\t sigma=1.1036736\n",
      "Iteration=3374\t Loss=2.522606\t mu=9.950558\t sigma=1.1036733\n",
      "Iteration=3375\t Loss=2.522606\t mu=9.950632\t sigma=1.1036731\n",
      "Iteration=3376\t Loss=2.5226057\t mu=9.9507065\t sigma=1.1036729\n",
      "Iteration=3377\t Loss=2.5226057\t mu=9.950781\t sigma=1.1036726\n",
      "Iteration=3378\t Loss=2.5226054\t mu=9.950855\t sigma=1.1036724\n",
      "Iteration=3379\t Loss=2.5226052\t mu=9.950929\t sigma=1.1036721\n",
      "Iteration=3380\t Loss=2.522605\t mu=9.951002\t sigma=1.1036719\n",
      "Iteration=3381\t Loss=2.5226047\t mu=9.951076\t sigma=1.1036717\n",
      "Iteration=3382\t Loss=2.5226045\t mu=9.951149\t sigma=1.1036714\n",
      "Iteration=3383\t Loss=2.5226042\t mu=9.951221\t sigma=1.1036712\n",
      "Iteration=3384\t Loss=2.522604\t mu=9.951294\t sigma=1.103671\n",
      "Iteration=3385\t Loss=2.5226038\t mu=9.951366\t sigma=1.1036707\n",
      "Iteration=3386\t Loss=2.5226035\t mu=9.951439\t sigma=1.1036705\n",
      "Iteration=3387\t Loss=2.5226035\t mu=9.951511\t sigma=1.1036702\n",
      "Iteration=3388\t Loss=2.522603\t mu=9.951583\t sigma=1.10367\n",
      "Iteration=3389\t Loss=2.5226028\t mu=9.951654\t sigma=1.1036698\n",
      "Iteration=3390\t Loss=2.5226028\t mu=9.951726\t sigma=1.1036695\n",
      "Iteration=3391\t Loss=2.522603\t mu=9.9517975\t sigma=1.1036693\n",
      "Iteration=3392\t Loss=2.5226023\t mu=9.951869\t sigma=1.103669\n",
      "Iteration=3393\t Loss=2.5226023\t mu=9.95194\t sigma=1.1036688\n",
      "Iteration=3394\t Loss=2.5226018\t mu=9.95201\t sigma=1.1036686\n",
      "Iteration=3395\t Loss=2.5226018\t mu=9.952081\t sigma=1.1036683\n",
      "Iteration=3396\t Loss=2.5226016\t mu=9.952151\t sigma=1.1036681\n",
      "Iteration=3397\t Loss=2.5226011\t mu=9.952222\t sigma=1.1036679\n",
      "Iteration=3398\t Loss=2.5226014\t mu=9.9522915\t sigma=1.1036676\n",
      "Iteration=3399\t Loss=2.522601\t mu=9.952361\t sigma=1.1036674\n",
      "Iteration=3400\t Loss=2.5226007\t mu=9.952431\t sigma=1.1036671\n",
      "Iteration=3401\t Loss=2.5226004\t mu=9.9525\t sigma=1.1036669\n",
      "Iteration=3402\t Loss=2.5226004\t mu=9.95257\t sigma=1.1036667\n",
      "Iteration=3403\t Loss=2.5226\t mu=9.952639\t sigma=1.1036664\n",
      "Iteration=3404\t Loss=2.5226002\t mu=9.952707\t sigma=1.1036662\n",
      "Iteration=3405\t Loss=2.5226\t mu=9.952776\t sigma=1.103666\n",
      "Iteration=3406\t Loss=2.5225995\t mu=9.952845\t sigma=1.1036657\n",
      "Iteration=3407\t Loss=2.5225997\t mu=9.952913\t sigma=1.1036655\n",
      "Iteration=3408\t Loss=2.5225992\t mu=9.952981\t sigma=1.1036652\n",
      "Iteration=3409\t Loss=2.5225992\t mu=9.953049\t sigma=1.103665\n",
      "Iteration=3410\t Loss=2.522599\t mu=9.953116\t sigma=1.1036648\n",
      "Iteration=3411\t Loss=2.5225987\t mu=9.953184\t sigma=1.1036645\n",
      "Iteration=3412\t Loss=2.5225987\t mu=9.953252\t sigma=1.1036643\n",
      "Iteration=3413\t Loss=2.5225985\t mu=9.953319\t sigma=1.103664\n",
      "Iteration=3414\t Loss=2.522598\t mu=9.953385\t sigma=1.1036638\n",
      "Iteration=3415\t Loss=2.5225976\t mu=9.953452\t sigma=1.1036636\n",
      "Iteration=3416\t Loss=2.5225976\t mu=9.953519\t sigma=1.1036633\n",
      "Iteration=3417\t Loss=2.5225978\t mu=9.953586\t sigma=1.1036631\n",
      "Iteration=3418\t Loss=2.5225976\t mu=9.953651\t sigma=1.1036628\n",
      "Iteration=3419\t Loss=2.5225976\t mu=9.953717\t sigma=1.1036626\n",
      "Iteration=3420\t Loss=2.5225968\t mu=9.953783\t sigma=1.1036624\n",
      "Iteration=3421\t Loss=2.522597\t mu=9.953849\t sigma=1.1036621\n",
      "Iteration=3422\t Loss=2.5225968\t mu=9.953915\t sigma=1.1036619\n",
      "Iteration=3423\t Loss=2.5225966\t mu=9.9539795\t sigma=1.1036617\n",
      "Iteration=3424\t Loss=2.5225964\t mu=9.954044\t sigma=1.1036614\n",
      "Iteration=3425\t Loss=2.5225966\t mu=9.954109\t sigma=1.1036613\n",
      "Iteration=3426\t Loss=2.5225961\t mu=9.954174\t sigma=1.1036611\n",
      "Iteration=3427\t Loss=2.5225961\t mu=9.954239\t sigma=1.103661\n",
      "Iteration=3428\t Loss=2.5225954\t mu=9.954304\t sigma=1.1036607\n",
      "Iteration=3429\t Loss=2.5225954\t mu=9.954368\t sigma=1.1036606\n",
      "Iteration=3430\t Loss=2.5225956\t mu=9.954432\t sigma=1.1036605\n",
      "Iteration=3431\t Loss=2.5225954\t mu=9.954495\t sigma=1.1036602\n",
      "Iteration=3432\t Loss=2.5225954\t mu=9.954559\t sigma=1.1036601\n",
      "Iteration=3433\t Loss=2.522595\t mu=9.954623\t sigma=1.1036599\n",
      "Iteration=3434\t Loss=2.522595\t mu=9.954686\t sigma=1.1036597\n",
      "Iteration=3435\t Loss=2.5225947\t mu=9.954749\t sigma=1.1036596\n",
      "Iteration=3436\t Loss=2.5225945\t mu=9.954812\t sigma=1.1036595\n",
      "Iteration=3437\t Loss=2.5225945\t mu=9.954875\t sigma=1.1036593\n",
      "Iteration=3438\t Loss=2.5225942\t mu=9.954938\t sigma=1.103659\n",
      "Iteration=3439\t Loss=2.5225942\t mu=9.955001\t sigma=1.1036589\n",
      "Iteration=3440\t Loss=2.522594\t mu=9.955063\t sigma=1.1036587\n",
      "Iteration=3441\t Loss=2.5225937\t mu=9.955125\t sigma=1.1036586\n",
      "Iteration=3442\t Loss=2.5225935\t mu=9.955187\t sigma=1.1036584\n",
      "Iteration=3443\t Loss=2.5225933\t mu=9.955249\t sigma=1.1036583\n",
      "Iteration=3444\t Loss=2.5225933\t mu=9.955311\t sigma=1.1036582\n",
      "Iteration=3445\t Loss=2.5225933\t mu=9.955372\t sigma=1.103658\n",
      "Iteration=3446\t Loss=2.5225933\t mu=9.955433\t sigma=1.1036578\n",
      "Iteration=3447\t Loss=2.5225925\t mu=9.955494\t sigma=1.1036577\n",
      "Iteration=3448\t Loss=2.5225925\t mu=9.955555\t sigma=1.1036576\n",
      "Iteration=3449\t Loss=2.5225925\t mu=9.955616\t sigma=1.1036574\n",
      "Iteration=3450\t Loss=2.5225923\t mu=9.955677\t sigma=1.1036572\n",
      "Iteration=3451\t Loss=2.5225923\t mu=9.955737\t sigma=1.1036571\n",
      "Iteration=3452\t Loss=2.522592\t mu=9.955797\t sigma=1.103657\n",
      "Iteration=3453\t Loss=2.522592\t mu=9.955857\t sigma=1.1036569\n",
      "Iteration=3454\t Loss=2.5225916\t mu=9.955917\t sigma=1.1036566\n",
      "Iteration=3455\t Loss=2.5225916\t mu=9.955977\t sigma=1.1036565\n",
      "Iteration=3456\t Loss=2.5225916\t mu=9.9560375\t sigma=1.1036564\n",
      "Iteration=3457\t Loss=2.5225914\t mu=9.956097\t sigma=1.1036563\n",
      "Iteration=3458\t Loss=2.522591\t mu=9.956156\t sigma=1.1036562\n",
      "Iteration=3459\t Loss=2.522591\t mu=9.956215\t sigma=1.1036559\n",
      "Iteration=3460\t Loss=2.5225906\t mu=9.956274\t sigma=1.1036558\n",
      "Iteration=3461\t Loss=2.5225906\t mu=9.956333\t sigma=1.1036557\n",
      "Iteration=3462\t Loss=2.522591\t mu=9.956392\t sigma=1.1036556\n",
      "Iteration=3463\t Loss=2.5225906\t mu=9.95645\t sigma=1.1036555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=3464\t Loss=2.5225904\t mu=9.956509\t sigma=1.1036552\n",
      "Iteration=3465\t Loss=2.5225902\t mu=9.956567\t sigma=1.1036551\n",
      "Iteration=3466\t Loss=2.5225902\t mu=9.956625\t sigma=1.103655\n",
      "Iteration=3467\t Loss=2.52259\t mu=9.956683\t sigma=1.1036549\n",
      "Iteration=3468\t Loss=2.52259\t mu=9.956741\t sigma=1.1036547\n",
      "Iteration=3469\t Loss=2.52259\t mu=9.956799\t sigma=1.1036545\n",
      "Iteration=3470\t Loss=2.5225897\t mu=9.956856\t sigma=1.1036544\n",
      "Iteration=3471\t Loss=2.5225894\t mu=9.956913\t sigma=1.1036543\n",
      "Iteration=3472\t Loss=2.5225894\t mu=9.95697\t sigma=1.1036541\n",
      "Iteration=3473\t Loss=2.5225892\t mu=9.957027\t sigma=1.103654\n",
      "Iteration=3474\t Loss=2.522589\t mu=9.957085\t sigma=1.1036539\n",
      "Iteration=3475\t Loss=2.522589\t mu=9.957141\t sigma=1.1036538\n",
      "Iteration=3476\t Loss=2.522589\t mu=9.957197\t sigma=1.1036537\n",
      "Iteration=3477\t Loss=2.522589\t mu=9.957253\t sigma=1.1036536\n",
      "Iteration=3478\t Loss=2.5225883\t mu=9.95731\t sigma=1.1036534\n",
      "Iteration=3479\t Loss=2.522588\t mu=9.957366\t sigma=1.1036533\n",
      "Iteration=3480\t Loss=2.5225883\t mu=9.957422\t sigma=1.1036532\n",
      "Iteration=3481\t Loss=2.5225878\t mu=9.957478\t sigma=1.1036531\n",
      "Iteration=3482\t Loss=2.522588\t mu=9.957533\t sigma=1.103653\n",
      "Iteration=3483\t Loss=2.5225878\t mu=9.957588\t sigma=1.1036528\n",
      "Iteration=3484\t Loss=2.5225878\t mu=9.9576435\t sigma=1.1036527\n",
      "Iteration=3485\t Loss=2.5225878\t mu=9.957699\t sigma=1.1036526\n",
      "Iteration=3486\t Loss=2.5225878\t mu=9.957754\t sigma=1.1036525\n",
      "Iteration=3487\t Loss=2.5225873\t mu=9.9578085\t sigma=1.1036524\n",
      "Iteration=3488\t Loss=2.5225873\t mu=9.957863\t sigma=1.1036522\n",
      "Iteration=3489\t Loss=2.522587\t mu=9.957917\t sigma=1.1036521\n",
      "Iteration=3490\t Loss=2.522587\t mu=9.957972\t sigma=1.103652\n",
      "Iteration=3491\t Loss=2.522587\t mu=9.958026\t sigma=1.1036519\n",
      "Iteration=3492\t Loss=2.5225868\t mu=9.95808\t sigma=1.1036518\n",
      "Iteration=3493\t Loss=2.5225868\t mu=9.958134\t sigma=1.1036516\n",
      "Iteration=3494\t Loss=2.5225866\t mu=9.958187\t sigma=1.1036515\n",
      "Iteration=3495\t Loss=2.5225863\t mu=9.9582405\t sigma=1.1036514\n",
      "Iteration=3496\t Loss=2.5225859\t mu=9.958294\t sigma=1.1036513\n",
      "Iteration=3497\t Loss=2.522586\t mu=9.958347\t sigma=1.1036512\n",
      "Iteration=3498\t Loss=2.5225863\t mu=9.958401\t sigma=1.103651\n",
      "Iteration=3499\t Loss=2.522586\t mu=9.958454\t sigma=1.1036509\n",
      "Iteration=3500\t Loss=2.5225859\t mu=9.958507\t sigma=1.1036508\n",
      "Iteration=3501\t Loss=2.5225856\t mu=9.958559\t sigma=1.1036507\n",
      "Iteration=3502\t Loss=2.5225856\t mu=9.9586115\t sigma=1.1036506\n",
      "Iteration=3503\t Loss=2.5225856\t mu=9.958664\t sigma=1.1036505\n",
      "Iteration=3504\t Loss=2.5225854\t mu=9.958716\t sigma=1.1036503\n",
      "Iteration=3505\t Loss=2.5225854\t mu=9.958769\t sigma=1.1036502\n",
      "Iteration=3506\t Loss=2.5225854\t mu=9.95882\t sigma=1.1036501\n",
      "Iteration=3507\t Loss=2.5225852\t mu=9.958872\t sigma=1.10365\n",
      "Iteration=3508\t Loss=2.5225847\t mu=9.958923\t sigma=1.1036499\n",
      "Iteration=3509\t Loss=2.5225847\t mu=9.958975\t sigma=1.1036497\n",
      "Iteration=3510\t Loss=2.522585\t mu=9.959026\t sigma=1.1036496\n",
      "Iteration=3511\t Loss=2.522585\t mu=9.959078\t sigma=1.1036495\n",
      "Iteration=3512\t Loss=2.5225847\t mu=9.959129\t sigma=1.1036494\n",
      "Iteration=3513\t Loss=2.5225844\t mu=9.95918\t sigma=1.1036493\n",
      "Iteration=3514\t Loss=2.5225844\t mu=9.95923\t sigma=1.1036491\n",
      "Iteration=3515\t Loss=2.5225847\t mu=9.959281\t sigma=1.103649\n",
      "Iteration=3516\t Loss=2.5225847\t mu=9.9593315\t sigma=1.1036489\n",
      "Iteration=3517\t Loss=2.522584\t mu=9.959382\t sigma=1.1036488\n",
      "Iteration=3518\t Loss=2.522584\t mu=9.959433\t sigma=1.1036487\n",
      "Iteration=3519\t Loss=2.522584\t mu=9.959483\t sigma=1.1036485\n",
      "Iteration=3520\t Loss=2.522584\t mu=9.959533\t sigma=1.1036484\n",
      "Iteration=3521\t Loss=2.5225835\t mu=9.959582\t sigma=1.1036483\n",
      "Iteration=3522\t Loss=2.522584\t mu=9.959632\t sigma=1.1036482\n",
      "Iteration=3523\t Loss=2.5225837\t mu=9.9596815\t sigma=1.1036481\n",
      "Iteration=3524\t Loss=2.5225837\t mu=9.959731\t sigma=1.103648\n",
      "Iteration=3525\t Loss=2.5225835\t mu=9.959781\t sigma=1.1036478\n",
      "Iteration=3526\t Loss=2.5225835\t mu=9.95983\t sigma=1.1036477\n",
      "Iteration=3527\t Loss=2.5225832\t mu=9.959879\t sigma=1.1036476\n",
      "Iteration=3528\t Loss=2.5225832\t mu=9.959928\t sigma=1.1036475\n",
      "Iteration=3529\t Loss=2.522583\t mu=9.959976\t sigma=1.1036474\n",
      "Iteration=3530\t Loss=2.522583\t mu=9.960025\t sigma=1.1036472\n",
      "Iteration=3531\t Loss=2.5225828\t mu=9.960073\t sigma=1.1036471\n",
      "Iteration=3532\t Loss=2.5225825\t mu=9.960122\t sigma=1.103647\n",
      "Iteration=3533\t Loss=2.5225825\t mu=9.960171\t sigma=1.1036469\n",
      "Iteration=3534\t Loss=2.5225825\t mu=9.960218\t sigma=1.1036468\n",
      "Iteration=3535\t Loss=2.5225823\t mu=9.960266\t sigma=1.1036466\n",
      "Iteration=3536\t Loss=2.5225825\t mu=9.960314\t sigma=1.1036465\n",
      "Iteration=3537\t Loss=2.522582\t mu=9.9603615\t sigma=1.1036464\n",
      "Iteration=3538\t Loss=2.522582\t mu=9.960409\t sigma=1.1036463\n",
      "Iteration=3539\t Loss=2.522582\t mu=9.960457\t sigma=1.1036462\n",
      "Iteration=3540\t Loss=2.522582\t mu=9.960505\t sigma=1.103646\n",
      "Iteration=3541\t Loss=2.522582\t mu=9.960551\t sigma=1.1036459\n",
      "Iteration=3542\t Loss=2.5225818\t mu=9.960598\t sigma=1.1036458\n",
      "Iteration=3543\t Loss=2.5225816\t mu=9.960645\t sigma=1.1036457\n",
      "Iteration=3544\t Loss=2.5225816\t mu=9.960691\t sigma=1.1036456\n",
      "Iteration=3545\t Loss=2.5225816\t mu=9.960738\t sigma=1.1036454\n",
      "Iteration=3546\t Loss=2.5225813\t mu=9.960785\t sigma=1.1036453\n",
      "Iteration=3547\t Loss=2.5225813\t mu=9.960832\t sigma=1.1036452\n",
      "Iteration=3548\t Loss=2.5225813\t mu=9.960878\t sigma=1.1036451\n",
      "Iteration=3549\t Loss=2.5225813\t mu=9.960924\t sigma=1.103645\n",
      "Iteration=3550\t Loss=2.5225813\t mu=9.96097\t sigma=1.1036448\n",
      "Iteration=3551\t Loss=2.5225809\t mu=9.961016\t sigma=1.1036447\n",
      "Iteration=3552\t Loss=2.5225809\t mu=9.9610615\t sigma=1.1036446\n",
      "Iteration=3553\t Loss=2.5225809\t mu=9.961107\t sigma=1.1036445\n",
      "Iteration=3554\t Loss=2.5225809\t mu=9.961153\t sigma=1.1036444\n",
      "Iteration=3555\t Loss=2.5225806\t mu=9.961199\t sigma=1.1036443\n",
      "Iteration=3556\t Loss=2.5225806\t mu=9.961244\t sigma=1.1036441\n",
      "Iteration=3557\t Loss=2.5225804\t mu=9.961288\t sigma=1.103644\n",
      "Iteration=3558\t Loss=2.5225804\t mu=9.961333\t sigma=1.1036439\n",
      "Iteration=3559\t Loss=2.5225804\t mu=9.961378\t sigma=1.1036438\n",
      "Iteration=3560\t Loss=2.5225804\t mu=9.961423\t sigma=1.1036437\n",
      "Iteration=3561\t Loss=2.5225801\t mu=9.961468\t sigma=1.1036435\n",
      "Iteration=3562\t Loss=2.5225801\t mu=9.961513\t sigma=1.1036434\n",
      "Iteration=3563\t Loss=2.5225804\t mu=9.961557\t sigma=1.1036433\n",
      "Iteration=3564\t Loss=2.5225801\t mu=9.961601\t sigma=1.1036432\n",
      "Iteration=3565\t Loss=2.5225797\t mu=9.961645\t sigma=1.1036431\n",
      "Iteration=3566\t Loss=2.52258\t mu=9.961689\t sigma=1.103643\n",
      "Iteration=3567\t Loss=2.52258\t mu=9.961733\t sigma=1.1036428\n",
      "Iteration=3568\t Loss=2.5225797\t mu=9.961777\t sigma=1.1036427\n",
      "Iteration=3569\t Loss=2.5225797\t mu=9.961821\t sigma=1.1036426\n",
      "Iteration=3570\t Loss=2.5225792\t mu=9.961864\t sigma=1.1036425\n",
      "Iteration=3571\t Loss=2.5225794\t mu=9.961908\t sigma=1.1036423\n",
      "Iteration=3572\t Loss=2.5225794\t mu=9.961951\t sigma=1.1036422\n",
      "Iteration=3573\t Loss=2.5225792\t mu=9.961994\t sigma=1.1036421\n",
      "Iteration=3574\t Loss=2.5225792\t mu=9.962037\t sigma=1.103642\n",
      "Iteration=3575\t Loss=2.522579\t mu=9.96208\t sigma=1.1036419\n",
      "Iteration=3576\t Loss=2.522579\t mu=9.962123\t sigma=1.1036417\n",
      "Iteration=3577\t Loss=2.5225787\t mu=9.962166\t sigma=1.1036416\n",
      "Iteration=3578\t Loss=2.522579\t mu=9.962209\t sigma=1.1036415\n",
      "Iteration=3579\t Loss=2.5225792\t mu=9.962252\t sigma=1.1036414\n",
      "Iteration=3580\t Loss=2.522579\t mu=9.962294\t sigma=1.1036413\n",
      "Iteration=3581\t Loss=2.5225787\t mu=9.962336\t sigma=1.1036413\n",
      "Iteration=3582\t Loss=2.5225785\t mu=9.962378\t sigma=1.1036413\n",
      "Iteration=3583\t Loss=2.5225787\t mu=9.9624195\t sigma=1.1036412\n",
      "Iteration=3584\t Loss=2.5225785\t mu=9.962461\t sigma=1.103641\n",
      "Iteration=3585\t Loss=2.5225785\t mu=9.962503\t sigma=1.103641\n",
      "Iteration=3586\t Loss=2.5225782\t mu=9.962545\t sigma=1.103641\n",
      "Iteration=3587\t Loss=2.5225782\t mu=9.962587\t sigma=1.1036409\n",
      "Iteration=3588\t Loss=2.5225782\t mu=9.962628\t sigma=1.1036408\n",
      "Iteration=3589\t Loss=2.5225782\t mu=9.962669\t sigma=1.1036407\n",
      "Iteration=3590\t Loss=2.522578\t mu=9.96271\t sigma=1.1036407\n",
      "Iteration=3591\t Loss=2.522578\t mu=9.962751\t sigma=1.1036406\n",
      "Iteration=3592\t Loss=2.5225782\t mu=9.962792\t sigma=1.1036406\n",
      "Iteration=3593\t Loss=2.5225782\t mu=9.962833\t sigma=1.1036404\n",
      "Iteration=3594\t Loss=2.522578\t mu=9.962874\t sigma=1.1036404\n",
      "Iteration=3595\t Loss=2.5225778\t mu=9.962915\t sigma=1.1036403\n",
      "Iteration=3596\t Loss=2.5225775\t mu=9.962956\t sigma=1.1036403\n",
      "Iteration=3597\t Loss=2.5225775\t mu=9.9629965\t sigma=1.1036403\n",
      "Iteration=3598\t Loss=2.5225775\t mu=9.963037\t sigma=1.1036402\n",
      "Iteration=3599\t Loss=2.5225775\t mu=9.963077\t sigma=1.1036401\n",
      "Iteration=3600\t Loss=2.5225775\t mu=9.963117\t sigma=1.10364\n",
      "Iteration=3601\t Loss=2.5225773\t mu=9.963157\t sigma=1.10364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=3602\t Loss=2.522577\t mu=9.963197\t sigma=1.1036398\n",
      "Iteration=3603\t Loss=2.522577\t mu=9.963237\t sigma=1.1036397\n",
      "Iteration=3604\t Loss=2.522577\t mu=9.963277\t sigma=1.1036397\n",
      "Iteration=3605\t Loss=2.522577\t mu=9.963316\t sigma=1.1036397\n",
      "Iteration=3606\t Loss=2.522577\t mu=9.963355\t sigma=1.1036396\n",
      "Iteration=3607\t Loss=2.5225768\t mu=9.963394\t sigma=1.1036395\n",
      "Iteration=3608\t Loss=2.5225766\t mu=9.963433\t sigma=1.1036394\n",
      "Iteration=3609\t Loss=2.5225766\t mu=9.963472\t sigma=1.1036394\n",
      "Iteration=3610\t Loss=2.5225766\t mu=9.963511\t sigma=1.1036394\n",
      "Iteration=3611\t Loss=2.522577\t mu=9.963551\t sigma=1.1036394\n",
      "Iteration=3612\t Loss=2.5225768\t mu=9.96359\t sigma=1.1036392\n",
      "Iteration=3613\t Loss=2.5225766\t mu=9.963629\t sigma=1.1036391\n",
      "Iteration=3614\t Loss=2.5225766\t mu=9.963667\t sigma=1.1036391\n",
      "Iteration=3615\t Loss=2.5225766\t mu=9.963705\t sigma=1.103639\n",
      "Iteration=3616\t Loss=2.5225766\t mu=9.963743\t sigma=1.1036389\n",
      "Iteration=3617\t Loss=2.5225766\t mu=9.963781\t sigma=1.1036389\n",
      "Iteration=3618\t Loss=2.522576\t mu=9.9638195\t sigma=1.1036389\n",
      "Iteration=3619\t Loss=2.5225763\t mu=9.963858\t sigma=1.1036389\n",
      "Iteration=3620\t Loss=2.522576\t mu=9.963896\t sigma=1.1036388\n",
      "Iteration=3621\t Loss=2.522576\t mu=9.963934\t sigma=1.1036388\n",
      "Iteration=3622\t Loss=2.5225756\t mu=9.963972\t sigma=1.1036386\n",
      "Iteration=3623\t Loss=2.522576\t mu=9.964009\t sigma=1.1036386\n",
      "Iteration=3624\t Loss=2.522576\t mu=9.9640465\t sigma=1.1036385\n",
      "Iteration=3625\t Loss=2.5225759\t mu=9.964084\t sigma=1.1036385\n",
      "Iteration=3626\t Loss=2.5225759\t mu=9.964121\t sigma=1.1036385\n",
      "Iteration=3627\t Loss=2.5225759\t mu=9.964158\t sigma=1.1036384\n",
      "Iteration=3628\t Loss=2.522576\t mu=9.964195\t sigma=1.1036384\n",
      "Iteration=3629\t Loss=2.5225756\t mu=9.964232\t sigma=1.1036383\n",
      "Iteration=3630\t Loss=2.5225759\t mu=9.96427\t sigma=1.1036382\n",
      "Iteration=3631\t Loss=2.5225756\t mu=9.964307\t sigma=1.1036382\n",
      "Iteration=3632\t Loss=2.5225754\t mu=9.964344\t sigma=1.1036382\n",
      "Iteration=3633\t Loss=2.5225754\t mu=9.96438\t sigma=1.103638\n",
      "Iteration=3634\t Loss=2.5225756\t mu=9.9644165\t sigma=1.1036379\n",
      "Iteration=3635\t Loss=2.5225754\t mu=9.964453\t sigma=1.1036379\n",
      "Iteration=3636\t Loss=2.5225754\t mu=9.964489\t sigma=1.1036379\n",
      "Iteration=3637\t Loss=2.5225754\t mu=9.964525\t sigma=1.1036379\n",
      "Iteration=3638\t Loss=2.5225756\t mu=9.964561\t sigma=1.1036379\n",
      "Iteration=3639\t Loss=2.5225754\t mu=9.964598\t sigma=1.1036378\n",
      "Iteration=3640\t Loss=2.522575\t mu=9.964634\t sigma=1.1036378\n",
      "Iteration=3641\t Loss=2.522575\t mu=9.96467\t sigma=1.1036377\n",
      "Iteration=3642\t Loss=2.522575\t mu=9.964705\t sigma=1.1036376\n",
      "Iteration=3643\t Loss=2.522575\t mu=9.964741\t sigma=1.1036375\n",
      "Iteration=3644\t Loss=2.522575\t mu=9.964776\t sigma=1.1036375\n",
      "Iteration=3645\t Loss=2.5225751\t mu=9.964811\t sigma=1.1036375\n",
      "Iteration=3646\t Loss=2.522575\t mu=9.964847\t sigma=1.1036375\n",
      "Iteration=3647\t Loss=2.5225747\t mu=9.964882\t sigma=1.1036373\n",
      "Iteration=3648\t Loss=2.522575\t mu=9.964917\t sigma=1.1036372\n",
      "Iteration=3649\t Loss=2.5225747\t mu=9.964952\t sigma=1.1036372\n",
      "Iteration=3650\t Loss=2.5225747\t mu=9.964988\t sigma=1.1036372\n",
      "Iteration=3651\t Loss=2.5225744\t mu=9.965023\t sigma=1.1036372\n",
      "Iteration=3652\t Loss=2.5225747\t mu=9.965057\t sigma=1.1036372\n",
      "Iteration=3653\t Loss=2.5225744\t mu=9.965092\t sigma=1.1036371\n",
      "Iteration=3654\t Loss=2.5225742\t mu=9.965126\t sigma=1.103637\n",
      "Iteration=3655\t Loss=2.5225744\t mu=9.96516\t sigma=1.103637\n",
      "Iteration=3656\t Loss=2.5225742\t mu=9.965195\t sigma=1.1036369\n",
      "Iteration=3657\t Loss=2.5225742\t mu=9.965229\t sigma=1.1036369\n",
      "Iteration=3658\t Loss=2.5225744\t mu=9.965263\t sigma=1.1036369\n",
      "Iteration=3659\t Loss=2.5225742\t mu=9.965298\t sigma=1.1036369\n",
      "Iteration=3660\t Loss=2.5225744\t mu=9.965332\t sigma=1.1036367\n",
      "Iteration=3661\t Loss=2.5225742\t mu=9.965366\t sigma=1.1036367\n",
      "Iteration=3662\t Loss=2.5225737\t mu=9.9654\t sigma=1.1036366\n",
      "Iteration=3663\t Loss=2.5225737\t mu=9.965433\t sigma=1.1036365\n",
      "Iteration=3664\t Loss=2.522574\t mu=9.9654665\t sigma=1.1036365\n",
      "Iteration=3665\t Loss=2.5225737\t mu=9.9655\t sigma=1.1036365\n",
      "Iteration=3666\t Loss=2.5225737\t mu=9.965533\t sigma=1.1036365\n",
      "Iteration=3667\t Loss=2.5225735\t mu=9.965567\t sigma=1.1036365\n",
      "Iteration=3668\t Loss=2.5225737\t mu=9.9656\t sigma=1.1036364\n",
      "Iteration=3669\t Loss=2.5225735\t mu=9.965633\t sigma=1.1036363\n",
      "Iteration=3670\t Loss=2.5225737\t mu=9.965667\t sigma=1.1036363\n",
      "Iteration=3671\t Loss=2.5225737\t mu=9.9657\t sigma=1.1036363\n",
      "Iteration=3672\t Loss=2.5225732\t mu=9.965734\t sigma=1.1036363\n",
      "Iteration=3673\t Loss=2.5225737\t mu=9.965766\t sigma=1.1036361\n",
      "Iteration=3674\t Loss=2.5225735\t mu=9.965798\t sigma=1.1036361\n",
      "Iteration=3675\t Loss=2.5225735\t mu=9.965831\t sigma=1.103636\n",
      "Iteration=3676\t Loss=2.5225735\t mu=9.965863\t sigma=1.103636\n",
      "Iteration=3677\t Loss=2.5225735\t mu=9.965896\t sigma=1.103636\n",
      "Iteration=3678\t Loss=2.5225732\t mu=9.965928\t sigma=1.1036359\n",
      "Iteration=3679\t Loss=2.5225735\t mu=9.9659605\t sigma=1.1036358\n",
      "Iteration=3680\t Loss=2.5225735\t mu=9.965993\t sigma=1.1036358\n",
      "Iteration=3681\t Loss=2.5225735\t mu=9.966025\t sigma=1.1036358\n",
      "Iteration=3682\t Loss=2.5225732\t mu=9.966058\t sigma=1.1036358\n",
      "Iteration=3683\t Loss=2.522573\t mu=9.966089\t sigma=1.1036357\n",
      "Iteration=3684\t Loss=2.522573\t mu=9.966121\t sigma=1.1036357\n",
      "Iteration=3685\t Loss=2.5225728\t mu=9.966152\t sigma=1.1036355\n",
      "Iteration=3686\t Loss=2.5225728\t mu=9.966184\t sigma=1.1036355\n",
      "Iteration=3687\t Loss=2.5225728\t mu=9.966215\t sigma=1.1036355\n",
      "Iteration=3688\t Loss=2.5225728\t mu=9.966247\t sigma=1.1036355\n",
      "Iteration=3689\t Loss=2.522573\t mu=9.966278\t sigma=1.1036355\n",
      "Iteration=3690\t Loss=2.5225728\t mu=9.96631\t sigma=1.1036355\n",
      "Iteration=3691\t Loss=2.5225728\t mu=9.966341\t sigma=1.1036355\n",
      "Iteration=3692\t Loss=2.5225728\t mu=9.9663725\t sigma=1.1036354\n",
      "Iteration=3693\t Loss=2.5225728\t mu=9.966404\t sigma=1.1036353\n",
      "Iteration=3694\t Loss=2.522573\t mu=9.9664345\t sigma=1.1036353\n",
      "Iteration=3695\t Loss=2.5225725\t mu=9.966465\t sigma=1.1036352\n",
      "Iteration=3696\t Loss=2.5225728\t mu=9.9664955\t sigma=1.1036352\n",
      "Iteration=3697\t Loss=2.5225725\t mu=9.966526\t sigma=1.1036351\n",
      "Iteration=3698\t Loss=2.5225725\t mu=9.966557\t sigma=1.1036351\n",
      "Iteration=3699\t Loss=2.5225725\t mu=9.966587\t sigma=1.1036351\n",
      "Iteration=3700\t Loss=2.5225728\t mu=9.966618\t sigma=1.1036351\n",
      "Iteration=3701\t Loss=2.5225723\t mu=9.966648\t sigma=1.1036351\n",
      "Iteration=3702\t Loss=2.522572\t mu=9.966679\t sigma=1.103635\n",
      "Iteration=3703\t Loss=2.522572\t mu=9.966709\t sigma=1.103635\n",
      "Iteration=3704\t Loss=2.5225723\t mu=9.96674\t sigma=1.1036348\n",
      "Iteration=3705\t Loss=2.5225725\t mu=9.96677\t sigma=1.1036348\n",
      "Iteration=3706\t Loss=2.5225723\t mu=9.9668\t sigma=1.1036348\n",
      "Iteration=3707\t Loss=2.5225723\t mu=9.966829\t sigma=1.1036347\n",
      "Iteration=3708\t Loss=2.522572\t mu=9.966859\t sigma=1.1036347\n",
      "Iteration=3709\t Loss=2.522572\t mu=9.966888\t sigma=1.1036347\n",
      "Iteration=3710\t Loss=2.522572\t mu=9.966918\t sigma=1.1036347\n",
      "Iteration=3711\t Loss=2.522572\t mu=9.966948\t sigma=1.1036347\n",
      "Iteration=3712\t Loss=2.522572\t mu=9.966977\t sigma=1.1036346\n",
      "Iteration=3713\t Loss=2.5225718\t mu=9.967007\t sigma=1.1036346\n",
      "Iteration=3714\t Loss=2.5225718\t mu=9.967036\t sigma=1.1036346\n",
      "Iteration=3715\t Loss=2.5225718\t mu=9.967066\t sigma=1.1036345\n",
      "Iteration=3716\t Loss=2.5225718\t mu=9.967095\t sigma=1.1036345\n",
      "Iteration=3717\t Loss=2.5225718\t mu=9.967124\t sigma=1.1036345\n",
      "Iteration=3718\t Loss=2.5225718\t mu=9.967153\t sigma=1.1036344\n",
      "Iteration=3719\t Loss=2.5225718\t mu=9.967181\t sigma=1.1036344\n",
      "Iteration=3720\t Loss=2.5225718\t mu=9.96721\t sigma=1.1036344\n",
      "Iteration=3721\t Loss=2.5225718\t mu=9.967238\t sigma=1.1036344\n",
      "Iteration=3722\t Loss=2.5225716\t mu=9.967267\t sigma=1.1036344\n",
      "Iteration=3723\t Loss=2.5225716\t mu=9.967296\t sigma=1.1036342\n",
      "Iteration=3724\t Loss=2.5225716\t mu=9.967324\t sigma=1.1036342\n",
      "Iteration=3725\t Loss=2.5225718\t mu=9.967353\t sigma=1.1036341\n",
      "Iteration=3726\t Loss=2.5225718\t mu=9.9673815\t sigma=1.1036341\n",
      "Iteration=3727\t Loss=2.5225716\t mu=9.96741\t sigma=1.1036341\n",
      "Iteration=3728\t Loss=2.5225716\t mu=9.967439\t sigma=1.1036341\n",
      "Iteration=3729\t Loss=2.5225716\t mu=9.967466\t sigma=1.1036341\n",
      "Iteration=3730\t Loss=2.5225716\t mu=9.967494\t sigma=1.103634\n",
      "Iteration=3731\t Loss=2.5225716\t mu=9.967522\t sigma=1.103634\n",
      "Iteration=3732\t Loss=2.5225716\t mu=9.967549\t sigma=1.103634\n",
      "Iteration=3733\t Loss=2.5225716\t mu=9.967577\t sigma=1.103634\n",
      "Iteration=3734\t Loss=2.5225713\t mu=9.967605\t sigma=1.103634\n",
      "Iteration=3735\t Loss=2.5225713\t mu=9.967632\t sigma=1.1036339\n",
      "Iteration=3736\t Loss=2.5225713\t mu=9.96766\t sigma=1.1036339\n",
      "Iteration=3737\t Loss=2.5225713\t mu=9.967688\t sigma=1.1036339\n",
      "Iteration=3738\t Loss=2.5225713\t mu=9.967715\t sigma=1.1036338\n",
      "Iteration=3739\t Loss=2.522571\t mu=9.967743\t sigma=1.1036338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=3740\t Loss=2.522571\t mu=9.967771\t sigma=1.1036338\n",
      "Iteration=3741\t Loss=2.522571\t mu=9.967798\t sigma=1.1036338\n",
      "Iteration=3742\t Loss=2.5225716\t mu=9.967825\t sigma=1.1036336\n",
      "Iteration=3743\t Loss=2.522571\t mu=9.967852\t sigma=1.1036336\n",
      "Iteration=3744\t Loss=2.5225713\t mu=9.967878\t sigma=1.1036336\n",
      "Iteration=3745\t Loss=2.5225713\t mu=9.967905\t sigma=1.1036336\n",
      "Iteration=3746\t Loss=2.522571\t mu=9.967932\t sigma=1.1036335\n",
      "Iteration=3747\t Loss=2.522571\t mu=9.967958\t sigma=1.1036335\n",
      "Iteration=3748\t Loss=2.522571\t mu=9.967985\t sigma=1.1036335\n",
      "Iteration=3749\t Loss=2.5225708\t mu=9.968012\t sigma=1.1036334\n",
      "Iteration=3750\t Loss=2.5225708\t mu=9.968039\t sigma=1.1036334\n",
      "Iteration=3751\t Loss=2.5225708\t mu=9.968065\t sigma=1.1036334\n",
      "Iteration=3752\t Loss=2.5225706\t mu=9.968092\t sigma=1.1036334\n",
      "Iteration=3753\t Loss=2.5225706\t mu=9.968119\t sigma=1.1036334\n",
      "Iteration=3754\t Loss=2.5225706\t mu=9.968145\t sigma=1.1036333\n",
      "Iteration=3755\t Loss=2.5225706\t mu=9.968171\t sigma=1.1036333\n",
      "Iteration=3756\t Loss=2.5225708\t mu=9.968197\t sigma=1.1036332\n",
      "Iteration=3757\t Loss=2.5225706\t mu=9.968223\t sigma=1.1036332\n",
      "Iteration=3758\t Loss=2.5225706\t mu=9.968248\t sigma=1.1036332\n",
      "Iteration=3759\t Loss=2.5225706\t mu=9.968274\t sigma=1.1036332\n",
      "Iteration=3760\t Loss=2.5225706\t mu=9.9683\t sigma=1.1036332\n",
      "Iteration=3761\t Loss=2.5225706\t mu=9.968326\t sigma=1.1036332\n",
      "Iteration=3762\t Loss=2.5225706\t mu=9.968351\t sigma=1.1036332\n",
      "Iteration=3763\t Loss=2.5225706\t mu=9.968377\t sigma=1.1036332\n",
      "Iteration=3764\t Loss=2.5225706\t mu=9.968403\t sigma=1.1036332\n",
      "Iteration=3765\t Loss=2.5225706\t mu=9.968429\t sigma=1.103633\n",
      "Iteration=3766\t Loss=2.5225706\t mu=9.968454\t sigma=1.103633\n",
      "Iteration=3767\t Loss=2.5225706\t mu=9.96848\t sigma=1.103633\n",
      "Iteration=3768\t Loss=2.5225704\t mu=9.968505\t sigma=1.103633\n",
      "Iteration=3769\t Loss=2.5225704\t mu=9.96853\t sigma=1.103633\n",
      "Iteration=3770\t Loss=2.5225704\t mu=9.9685545\t sigma=1.1036329\n",
      "Iteration=3771\t Loss=2.5225704\t mu=9.968579\t sigma=1.1036328\n",
      "Iteration=3772\t Loss=2.5225704\t mu=9.968604\t sigma=1.1036328\n",
      "Iteration=3773\t Loss=2.5225704\t mu=9.968629\t sigma=1.1036328\n",
      "Iteration=3774\t Loss=2.5225701\t mu=9.968654\t sigma=1.1036328\n",
      "Iteration=3775\t Loss=2.52257\t mu=9.968678\t sigma=1.1036328\n",
      "Iteration=3776\t Loss=2.52257\t mu=9.968703\t sigma=1.1036328\n",
      "Iteration=3777\t Loss=2.5225701\t mu=9.968728\t sigma=1.1036327\n",
      "Iteration=3778\t Loss=2.5225701\t mu=9.968753\t sigma=1.1036326\n",
      "Iteration=3779\t Loss=2.52257\t mu=9.968778\t sigma=1.1036326\n",
      "Iteration=3780\t Loss=2.5225701\t mu=9.968802\t sigma=1.1036326\n",
      "Iteration=3781\t Loss=2.5225701\t mu=9.968827\t sigma=1.1036326\n",
      "Iteration=3782\t Loss=2.5225701\t mu=9.968851\t sigma=1.1036326\n",
      "Iteration=3783\t Loss=2.52257\t mu=9.968875\t sigma=1.1036326\n",
      "Iteration=3784\t Loss=2.5225701\t mu=9.968899\t sigma=1.1036326\n",
      "Iteration=3785\t Loss=2.52257\t mu=9.968923\t sigma=1.1036326\n",
      "Iteration=3786\t Loss=2.52257\t mu=9.968946\t sigma=1.1036326\n",
      "Iteration=3787\t Loss=2.52257\t mu=9.96897\t sigma=1.1036326\n",
      "Iteration=3788\t Loss=2.5225704\t mu=9.968994\t sigma=1.1036325\n",
      "Iteration=3789\t Loss=2.5225697\t mu=9.969018\t sigma=1.1036323\n",
      "Iteration=3790\t Loss=2.52257\t mu=9.969042\t sigma=1.1036323\n",
      "Iteration=3791\t Loss=2.5225697\t mu=9.969066\t sigma=1.1036323\n",
      "Iteration=3792\t Loss=2.5225697\t mu=9.9690895\t sigma=1.1036323\n",
      "Iteration=3793\t Loss=2.5225697\t mu=9.969113\t sigma=1.1036323\n",
      "Iteration=3794\t Loss=2.52257\t mu=9.969137\t sigma=1.1036323\n",
      "Iteration=3795\t Loss=2.52257\t mu=9.969161\t sigma=1.1036322\n",
      "Iteration=3796\t Loss=2.5225697\t mu=9.969185\t sigma=1.1036322\n",
      "Iteration=3797\t Loss=2.5225697\t mu=9.969208\t sigma=1.1036322\n",
      "Iteration=3798\t Loss=2.5225697\t mu=9.969231\t sigma=1.1036322\n",
      "Iteration=3799\t Loss=2.5225694\t mu=9.969254\t sigma=1.1036322\n",
      "Iteration=3800\t Loss=2.5225697\t mu=9.969276\t sigma=1.1036322\n",
      "Iteration=3801\t Loss=2.5225697\t mu=9.969299\t sigma=1.1036321\n",
      "Iteration=3802\t Loss=2.5225694\t mu=9.969322\t sigma=1.1036321\n",
      "Iteration=3803\t Loss=2.5225694\t mu=9.969345\t sigma=1.1036321\n",
      "Iteration=3804\t Loss=2.5225697\t mu=9.969368\t sigma=1.1036321\n",
      "Iteration=3805\t Loss=2.5225697\t mu=9.969391\t sigma=1.1036321\n",
      "Iteration=3806\t Loss=2.5225694\t mu=9.969414\t sigma=1.1036321\n",
      "Iteration=3807\t Loss=2.5225694\t mu=9.969437\t sigma=1.1036321\n",
      "Iteration=3808\t Loss=2.5225694\t mu=9.96946\t sigma=1.1036321\n",
      "Iteration=3809\t Loss=2.5225694\t mu=9.969482\t sigma=1.1036321\n",
      "Iteration=3810\t Loss=2.5225694\t mu=9.969505\t sigma=1.1036321\n",
      "Iteration=3811\t Loss=2.5225694\t mu=9.969528\t sigma=1.1036321\n",
      "Iteration=3812\t Loss=2.5225694\t mu=9.96955\t sigma=1.103632\n",
      "Iteration=3813\t Loss=2.5225694\t mu=9.969572\t sigma=1.103632\n",
      "Iteration=3814\t Loss=2.5225694\t mu=9.969594\t sigma=1.1036319\n",
      "Iteration=3815\t Loss=2.5225694\t mu=9.969616\t sigma=1.1036319\n",
      "Iteration=3816\t Loss=2.5225694\t mu=9.969638\t sigma=1.1036319\n",
      "Iteration=3817\t Loss=2.5225694\t mu=9.96966\t sigma=1.1036317\n",
      "Iteration=3818\t Loss=2.5225694\t mu=9.969682\t sigma=1.1036317\n",
      "Iteration=3819\t Loss=2.5225694\t mu=9.969704\t sigma=1.1036317\n",
      "Iteration=3820\t Loss=2.5225692\t mu=9.969726\t sigma=1.1036317\n",
      "Iteration=3821\t Loss=2.5225692\t mu=9.969748\t sigma=1.1036317\n",
      "Iteration=3822\t Loss=2.5225694\t mu=9.9697695\t sigma=1.1036317\n",
      "Iteration=3823\t Loss=2.5225694\t mu=9.969791\t sigma=1.1036317\n",
      "Iteration=3824\t Loss=2.5225692\t mu=9.969813\t sigma=1.1036317\n",
      "Iteration=3825\t Loss=2.5225692\t mu=9.969835\t sigma=1.1036316\n",
      "Iteration=3826\t Loss=2.522569\t mu=9.969857\t sigma=1.1036316\n",
      "Iteration=3827\t Loss=2.5225694\t mu=9.969879\t sigma=1.1036316\n",
      "Iteration=3828\t Loss=2.5225694\t mu=9.9699\t sigma=1.1036316\n",
      "Iteration=3829\t Loss=2.5225692\t mu=9.969921\t sigma=1.1036316\n",
      "Iteration=3830\t Loss=2.5225692\t mu=9.969942\t sigma=1.1036316\n",
      "Iteration=3831\t Loss=2.5225692\t mu=9.969963\t sigma=1.1036316\n",
      "Iteration=3832\t Loss=2.522569\t mu=9.969984\t sigma=1.1036316\n",
      "Iteration=3833\t Loss=2.5225692\t mu=9.970005\t sigma=1.1036316\n",
      "Iteration=3834\t Loss=2.522569\t mu=9.970026\t sigma=1.1036315\n",
      "Iteration=3835\t Loss=2.5225687\t mu=9.970047\t sigma=1.1036315\n",
      "Iteration=3836\t Loss=2.5225687\t mu=9.970068\t sigma=1.1036315\n",
      "Iteration=3837\t Loss=2.5225687\t mu=9.970089\t sigma=1.1036315\n",
      "Iteration=3838\t Loss=2.5225687\t mu=9.97011\t sigma=1.1036315\n",
      "Iteration=3839\t Loss=2.5225687\t mu=9.970131\t sigma=1.1036315\n",
      "Iteration=3840\t Loss=2.5225687\t mu=9.970152\t sigma=1.1036315\n",
      "Iteration=3841\t Loss=2.5225687\t mu=9.970173\t sigma=1.1036314\n",
      "Iteration=3842\t Loss=2.5225685\t mu=9.970194\t sigma=1.1036314\n",
      "Iteration=3843\t Loss=2.5225685\t mu=9.970215\t sigma=1.1036314\n",
      "Iteration=3844\t Loss=2.522569\t mu=9.970235\t sigma=1.1036313\n",
      "Iteration=3845\t Loss=2.522569\t mu=9.970255\t sigma=1.1036313\n",
      "Iteration=3846\t Loss=2.522569\t mu=9.970275\t sigma=1.1036313\n",
      "Iteration=3847\t Loss=2.5225692\t mu=9.970295\t sigma=1.1036313\n",
      "Iteration=3848\t Loss=2.522569\t mu=9.970315\t sigma=1.1036313\n",
      "Iteration=3849\t Loss=2.5225692\t mu=9.970335\t sigma=1.1036313\n",
      "Iteration=3850\t Loss=2.5225687\t mu=9.970355\t sigma=1.1036313\n",
      "Iteration=3851\t Loss=2.5225692\t mu=9.970375\t sigma=1.1036313\n",
      "Iteration=3852\t Loss=2.5225685\t mu=9.970395\t sigma=1.1036311\n",
      "Iteration=3853\t Loss=2.5225687\t mu=9.970415\t sigma=1.1036311\n",
      "Iteration=3854\t Loss=2.5225687\t mu=9.970435\t sigma=1.1036311\n",
      "Iteration=3855\t Loss=2.5225687\t mu=9.970455\t sigma=1.1036311\n",
      "Iteration=3856\t Loss=2.5225687\t mu=9.970475\t sigma=1.1036311\n",
      "Iteration=3857\t Loss=2.5225685\t mu=9.970495\t sigma=1.1036311\n",
      "Iteration=3858\t Loss=2.5225685\t mu=9.970515\t sigma=1.1036311\n",
      "Iteration=3859\t Loss=2.5225687\t mu=9.970535\t sigma=1.1036311\n",
      "Iteration=3860\t Loss=2.5225687\t mu=9.970555\t sigma=1.1036311\n",
      "Iteration=3861\t Loss=2.5225685\t mu=9.970575\t sigma=1.1036311\n",
      "Iteration=3862\t Loss=2.5225685\t mu=9.970594\t sigma=1.1036311\n",
      "Iteration=3863\t Loss=2.5225682\t mu=9.9706135\t sigma=1.103631\n",
      "Iteration=3864\t Loss=2.5225685\t mu=9.970633\t sigma=1.103631\n",
      "Iteration=3865\t Loss=2.5225685\t mu=9.970652\t sigma=1.103631\n",
      "Iteration=3866\t Loss=2.5225682\t mu=9.970671\t sigma=1.103631\n",
      "Iteration=3867\t Loss=2.5225685\t mu=9.97069\t sigma=1.103631\n",
      "Iteration=3868\t Loss=2.5225685\t mu=9.970709\t sigma=1.1036309\n",
      "Iteration=3869\t Loss=2.5225682\t mu=9.970728\t sigma=1.1036309\n",
      "Iteration=3870\t Loss=2.522568\t mu=9.970747\t sigma=1.1036309\n",
      "Iteration=3871\t Loss=2.5225685\t mu=9.970766\t sigma=1.1036309\n",
      "Iteration=3872\t Loss=2.5225685\t mu=9.970785\t sigma=1.1036308\n",
      "Iteration=3873\t Loss=2.5225685\t mu=9.970804\t sigma=1.1036308\n",
      "Iteration=3874\t Loss=2.5225685\t mu=9.970823\t sigma=1.1036308\n",
      "Iteration=3875\t Loss=2.5225685\t mu=9.970842\t sigma=1.1036308\n",
      "Iteration=3876\t Loss=2.5225685\t mu=9.970861\t sigma=1.1036308\n",
      "Iteration=3877\t Loss=2.5225685\t mu=9.9708805\t sigma=1.1036308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=3878\t Loss=2.5225685\t mu=9.9709\t sigma=1.1036308\n",
      "Iteration=3879\t Loss=2.5225685\t mu=9.970919\t sigma=1.1036308\n",
      "Iteration=3880\t Loss=2.5225685\t mu=9.970937\t sigma=1.1036308\n",
      "Iteration=3881\t Loss=2.5225685\t mu=9.970955\t sigma=1.1036308\n",
      "Iteration=3882\t Loss=2.5225682\t mu=9.970973\t sigma=1.1036308\n",
      "Iteration=3883\t Loss=2.5225682\t mu=9.970991\t sigma=1.1036308\n",
      "Iteration=3884\t Loss=2.5225685\t mu=9.971009\t sigma=1.1036307\n",
      "Iteration=3885\t Loss=2.5225682\t mu=9.971027\t sigma=1.1036307\n",
      "Iteration=3886\t Loss=2.5225685\t mu=9.9710455\t sigma=1.1036307\n",
      "Iteration=3887\t Loss=2.5225682\t mu=9.971064\t sigma=1.1036307\n",
      "Iteration=3888\t Loss=2.5225682\t mu=9.971082\t sigma=1.1036307\n",
      "Iteration=3889\t Loss=2.5225682\t mu=9.9711\t sigma=1.1036307\n",
      "Iteration=3890\t Loss=2.5225682\t mu=9.971118\t sigma=1.1036307\n",
      "Iteration=3891\t Loss=2.522568\t mu=9.971136\t sigma=1.1036307\n",
      "Iteration=3892\t Loss=2.522568\t mu=9.971154\t sigma=1.1036307\n",
      "Iteration=3893\t Loss=2.522568\t mu=9.971172\t sigma=1.1036307\n",
      "Iteration=3894\t Loss=2.522568\t mu=9.97119\t sigma=1.1036307\n",
      "Iteration=3895\t Loss=2.5225685\t mu=9.971209\t sigma=1.1036307\n",
      "Iteration=3896\t Loss=2.5225682\t mu=9.971227\t sigma=1.1036305\n",
      "Iteration=3897\t Loss=2.522568\t mu=9.971245\t sigma=1.1036305\n",
      "Iteration=3898\t Loss=2.522568\t mu=9.971263\t sigma=1.1036305\n",
      "Iteration=3899\t Loss=2.5225682\t mu=9.97128\t sigma=1.1036305\n",
      "Iteration=3900\t Loss=2.5225682\t mu=9.971297\t sigma=1.1036305\n",
      "Iteration=3901\t Loss=2.5225682\t mu=9.971314\t sigma=1.1036305\n",
      "Iteration=3902\t Loss=2.522568\t mu=9.971332\t sigma=1.1036305\n",
      "Iteration=3903\t Loss=2.5225677\t mu=9.971349\t sigma=1.1036305\n",
      "Iteration=3904\t Loss=2.522568\t mu=9.971366\t sigma=1.1036305\n",
      "Iteration=3905\t Loss=2.522568\t mu=9.971383\t sigma=1.1036305\n",
      "Iteration=3906\t Loss=2.522568\t mu=9.9714\t sigma=1.1036305\n",
      "Iteration=3907\t Loss=2.5225677\t mu=9.971417\t sigma=1.1036304\n",
      "Iteration=3908\t Loss=2.522568\t mu=9.971435\t sigma=1.1036304\n",
      "Iteration=3909\t Loss=2.522568\t mu=9.971452\t sigma=1.1036304\n",
      "Iteration=3910\t Loss=2.5225682\t mu=9.971469\t sigma=1.1036304\n",
      "Iteration=3911\t Loss=2.522568\t mu=9.971486\t sigma=1.1036304\n",
      "Iteration=3912\t Loss=2.522568\t mu=9.971503\t sigma=1.1036304\n",
      "Iteration=3913\t Loss=2.522568\t mu=9.97152\t sigma=1.1036304\n",
      "Iteration=3914\t Loss=2.5225677\t mu=9.971538\t sigma=1.1036304\n",
      "Iteration=3915\t Loss=2.5225677\t mu=9.971555\t sigma=1.1036304\n",
      "Iteration=3916\t Loss=2.5225677\t mu=9.971572\t sigma=1.1036303\n",
      "Iteration=3917\t Loss=2.5225677\t mu=9.971589\t sigma=1.1036303\n",
      "Iteration=3918\t Loss=2.5225675\t mu=9.971606\t sigma=1.1036303\n",
      "Iteration=3919\t Loss=2.5225675\t mu=9.971622\t sigma=1.1036303\n",
      "Iteration=3920\t Loss=2.5225675\t mu=9.971639\t sigma=1.1036303\n",
      "Iteration=3921\t Loss=2.522568\t mu=9.971655\t sigma=1.1036303\n",
      "Iteration=3922\t Loss=2.522568\t mu=9.971671\t sigma=1.1036303\n",
      "Iteration=3923\t Loss=2.5225675\t mu=9.971687\t sigma=1.1036303\n",
      "Iteration=3924\t Loss=2.522568\t mu=9.971704\t sigma=1.1036303\n",
      "Iteration=3925\t Loss=2.522568\t mu=9.97172\t sigma=1.1036302\n",
      "Iteration=3926\t Loss=2.5225677\t mu=9.971736\t sigma=1.1036302\n",
      "Iteration=3927\t Loss=2.5225677\t mu=9.971752\t sigma=1.1036302\n",
      "Iteration=3928\t Loss=2.5225677\t mu=9.971768\t sigma=1.1036302\n",
      "Iteration=3929\t Loss=2.5225677\t mu=9.971785\t sigma=1.1036302\n",
      "Iteration=3930\t Loss=2.5225677\t mu=9.971801\t sigma=1.1036302\n",
      "Iteration=3931\t Loss=2.5225675\t mu=9.971817\t sigma=1.1036302\n",
      "Iteration=3932\t Loss=2.5225675\t mu=9.971833\t sigma=1.1036302\n",
      "Iteration=3933\t Loss=2.5225677\t mu=9.971849\t sigma=1.1036301\n",
      "Iteration=3934\t Loss=2.5225675\t mu=9.971866\t sigma=1.1036301\n",
      "Iteration=3935\t Loss=2.5225677\t mu=9.971882\t sigma=1.1036301\n",
      "Iteration=3936\t Loss=2.5225675\t mu=9.971898\t sigma=1.1036301\n",
      "Iteration=3937\t Loss=2.5225675\t mu=9.971914\t sigma=1.1036301\n",
      "Iteration=3938\t Loss=2.5225675\t mu=9.9719305\t sigma=1.1036301\n",
      "Iteration=3939\t Loss=2.5225675\t mu=9.971947\t sigma=1.1036301\n",
      "Iteration=3940\t Loss=2.5225675\t mu=9.971962\t sigma=1.1036301\n",
      "Iteration=3941\t Loss=2.5225675\t mu=9.971977\t sigma=1.1036301\n",
      "Iteration=3942\t Loss=2.5225675\t mu=9.9719925\t sigma=1.1036301\n",
      "Iteration=3943\t Loss=2.5225675\t mu=9.972008\t sigma=1.1036301\n",
      "Iteration=3944\t Loss=2.5225677\t mu=9.972023\t sigma=1.1036301\n",
      "Iteration=3945\t Loss=2.5225675\t mu=9.972038\t sigma=1.1036301\n",
      "Iteration=3946\t Loss=2.5225675\t mu=9.972054\t sigma=1.1036301\n",
      "Iteration=3947\t Loss=2.5225675\t mu=9.972069\t sigma=1.1036301\n",
      "Iteration=3948\t Loss=2.5225675\t mu=9.972084\t sigma=1.1036301\n",
      "Iteration=3949\t Loss=2.5225675\t mu=9.972099\t sigma=1.1036301\n",
      "Iteration=3950\t Loss=2.5225675\t mu=9.972115\t sigma=1.1036301\n",
      "Iteration=3951\t Loss=2.5225675\t mu=9.97213\t sigma=1.1036301\n",
      "Iteration=3952\t Loss=2.5225673\t mu=9.972145\t sigma=1.1036301\n",
      "Iteration=3953\t Loss=2.5225673\t mu=9.97216\t sigma=1.10363\n",
      "Iteration=3954\t Loss=2.5225673\t mu=9.972176\t sigma=1.10363\n",
      "Iteration=3955\t Loss=2.5225673\t mu=9.972191\t sigma=1.10363\n",
      "Iteration=3956\t Loss=2.5225675\t mu=9.972206\t sigma=1.10363\n",
      "Iteration=3957\t Loss=2.5225675\t mu=9.972221\t sigma=1.10363\n",
      "Iteration=3958\t Loss=2.5225675\t mu=9.972237\t sigma=1.10363\n",
      "Iteration=3959\t Loss=2.5225675\t mu=9.972252\t sigma=1.10363\n",
      "Iteration=3960\t Loss=2.5225675\t mu=9.972267\t sigma=1.10363\n",
      "Iteration=3961\t Loss=2.5225675\t mu=9.972282\t sigma=1.10363\n",
      "Iteration=3962\t Loss=2.5225675\t mu=9.972298\t sigma=1.1036298\n",
      "Iteration=3963\t Loss=2.5225673\t mu=9.972312\t sigma=1.1036298\n",
      "Iteration=3964\t Loss=2.5225675\t mu=9.972326\t sigma=1.1036298\n",
      "Iteration=3965\t Loss=2.5225673\t mu=9.972341\t sigma=1.1036298\n",
      "Iteration=3966\t Loss=2.5225673\t mu=9.972355\t sigma=1.1036298\n",
      "Iteration=3967\t Loss=2.5225673\t mu=9.972369\t sigma=1.1036298\n",
      "Iteration=3968\t Loss=2.5225673\t mu=9.9723835\t sigma=1.1036298\n",
      "Iteration=3969\t Loss=2.5225673\t mu=9.972398\t sigma=1.1036298\n",
      "Iteration=3970\t Loss=2.5225673\t mu=9.972412\t sigma=1.1036298\n",
      "Iteration=3971\t Loss=2.5225673\t mu=9.972426\t sigma=1.1036298\n",
      "Iteration=3972\t Loss=2.5225673\t mu=9.972441\t sigma=1.1036298\n",
      "Iteration=3973\t Loss=2.5225673\t mu=9.972455\t sigma=1.1036298\n",
      "Iteration=3974\t Loss=2.5225673\t mu=9.972469\t sigma=1.1036298\n",
      "Iteration=3975\t Loss=2.5225673\t mu=9.972484\t sigma=1.1036298\n",
      "Iteration=3976\t Loss=2.5225673\t mu=9.972498\t sigma=1.1036298\n",
      "Iteration=3977\t Loss=2.5225673\t mu=9.972512\t sigma=1.1036298\n",
      "Iteration=3978\t Loss=2.5225673\t mu=9.972527\t sigma=1.1036298\n",
      "Iteration=3979\t Loss=2.5225673\t mu=9.972541\t sigma=1.1036297\n",
      "Iteration=3980\t Loss=2.522567\t mu=9.972555\t sigma=1.1036297\n",
      "Iteration=3981\t Loss=2.522567\t mu=9.972569\t sigma=1.1036297\n",
      "Iteration=3982\t Loss=2.5225673\t mu=9.972584\t sigma=1.1036297\n",
      "Iteration=3983\t Loss=2.5225673\t mu=9.972598\t sigma=1.1036297\n",
      "Iteration=3984\t Loss=2.522567\t mu=9.972612\t sigma=1.1036297\n",
      "Iteration=3985\t Loss=2.5225673\t mu=9.972627\t sigma=1.1036297\n",
      "Iteration=3986\t Loss=2.522567\t mu=9.972641\t sigma=1.1036297\n",
      "Iteration=3987\t Loss=2.5225673\t mu=9.972654\t sigma=1.1036297\n",
      "Iteration=3988\t Loss=2.5225673\t mu=9.972668\t sigma=1.1036297\n",
      "Iteration=3989\t Loss=2.5225673\t mu=9.972681\t sigma=1.1036297\n",
      "Iteration=3990\t Loss=2.5225673\t mu=9.972694\t sigma=1.1036297\n",
      "Iteration=3991\t Loss=2.5225673\t mu=9.972708\t sigma=1.1036297\n",
      "Iteration=3992\t Loss=2.5225673\t mu=9.972721\t sigma=1.1036297\n",
      "Iteration=3993\t Loss=2.5225673\t mu=9.972734\t sigma=1.1036297\n",
      "Iteration=3994\t Loss=2.5225673\t mu=9.972748\t sigma=1.1036297\n",
      "Iteration=3995\t Loss=2.5225673\t mu=9.972761\t sigma=1.1036297\n",
      "Iteration=3996\t Loss=2.5225673\t mu=9.9727745\t sigma=1.1036296\n",
      "Iteration=3997\t Loss=2.5225673\t mu=9.972788\t sigma=1.1036296\n",
      "Iteration=3998\t Loss=2.5225673\t mu=9.972801\t sigma=1.1036296\n",
      "Iteration=3999\t Loss=2.5225673\t mu=9.972815\t sigma=1.1036296\n",
      "Iteration=4000\t Loss=2.522567\t mu=9.972828\t sigma=1.1036296\n",
      "Iteration=4001\t Loss=2.522567\t mu=9.972841\t sigma=1.1036296\n",
      "Iteration=4002\t Loss=2.522567\t mu=9.972855\t sigma=1.1036295\n",
      "Iteration=4003\t Loss=2.5225673\t mu=9.972868\t sigma=1.1036295\n",
      "Iteration=4004\t Loss=2.5225673\t mu=9.972881\t sigma=1.1036295\n",
      "Iteration=4005\t Loss=2.522567\t mu=9.972895\t sigma=1.1036295\n",
      "Iteration=4006\t Loss=2.5225668\t mu=9.972908\t sigma=1.1036295\n",
      "Iteration=4007\t Loss=2.5225673\t mu=9.972921\t sigma=1.1036295\n",
      "Iteration=4008\t Loss=2.5225668\t mu=9.972935\t sigma=1.1036295\n",
      "Iteration=4009\t Loss=2.522567\t mu=9.972948\t sigma=1.1036295\n",
      "Iteration=4010\t Loss=2.522567\t mu=9.972961\t sigma=1.1036295\n",
      "Iteration=4011\t Loss=2.522567\t mu=9.972975\t sigma=1.1036295\n",
      "Iteration=4012\t Loss=2.522567\t mu=9.972988\t sigma=1.1036295\n",
      "Iteration=4013\t Loss=2.522567\t mu=9.973001\t sigma=1.1036295\n",
      "Iteration=4014\t Loss=2.522567\t mu=9.973013\t sigma=1.1036295\n",
      "Iteration=4015\t Loss=2.522567\t mu=9.973025\t sigma=1.1036295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration=4016\t Loss=2.522567\t mu=9.973038\t sigma=1.1036295\n",
      "Iteration=4017\t Loss=2.522567\t mu=9.97305\t sigma=1.1036295\n",
      "Iteration=4018\t Loss=2.522567\t mu=9.9730625\t sigma=1.1036295\n",
      "Iteration=4019\t Loss=2.5225668\t mu=9.973075\t sigma=1.1036295\n",
      "Iteration=4020\t Loss=2.5225668\t mu=9.973087\t sigma=1.1036295\n",
      "Iteration=4021\t Loss=2.5225668\t mu=9.9731\t sigma=1.1036295\n",
      "Iteration=4022\t Loss=2.5225668\t mu=9.973112\t sigma=1.1036295\n",
      "Iteration=4023\t Loss=2.5225668\t mu=9.9731245\t sigma=1.1036295\n",
      "Iteration=4024\t Loss=2.5225668\t mu=9.973137\t sigma=1.1036295\n",
      "Iteration=4025\t Loss=2.5225668\t mu=9.973149\t sigma=1.1036295\n",
      "Iteration=4026\t Loss=2.522567\t mu=9.973162\t sigma=1.1036295\n",
      "Iteration=4027\t Loss=2.522567\t mu=9.973174\t sigma=1.1036295\n",
      "Iteration=4028\t Loss=2.522567\t mu=9.9731865\t sigma=1.1036295\n",
      "Iteration=4029\t Loss=2.522567\t mu=9.973199\t sigma=1.1036295\n",
      "Iteration=4030\t Loss=2.522567\t mu=9.973211\t sigma=1.1036295\n",
      "Iteration=4031\t Loss=2.522567\t mu=9.973224\t sigma=1.1036295\n",
      "Iteration=4032\t Loss=2.522567\t mu=9.973236\t sigma=1.1036295\n",
      "Iteration=4033\t Loss=2.522567\t mu=9.9732485\t sigma=1.1036294\n",
      "Iteration=4034\t Loss=2.522567\t mu=9.973261\t sigma=1.1036294\n",
      "Iteration=4035\t Loss=2.5225668\t mu=9.973273\t sigma=1.1036294\n",
      "Iteration=4036\t Loss=2.5225668\t mu=9.973286\t sigma=1.1036294\n",
      "Iteration=4037\t Loss=2.5225668\t mu=9.973298\t sigma=1.1036294\n",
      "Iteration=4038\t Loss=2.5225668\t mu=9.97331\t sigma=1.1036294\n",
      "Iteration=4039\t Loss=2.5225668\t mu=9.973323\t sigma=1.1036294\n",
      "Iteration=4040\t Loss=2.5225666\t mu=9.973335\t sigma=1.1036294\n",
      "Iteration=4041\t Loss=2.5225666\t mu=9.973347\t sigma=1.1036294\n",
      "Iteration=4042\t Loss=2.5225666\t mu=9.973358\t sigma=1.1036294\n",
      "Iteration=4043\t Loss=2.5225668\t mu=9.97337\t sigma=1.1036294\n",
      "Iteration=4044\t Loss=2.5225668\t mu=9.973381\t sigma=1.1036294\n",
      "Iteration=4045\t Loss=2.5225666\t mu=9.9733925\t sigma=1.1036292\n",
      "Iteration=4046\t Loss=2.5225668\t mu=9.973404\t sigma=1.1036292\n",
      "Iteration=4047\t Loss=2.522567\t mu=9.973415\t sigma=1.1036292\n",
      "Iteration=4048\t Loss=2.5225668\t mu=9.973427\t sigma=1.1036292\n",
      "Iteration=4049\t Loss=2.5225668\t mu=9.973438\t sigma=1.1036292\n",
      "Iteration=4050\t Loss=2.522567\t mu=9.97345\t sigma=1.1036292\n",
      "Iteration=4051\t Loss=2.5225668\t mu=9.973461\t sigma=1.1036292\n",
      "Iteration=4052\t Loss=2.5225668\t mu=9.973473\t sigma=1.1036292\n",
      "Iteration=4053\t Loss=2.5225668\t mu=9.973484\t sigma=1.1036292\n",
      "Iteration=4054\t Loss=2.5225668\t mu=9.9734955\t sigma=1.1036292\n",
      "Iteration=4055\t Loss=2.5225668\t mu=9.973507\t sigma=1.1036292\n",
      "Iteration=4056\t Loss=2.5225666\t mu=9.973518\t sigma=1.1036292\n",
      "Iteration=4057\t Loss=2.5225666\t mu=9.97353\t sigma=1.1036292\n",
      "Iteration=4058\t Loss=2.5225668\t mu=9.973541\t sigma=1.1036292\n",
      "Iteration=4059\t Loss=2.5225666\t mu=9.973553\t sigma=1.1036292\n",
      "Iteration=4060\t Loss=2.5225668\t mu=9.973564\t sigma=1.1036292\n",
      "Iteration=4061\t Loss=2.5225668\t mu=9.973576\t sigma=1.1036292\n",
      "Iteration=4062\t Loss=2.5225668\t mu=9.973587\t sigma=1.1036292\n",
      "Iteration=4063\t Loss=2.5225668\t mu=9.9735985\t sigma=1.1036292\n",
      "Iteration=4064\t Loss=2.5225668\t mu=9.97361\t sigma=1.1036292\n",
      "Iteration=4065\t Loss=2.5225668\t mu=9.973621\t sigma=1.1036292\n",
      "Iteration=4066\t Loss=2.5225668\t mu=9.973633\t sigma=1.1036292\n",
      "Iteration=4067\t Loss=2.5225668\t mu=9.973644\t sigma=1.1036292\n",
      "Iteration=4068\t Loss=2.5225668\t mu=9.973656\t sigma=1.1036292\n",
      "Iteration=4069\t Loss=2.5225666\t mu=9.973667\t sigma=1.1036292\n",
      "Iteration=4070\t Loss=2.5225666\t mu=9.973679\t sigma=1.1036292\n",
      "Iteration=4071\t Loss=2.5225666\t mu=9.973689\t sigma=1.1036292\n",
      "Iteration=4072\t Loss=2.5225668\t mu=9.9737\t sigma=1.1036291\n",
      "Iteration=4073\t Loss=2.5225668\t mu=9.97371\t sigma=1.1036291\n",
      "Iteration=4074\t Loss=2.5225666\t mu=9.973721\t sigma=1.1036291\n",
      "Iteration=4075\t Loss=2.5225666\t mu=9.973731\t sigma=1.1036291\n",
      "Iteration=4076\t Loss=2.5225668\t mu=9.973742\t sigma=1.1036291\n",
      "Iteration=4077\t Loss=2.5225668\t mu=9.973752\t sigma=1.1036291\n",
      "Iteration=4078\t Loss=2.5225666\t mu=9.9737625\t sigma=1.1036291\n",
      "Iteration=4079\t Loss=2.5225666\t mu=9.973773\t sigma=1.1036291\n",
      "Iteration=4080\t Loss=2.5225663\t mu=9.9737835\t sigma=1.1036291\n",
      "Iteration=4081\t Loss=2.5225663\t mu=9.973794\t sigma=1.1036291\n",
      "Iteration=4082\t Loss=2.5225666\t mu=9.973804\t sigma=1.1036291\n",
      "Iteration=4083\t Loss=2.5225666\t mu=9.973815\t sigma=1.1036291\n",
      "Iteration=4084\t Loss=2.5225666\t mu=9.973825\t sigma=1.1036291\n",
      "Iteration=4085\t Loss=2.5225666\t mu=9.973836\t sigma=1.1036291\n",
      "Iteration=4086\t Loss=2.5225666\t mu=9.973846\t sigma=1.1036291\n",
      "Iteration=4087\t Loss=2.5225663\t mu=9.973857\t sigma=1.1036291\n",
      "Iteration=4088\t Loss=2.5225668\t mu=9.973867\t sigma=1.1036291\n",
      "Iteration=4089\t Loss=2.5225663\t mu=9.973878\t sigma=1.1036291\n",
      "Iteration=4090\t Loss=2.5225663\t mu=9.973888\t sigma=1.103629\n",
      "Iteration=4091\t Loss=2.5225663\t mu=9.973899\t sigma=1.103629\n",
      "Iteration=4092\t Loss=2.5225666\t mu=9.973909\t sigma=1.103629\n",
      "Iteration=4093\t Loss=2.5225668\t mu=9.97392\t sigma=1.103629\n",
      "Iteration=4094\t Loss=2.5225668\t mu=9.97393\t sigma=1.103629\n",
      "Iteration=4095\t Loss=2.5225668\t mu=9.973941\t sigma=1.103629\n",
      "Iteration=4096\t Loss=2.5225668\t mu=9.973951\t sigma=1.103629\n",
      "Iteration=4097\t Loss=2.5225668\t mu=9.973962\t sigma=1.103629\n",
      "Iteration=4098\t Loss=2.5225668\t mu=9.973972\t sigma=1.103629\n",
      "Iteration=4099\t Loss=2.5225666\t mu=9.973983\t sigma=1.103629\n",
      "Iteration=4100\t Loss=2.5225668\t mu=9.973993\t sigma=1.103629\n",
      "Iteration=4101\t Loss=2.5225666\t mu=9.974004\t sigma=1.103629\n",
      "Iteration=4102\t Loss=2.5225666\t mu=9.974014\t sigma=1.103629\n",
      "Iteration=4103\t Loss=2.5225666\t mu=9.974025\t sigma=1.103629\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## Simple gradient descent update\n",
    "## Use \"while\" loop instead of \"for\" loop\n",
    "#############################\n",
    "\n",
    "## Initial rate parameter (guess)\n",
    "mu = 2.0\n",
    "sigma = 2.0\n",
    "theta = jnp.array([mu, sigma])\n",
    "\n",
    "## Step size\n",
    "step_size = 0.025\n",
    "\n",
    "## List to hold loss values for each update of the rate parameter\n",
    "l = []\n",
    "\n",
    "## Convergence flag (intialized to false)\n",
    "conv_flag = False\n",
    "## Convergence tolerance abs(loss_i - loss_{i-1})\n",
    "conv_tol = 1e-5\n",
    "\n",
    "## Iteration counter\n",
    "i = 0\n",
    "\n",
    "while conv_flag==False:\n",
    "    ## Grab current loss\n",
    "    current_loss = normal_loss(theta, x)\n",
    "    l.append(current_loss)\n",
    "    ## Print current parm/loss values to console for given iteration\n",
    "    print_string = \"Iteration=\" + str(i) + \"\\t Loss=\" + str(current_loss) + \"\\t mu=\" + str(theta[0]) + \"\\t sigma=\" + str(theta[1])\n",
    "    print(print_string)\n",
    "    ## Update parm\n",
    "    mu_new = mu - step_size*grad_theta(theta, x)[0]\n",
    "    sigma_new = sigma - step_size*grad_theta(theta, x)[1]\n",
    "    ## Check for convergence\n",
    "    diff_mu = jnp.abs(mu_new) - mu\n",
    "    diff_sigma = jnp.abs(sigma_new) - sigma\n",
    "    ## If convergence achieved that change conv_flag=True and break while loop\n",
    "    if (diff_mu < conv_tol) and (diff_sigma < conv_tol):\n",
    "        conv_flag=True\n",
    "    ## Else if convergebce if not acheived maintain flag, increment iteration, update mu\n",
    "    else:\n",
    "        conv_flag=False\n",
    "        i = i +1\n",
    "        mu = mu_new\n",
    "        sigma = sigma_new\n",
    "        theta = jnp.array([mu,sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "resident-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='iter', ylabel='loss'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot loss as function of iteration history\n",
    "df = pd.DataFrame({'iter':jnp.arange(len(l)), 'loss':jnp.array(l)})\n",
    "sns.lineplot(data=df, x='iter', y='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "confident-improvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 2.5225656032562256\n",
       " hess_inv: array([[9.54844387, 0.10617023],\n",
       "       [0.10617023, 0.52211835]])\n",
       "      jac: array([7.2875991e-07, 3.1156426e-06], dtype=float32)\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 21\n",
       "      nit: 18\n",
       "     njev: 21\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([9.97767221, 1.1036286 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Scipy optimize - autograd through an optimization program?\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "## Initial value mu\n",
    "mu0 = 0.5\n",
    "sigma0 = 0.5\n",
    "theta0 = jnp.array([mu0, sigma0])\n",
    "\n",
    "## Optimize for Poisson mean/rate parameter (using Autograd)\n",
    "theta_bfgs = minimize(fun=normal_loss,\n",
    "                                           x0=theta0,\n",
    "                                           args=x,\n",
    "                                           method='BFGS',\n",
    "                                           jac=grad_theta)\n",
    "\n",
    "## Output\n",
    "\n",
    "#print(\"Convergence achieved: \", theta_bfgs.success)\n",
    "#print(\"Mean=\", theta_bfgs.x)\n",
    "\n",
    "theta_bfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-flooring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-console",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-cooper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-hungary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "retired-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "jax         0.2.9\n",
      "matplotlib  3.3.4\n",
      "numpy       1.20.1\n",
      "pandas      1.2.2\n",
      "seaborn     0.11.1\n",
      "sinfo       0.3.1\n",
      "-----\n",
      "IPython             7.20.0\n",
      "jupyter_client      6.1.11\n",
      "jupyter_core        4.7.1\n",
      "jupyterlab          3.0.9\n",
      "notebook            6.2.0\n",
      "-----\n",
      "Python 3.7.10 | packaged by conda-forge | (default, Feb 19 2021, 16:07:37) [GCC 9.3.0]\n",
      "Linux-3.10.0-1127.el7.x86_64-x86_64-with-centos-7.8.2003-Core\n",
      "79 logical CPU cores, x86_64\n",
      "-----\n",
      "Session information updated at 2021-03-01 13:51\n"
     ]
    }
   ],
   "source": [
    "from sinfo import sinfo\n",
    "sinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-syndicate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
